[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Book of Exploratory Data Analysis (EDA)",
    "section": "",
    "text": "This “book”, Book of Exploratory Data Analysis (EDA), is actually the organized lecture notes of the course MEF BDA 503.\nMaterials will progressively emerge…\nLatest update in 2022-10-06"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "See Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "4  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "dplyr.html",
    "href": "dplyr.html",
    "title": "2  dplyr",
    "section": "",
    "text": "Main purpose of this document is to introduce a major data manipulation package, dplyr, with a contemporary subject. There are seven fundamental dplyr functions: select/rename, filter, distinct, arrange, mutate/transmute, group_by and summarise with a number of assisting functions used either in these functions or separately. In this document, we will cover every one of them and there will be supplementary functions to carry out data operations. Also, pipe operator (%>%) will be briefly introduced. This document is updated for dplyr 1.0.0 and R 4.0+ to show you new stuff as well. We will also use lubridate package for date time operations but we will not cover it except for quick explanations (check appendix at the end of this document for a mini tutorial). You can use advanced features in the “Advance Usage” subsections.\n\n\nThere are two prerequisites to start: Install tidyverse package and putting the relevant data set into the working directory (write getwd() in the console to locate your working directory). In this document, topic of the data set is the hourly licensed and unlicensed renewable energy production data between January 1, 2018 and May 31, 2020.\nTo install the package run install.packages(\"tidyverse\") in the console and select a mirror (first one is quite ok). Once you install the library you can always call it with library(tidyverse) command (no need to reinstall). You can download the data set from its GitHub Repository.\n\nlibrary(tidyverse) #tidyverse is a package group which includes dplyr as well\nlibrary(lubridate)\nraw_df <- readRDS(\"rp_201801_202005_df.rds\")\n\n\n\n\nFirst of those above commands calls the package (different from installing) The second command assigns the data to raw_df variable. There are two types of assignment operators in R: <- and =. No operation in R is permanent unless you assign it to somewhere (There are exceptions, though. See data.table package for instance.). We will benefit from this property in this document as well. No matter how many operations we do on each example we will always start from the original data frame.\nLet’s do a simple sanity check. The output of the following command reads “21,168 x 17” in the first line, which means there are 21,168 rows and 17 columns in the tibble. Tibble is the name of the data.frame type of dplyr. It usually is data frame plus some advanced features. There are abbreviations of data types under each column name. These are usually character/string (), numeric (, if integer ), logical (TRUE/FALSE, logical) (), factor (), date () and datetime (). In the introduction phase we will only use character, numeric and logical data types.\n\nprint(raw_df,n=3)\n\n# A tibble: 21,168 × 17\n  dt                  wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2020-05-31 23:00:00    1434.           913.       75.8         2585.\n2 2020-05-31 22:00:00    1577.           908.       75.6         2631.\n3 2020-05-31 21:00:00    1858.           901.       75.4         2585.\n# … with 21,165 more rows, and 12 more variables: riverType_lic <dbl>,\n#   biomass_lic <dbl>, landfillGas_lic <dbl>, sun_lic <dbl>,\n#   reservoir_lic <dbl>, others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>,\n#   canalType_ul <dbl>, biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>\n\n\nAlso we can use glimpse function to inspect. Using glimpse each column is represented in a row with its data type and first few entries. Our data consists of hourly renewable electricity production of YEKDEM plants from different origins and license types. YEKDEM is a type of feed-in-tariff incentive framework. Suffixes with “_lic” represents licensed (larger scale) plants and “_ul” represents unlicensed (smaller scale) production. canalType, riverType and reservoir columns represent hydro power.\n\nraw_df %>% glimpse()\n\nRows: 21,168\nColumns: 17\n$ dt              <dttm> 2020-05-31 23:00:00, 2020-05-31 22:00:00, 2020-05-31 …\n$ wind_lic        <dbl> 1433.8132, 1577.1419, 1857.5492, 1933.0142, 2031.7862,…\n$ geothermal_lic  <dbl> 912.7882, 907.9303, 900.5844, 888.4561, 864.5402, 847.…\n$ biogas_lic      <dbl> 75.8047, 75.6163, 75.3906, 76.7873, 76.9707, 77.5750, …\n$ canalType_lic   <dbl> 2584.930, 2630.602, 2585.038, 2542.381, 2594.459, 2622…\n$ riverType_lic   <dbl> 316.5538, 316.6800, 356.7637, 350.1544, 377.5312, 379.…\n$ biomass_lic     <dbl> 262.4994, 253.0814, 246.9268, 249.9152, 248.2336, 246.…\n$ landfillGas_lic <dbl> 100.3971, 101.1378, 100.4442, 100.7307, 102.2474, 102.…\n$ sun_lic         <dbl> 0.0000, 0.0000, 0.0000, 0.0000, 2.0594, 14.2800, 48.09…\n$ reservoir_lic   <dbl> 2306.303, 2296.045, 2279.266, 2308.918, 2792.313, 3180…\n$ others_lic      <dbl> 48.3833, 48.4011, 48.4041, 48.4199, 48.4653, 48.5485, …\n$ wind_ul         <dbl> 3.7751, 4.8375, 7.6659, 11.8121, 13.1070, 13.1830, 10.…\n$ biogas_ul       <dbl> 16.9293, 16.9227, 16.9052, 16.7517, 16.2928, 16.5989, …\n$ canalType_ul    <dbl> 4.1749, 4.4221, 4.4658, 4.6020, 4.6195, 4.5146, 4.6616…\n$ biomass_ul      <dbl> 15.4698, 15.3609, 16.0483, 15.2271, 15.5563, 15.5007, …\n$ sun_ul          <dbl> 0.0582, 0.0320, 0.0335, 1.3121, 103.3267, 555.5787, 14…\n$ others_ul       <dbl> 0.0610, 0.0395, 0.4136, 0.5508, 0.7106, 1.3775, 2.7468…\n\n\nDid you notice the expression we used this time? Pipe operator makes data analysis and transformation very easy and civilized. We will use pipes frequently in this document and in the future.\nWe can connect many functions without calling the variable multiple times with the help of the pipe operator."
  },
  {
    "objectID": "dplyr.html#selectrename",
    "href": "dplyr.html#selectrename",
    "title": "2  Introduction to dplyr 1.0.0: Turkish Renewable Energy Production Data",
    "section": "4.1 select/rename",
    "text": "4.1 select/rename\nSelect, as the name suggests, is used to select columns. For instance, suppose we only want licensed wind production (wind_lic) and date-time (dt) columns.\n\nraw_df %>% select(dt,wind_lic)\n\n# A tibble: 21,168 × 2\n  dt                  wind_lic\n  <dttm>                 <dbl>\n1 2020-05-31 23:00:00    1434.\n2 2020-05-31 22:00:00    1577.\n3 2020-05-31 21:00:00    1858.\n# … with 21,165 more rows\n\n\nIf we wanted to write the above expression without the pipe operator, we could go with the sad expression below. You can extrapolate how complicated things can be without the pipe.\n\nselect(raw_df,dt,wind_lic)\n\nWe can use rename to rename columns (again as the name suggests). Let’s change dt to date_time.\n\nraw_df %>% rename(date_time = dt)\n\n# A tibble: 21,168 × 17\n  date_time           wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2020-05-31 23:00:00    1434.           913.       75.8         2585.\n2 2020-05-31 22:00:00    1577.           908.       75.6         2631.\n3 2020-05-31 21:00:00    1858.           901.       75.4         2585.\n# … with 21,165 more rows, and 12 more variables: riverType_lic <dbl>,\n#   biomass_lic <dbl>, landfillGas_lic <dbl>, sun_lic <dbl>,\n#   reservoir_lic <dbl>, others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>,\n#   canalType_ul <dbl>, biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>\n\n\np.s. We can rename columns inside select function.\nSelect has many convenient sub operators and special expressions. If we know the order of columns, we can use the scope (:) expression to get all the columns determined by the scope. Suppose, we want date-time (dt) and licensed production.\n\nraw_df %>% select(date_time=dt,wind_lic:others_lic)\n\n# A tibble: 21,168 × 11\n  date_time           wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2020-05-31 23:00:00    1434.           913.       75.8         2585.\n2 2020-05-31 22:00:00    1577.           908.       75.6         2631.\n3 2020-05-31 21:00:00    1858.           901.       75.4         2585.\n# … with 21,165 more rows, and 6 more variables: riverType_lic <dbl>,\n#   biomass_lic <dbl>, landfillGas_lic <dbl>, sun_lic <dbl>,\n#   reservoir_lic <dbl>, others_lic <dbl>\n\n\nWe can eliminate unwanted columns by putting - before the names. Suppose I am not interested in wind values, want to remove all other related columns from the data set, and all other related column names start with “wind_”. We can do it using - and starts_with.\n\nraw_df %>% select(-starts_with(\"wind_\")) \n\n# A tibble: 21,168 × 15\n  dt                  geothermal_lic biogas_lic canalType_lic riverType_lic\n  <dttm>                       <dbl>      <dbl>         <dbl>         <dbl>\n1 2020-05-31 23:00:00           913.       75.8         2585.          317.\n2 2020-05-31 22:00:00           908.       75.6         2631.          317.\n3 2020-05-31 21:00:00           901.       75.4         2585.          357.\n# … with 21,165 more rows, and 10 more variables: biomass_lic <dbl>,\n#   landfillGas_lic <dbl>, sun_lic <dbl>, reservoir_lic <dbl>,\n#   others_lic <dbl>, biogas_ul <dbl>, canalType_ul <dbl>, biomass_ul <dbl>,\n#   sun_ul <dbl>, others_ul <dbl>\n\n\nThere are similar expressions for other purposes, such as starts_with, everything and contains. You can see all the expressions in the Cheat Sheet link given at the end of this document.\ndplyr 1.0.0 Feature: Sometimes you just want to change the order of the columns. Then use relocate. Suppose we want to show solar and wind production with date-time. But we want to get licensed wind together with licensed solar.\n\nraw_df %>% select(dt,starts_with(\"sun_\"),starts_with(\"wind\")) %>% relocate(wind_lic,.before=sun_ul)\n\n# A tibble: 21,168 × 5\n  dt                  sun_lic wind_lic sun_ul wind_ul\n  <dttm>                <dbl>    <dbl>  <dbl>   <dbl>\n1 2020-05-31 23:00:00       0    1434. 0.0582    3.78\n2 2020-05-31 22:00:00       0    1577. 0.032     4.84\n3 2020-05-31 21:00:00       0    1858. 0.0335    7.67\n# … with 21,165 more rows\n\n\nIf we specify nothing, it will be in the first place.\n\nraw_df %>% select(dt,starts_with(\"sun_\"),starts_with(\"wind\")) %>% relocate(wind_lic)\n\n# A tibble: 21,168 × 5\n  wind_lic dt                  sun_lic sun_ul wind_ul\n     <dbl> <dttm>                <dbl>  <dbl>   <dbl>\n1    1434. 2020-05-31 23:00:00       0 0.0582    3.78\n2    1577. 2020-05-31 22:00:00       0 0.032     4.84\n3    1858. 2020-05-31 21:00:00       0 0.0335    7.67\n# … with 21,165 more rows\n\n\nWe use last_col() if we want to take a column to the end.\n\nraw_df %>% select(dt,starts_with(\"sun_\"),starts_with(\"wind\")) %>% relocate(dt,.after=last_col())\n\n# A tibble: 21,168 × 5\n  sun_lic sun_ul wind_lic wind_ul dt                 \n    <dbl>  <dbl>    <dbl>   <dbl> <dttm>             \n1       0 0.0582    1434.    3.78 2020-05-31 23:00:00\n2       0 0.032     1577.    4.84 2020-05-31 22:00:00\n3       0 0.0335    1858.    7.67 2020-05-31 21:00:00\n# … with 21,165 more rows\n\n\nHonestly, relocate is a very convenient function.\n\n4.1.1 select/rename advanced usage\nAdvanced usage subsection introduces extra functionality which can be a bit confusing at the first phase. But, once you get a grasp on the fundamentals check back here as reference. There are several features not available for versions before dplyr 1.0.0.\nWe can use rename_with function to rename columns with given criteria. In pipe version of the function, first parameter is the function and the second parameter is the criterion. Let’s replace all “Type” with “_type”. For instance it should change “canalType” to “canal_type”.\n\nraw_df %>% rename_with(~gsub(\"Type\",\"_type\",.),contains(\"Type\")) %>% glimpse()\n\nRows: 21,168\nColumns: 17\n$ dt              <dttm> 2020-05-31 23:00:00, 2020-05-31 22:00:00, 2020-05-31 …\n$ wind_lic        <dbl> 1433.8132, 1577.1419, 1857.5492, 1933.0142, 2031.7862,…\n$ geothermal_lic  <dbl> 912.7882, 907.9303, 900.5844, 888.4561, 864.5402, 847.…\n$ biogas_lic      <dbl> 75.8047, 75.6163, 75.3906, 76.7873, 76.9707, 77.5750, …\n$ canal_type_lic  <dbl> 2584.930, 2630.602, 2585.038, 2542.381, 2594.459, 2622…\n$ river_type_lic  <dbl> 316.5538, 316.6800, 356.7637, 350.1544, 377.5312, 379.…\n$ biomass_lic     <dbl> 262.4994, 253.0814, 246.9268, 249.9152, 248.2336, 246.…\n$ landfillGas_lic <dbl> 100.3971, 101.1378, 100.4442, 100.7307, 102.2474, 102.…\n$ sun_lic         <dbl> 0.0000, 0.0000, 0.0000, 0.0000, 2.0594, 14.2800, 48.09…\n$ reservoir_lic   <dbl> 2306.303, 2296.045, 2279.266, 2308.918, 2792.313, 3180…\n$ others_lic      <dbl> 48.3833, 48.4011, 48.4041, 48.4199, 48.4653, 48.5485, …\n$ wind_ul         <dbl> 3.7751, 4.8375, 7.6659, 11.8121, 13.1070, 13.1830, 10.…\n$ biogas_ul       <dbl> 16.9293, 16.9227, 16.9052, 16.7517, 16.2928, 16.5989, …\n$ canal_type_ul   <dbl> 4.1749, 4.4221, 4.4658, 4.6020, 4.6195, 4.5146, 4.6616…\n$ biomass_ul      <dbl> 15.4698, 15.3609, 16.0483, 15.2271, 15.5563, 15.5007, …\n$ sun_ul          <dbl> 0.0582, 0.0320, 0.0335, 1.3121, 103.3267, 555.5787, 14…\n$ others_ul       <dbl> 0.0610, 0.0395, 0.4136, 0.5508, 0.7106, 1.3775, 2.7468…\n\n\nDid you notice ~ and . in the function? Dot (.) is a representation of the entity. Depending on the situation it can be the latest version of the tibble in the pipe chain, a specific column or something else. ~ is a special character notifying that function evaluation will be done using the dot notation. We will see more examples of that.\nLet’s introduce where. If is a function from tidyselect package to select variables with a function where it returns TRUE. It is quite handy.\n\nraw_df %>% select(dt,starts_with(\"sun_\"),starts_with(\"wind\")) %>% relocate(where(is.numeric))\n\n# A tibble: 21,168 × 5\n  sun_lic sun_ul wind_lic wind_ul dt                 \n    <dbl>  <dbl>    <dbl>   <dbl> <dttm>             \n1       0 0.0582    1434.    3.78 2020-05-31 23:00:00\n2       0 0.032     1577.    4.84 2020-05-31 22:00:00\n3       0 0.0335    1858.    7.67 2020-05-31 21:00:00\n# … with 21,165 more rows\n\n\nWe can also use any_of or all_of functions in select. The main difference is while the former returns as much as it can, the latter will throw an error if any one of the criteria is not fulfilled. Let’s try to select “dt”, “others_lic” and “nuclear_lic”. Since this data does not include nuclear power production we should not see it.\n\nraw_df %>% select(any_of(c(\"dt\",\"others_lic\",\"nuclear_lic\")))\n\n# A tibble: 21,168 × 2\n  dt                  others_lic\n  <dttm>                   <dbl>\n1 2020-05-31 23:00:00       48.4\n2 2020-05-31 22:00:00       48.4\n3 2020-05-31 21:00:00       48.4\n# … with 21,165 more rows\n\n\nIn order not to break our notebook, we wrap it around try (error handling is another topic).\n\ntry(raw_df %>% select(all_of(c(\"dt\",\"others_lic\",\"nuclear_lic\"))))\n\nError : Can't subset columns that don't exist.\n✖ Column `nuclear_lic` doesn't exist."
  },
  {
    "objectID": "dplyr.html#filterdistinct",
    "href": "dplyr.html#filterdistinct",
    "title": "2  Introduction to dplyr 1.0.0: Turkish Renewable Energy Production Data",
    "section": "4.2 filter/distinct",
    "text": "4.2 filter/distinct\nFilter (no more “as the name suggests”, as you already figured it out) helps filter rows according to given criteria. It is highly similar with Excel’s filter functionality (but much much more flexible and reliable).\nLet’s see the production at 2020-05-08 16:00:00.\n\nraw_df %>% filter(dt == \"2020-05-08 16:00:00\")\n\n# A tibble: 1 × 17\n  dt                  wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2020-05-08 16:00:00    2618.           856.       79.8         3896.\n# … with 12 more variables: riverType_lic <dbl>, biomass_lic <dbl>,\n#   landfillGas_lic <dbl>, sun_lic <dbl>, reservoir_lic <dbl>,\n#   others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>, canalType_ul <dbl>,\n#   biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>\n\n\nBy using == operator, we bring the values in dt column which are equal to the hour we desired. There are other expressions such as not equal to (!=), greater than (or equal to) (>,>=), smaller than (or equal to) (<,<=), in (%in%) and some more.\nAt the same time we can make comparisons between columns and combine multiple criteria to create more complex filters. Here we use AND (&) and OR (|) operators to combine criteria.\nSuppose we want to find our the times when licensed wind production is greater than all of hydro type licensed production.\n\nraw_df %>% filter(wind_lic > canalType_lic & wind_lic > reservoir_lic & wind_lic > riverType_lic)\n\n# A tibble: 11,287 × 17\n  dt                  wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2020-05-27 19:00:00    3303.           930.       74.7         2969.\n2 2020-05-27 18:00:00    3596.           914.       75.0         2953.\n3 2020-05-27 17:00:00    3551.           900.       76.3         2954.\n# … with 11,284 more rows, and 12 more variables: riverType_lic <dbl>,\n#   biomass_lic <dbl>, landfillGas_lic <dbl>, sun_lic <dbl>,\n#   reservoir_lic <dbl>, others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>,\n#   canalType_ul <dbl>, biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>\n\n\nWe can add numeric operations as well. Suppose we want to find the total solar production is greater than total wind production.\n\nraw_df %>% filter(wind_lic + wind_ul < sun_lic + sun_ul)\n\n# A tibble: 4,949 × 17\n  dt                  wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2020-05-31 16:00:00    2036.           843.       76.8         2616.\n2 2020-05-31 15:00:00    1875.           845.       77.4         2685.\n3 2020-05-31 14:00:00    1755.           853.       77.2         2715.\n# … with 4,946 more rows, and 12 more variables: riverType_lic <dbl>,\n#   biomass_lic <dbl>, landfillGas_lic <dbl>, sun_lic <dbl>,\n#   reservoir_lic <dbl>, others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>,\n#   canalType_ul <dbl>, biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>\n\n\nSuppose we want to filter only the unique values. Then we simply use distinct command. Let’s get unique rounded licensed wind production values.\n\nraw_df %>% distinct(round(wind_lic))\n\n# A tibble: 4,893 × 1\n  `round(wind_lic)`\n              <dbl>\n1              1434\n2              1577\n3              1858\n# … with 4,890 more rows\n\n\nIf we want to keep all columns we simply make the parameter .keep=TRUE.\n\nraw_df %>% distinct(round(wind_lic),.keep=TRUE)\n\n# A tibble: 4,893 × 2\n  `round(wind_lic)` .keep\n              <dbl> <lgl>\n1              1434 TRUE \n2              1577 TRUE \n3              1858 TRUE \n# … with 4,890 more rows\n\n\n\n4.2.1 filter/distinct advanced usage\nLet’s introduce slice. This function helps return rows by its row number. Suppose we want the top 5 rows.\n\nraw_df %>% slice(1:5) %>% print(n=5)\n\n# A tibble: 5 × 17\n  dt                  wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2020-05-31 23:00:00    1434.           913.       75.8         2585.\n2 2020-05-31 22:00:00    1577.           908.       75.6         2631.\n3 2020-05-31 21:00:00    1858.           901.       75.4         2585.\n4 2020-05-31 20:00:00    1933.           888.       76.8         2542.\n5 2020-05-31 19:00:00    2032.           865.       77.0         2594.\n# … with 12 more variables: riverType_lic <dbl>, biomass_lic <dbl>,\n#   landfillGas_lic <dbl>, sun_lic <dbl>, reservoir_lic <dbl>,\n#   others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>, canalType_ul <dbl>,\n#   biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>\n\n\nIf we want to return random rows we have slice_sample. Let’s bring 5 random rows.\n\nraw_df %>% slice_sample(n=5)\n\n# A tibble: 5 × 17\n  dt                  wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2020-05-18 13:00:00    1661.           669.       75.9         3266.\n2 2019-08-28 10:00:00    3410.           691.       83.0          843.\n3 2019-02-28 12:00:00    2106.           898.       82.5         2128.\n# … with 2 more rows, and 12 more variables: riverType_lic <dbl>,\n#   biomass_lic <dbl>, landfillGas_lic <dbl>, sun_lic <dbl>,\n#   reservoir_lic <dbl>, others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>,\n#   canalType_ul <dbl>, biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>\n\n\nIf we want to do it proportionately, we have the prop parameter. Let’s say we want 0.1% of the data frame.\n\nraw_df %>% slice_sample(prop=0.001)\n\n# A tibble: 21 × 17\n  dt                  wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2020-02-09 17:00:00    1422.           971.       77.3         1995.\n2 2020-02-28 18:00:00    2401.           923.       77.4         2389.\n3 2018-04-22 22:00:00    1525.           720.       64.3         1986.\n# … with 18 more rows, and 12 more variables: riverType_lic <dbl>,\n#   biomass_lic <dbl>, landfillGas_lic <dbl>, sun_lic <dbl>,\n#   reservoir_lic <dbl>, others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>,\n#   canalType_ul <dbl>, biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>\n\n\nThere are other slice_* type functions. These are slice_head/slice_tail for first/last n or percentage of rows. slice_min/slice_max for the top/bottom n rows according to an ordering criteria."
  },
  {
    "objectID": "dplyr.html#arrange",
    "href": "dplyr.html#arrange",
    "title": "2  Introduction to dplyr 1.0.0: Turkish Renewable Energy Production Data",
    "section": "4.3 arrange",
    "text": "4.3 arrange\nArrange sorts rows from A to Z or smallest to largest. It has great similarity with Excel’s Sort functionality.\nLet’s sort licensed reservoir production from largest to smallest.\n\nraw_df %>% select(dt,reservoir_lic) %>% arrange(desc(reservoir_lic))\n\n# A tibble: 21,168 × 2\n  dt                  reservoir_lic\n  <dttm>                      <dbl>\n1 2019-05-10 23:00:00         5058.\n2 2019-05-10 21:00:00         5035.\n3 2019-05-15 02:00:00         5019.\n# … with 21,165 more rows\n\n\nDo you see desc() function inside arrange? By default arrange sorts a column by first to last or A-Z. desc reverses this.\nYou can also use multiple sorting criteria and use operations inside arrange. Let’s arrange by licensed wind production rounded down (floor) in 100s range (e.g. 5634 = 5600 and 5693 = 5600 as well). Then we sort by date time to see the first time the production entered a 100-range in the data time period.\n\nraw_df %>% arrange(desc(floor(wind_lic/100)*100),dt)\n\n# A tibble: 21,168 × 17\n  dt                  wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2019-09-15 17:00:00    5767.           691.       83.0          922.\n2 2018-09-26 19:00:00    5622.           672.       67.8          951.\n3 2019-09-15 15:00:00    5628.           692.       81.4          901.\n# … with 21,165 more rows, and 12 more variables: riverType_lic <dbl>,\n#   biomass_lic <dbl>, landfillGas_lic <dbl>, sun_lic <dbl>,\n#   reservoir_lic <dbl>, others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>,\n#   canalType_ul <dbl>, biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>"
  },
  {
    "objectID": "dplyr.html#mutatetransmute",
    "href": "dplyr.html#mutatetransmute",
    "title": "2  Introduction to dplyr 1.0.0: Turkish Renewable Energy Production Data",
    "section": "4.4 mutate/transmute",
    "text": "4.4 mutate/transmute\nMutate is the function when we do operations and calculations using other columns.\nFor instance let’s calculate wind power’s share in total renewables production at each hour.\n\nraw_df %>% mutate(wind_lic_perc = wind_lic / (wind_lic + geothermal_lic + biogas_lic + canalType_lic + riverType_lic + biomass_lic + landfillGas_lic + sun_lic + reservoir_lic + others_lic + wind_ul + biogas_ul + canalType_ul + biomass_ul + sun_ul + others_ul)) %>% select(dt, wind_lic_perc)\n\n# A tibble: 21,168 × 2\n  dt                  wind_lic_perc\n  <dttm>                      <dbl>\n1 2020-05-31 23:00:00         0.177\n2 2020-05-31 22:00:00         0.191\n3 2020-05-31 21:00:00         0.219\n# … with 21,165 more rows\n\n\nYou can use many R functions (from both base functions and other packages). For instance to calculate “competition” wind and solar we can use the following expression.\n\nraw_df %>% mutate(wind_or_solar = ifelse(wind_lic + wind_ul > sun_lic + sun_ul, \"wind\", \"solar\")) %>% select(dt,wind_or_solar)\n\n# A tibble: 21,168 × 2\n  dt                  wind_or_solar\n  <dttm>              <chr>        \n1 2020-05-31 23:00:00 wind         \n2 2020-05-31 22:00:00 wind         \n3 2020-05-31 21:00:00 wind         \n# … with 21,165 more rows\n\n\nTransmute has the same functionality as mutate with the additional property similar to select. Transmute returns only the columns included in the function. Suppose we also want to calculate the difference between total wind and total solar.\n\nraw_df %>% transmute(dt, wind_or_solar = ifelse(wind_lic + wind_ul > sun_lic + sun_ul, \"wind\", \"solar\"), absdiff = abs(wind_lic + wind_ul - sun_lic - sun_ul))\n\n# A tibble: 21,168 × 3\n  dt                  wind_or_solar absdiff\n  <dttm>              <chr>           <dbl>\n1 2020-05-31 23:00:00 wind            1438.\n2 2020-05-31 22:00:00 wind            1582.\n3 2020-05-31 21:00:00 wind            1865.\n# … with 21,165 more rows\n\n\n\n4.4.1 mutate/transmute advanced usage\nSuppose we want to see the difference between the previous and next hour’s production. We offset rows using lead and lag functions. But remember lead and lag does not actually give you “next/previous hour’s” values, just the rows. You may need to arrange your data.\n\nraw_df %>% transmute(dt, wind_lic, wind_lic_prev_h = lead(wind_lic,1), wind_lic_next_h = lag(wind_lic,1))\n\n# A tibble: 21,168 × 4\n  dt                  wind_lic wind_lic_prev_h wind_lic_next_h\n  <dttm>                 <dbl>           <dbl>           <dbl>\n1 2020-05-31 23:00:00    1434.           1577.             NA \n2 2020-05-31 22:00:00    1577.           1858.           1434.\n3 2020-05-31 21:00:00    1858.           1933.           1577.\n# … with 21,165 more rows\n\n\nIf you want to use the same function over several columns, you can use the new across function. Let’s round every numeric column to one significant digit.\n\nraw_df %>% mutate(across(where(is.numeric),~round(.,1)))\n\n# A tibble: 21,168 × 17\n  dt                  wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2020-05-31 23:00:00    1434.           913.       75.8         2585.\n2 2020-05-31 22:00:00    1577.           908.       75.6         2631.\n3 2020-05-31 21:00:00    1858.           901.       75.4         2585 \n# … with 21,165 more rows, and 12 more variables: riverType_lic <dbl>,\n#   biomass_lic <dbl>, landfillGas_lic <dbl>, sun_lic <dbl>,\n#   reservoir_lic <dbl>, others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>,\n#   canalType_ul <dbl>, biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>\n\n\nWe can also specify columns. Let’s see the comparative production of wind and reservoir hydro against the unlicensed solar production. We just increment solar production by 1 to prevent any infinity values.\n\nraw_df %>% mutate(sun_ul = sun_ul + 1) %>% transmute(dt,across(c(wind_lic,reservoir_lic),~round(./sun_ul,2)))\n\n# A tibble: 21,168 × 3\n  dt                  wind_lic reservoir_lic\n  <dttm>                 <dbl>         <dbl>\n1 2020-05-31 23:00:00    1355.         2179.\n2 2020-05-31 22:00:00    1528.         2225.\n3 2020-05-31 21:00:00    1797.         2205.\n# … with 21,165 more rows\n\n\nIf there are multiple conditions ifelse is not enough. It is possible to use case_when to specify multiple conditions and outcomes.\n\nraw_df %>% transmute(dt, solar_production_level = case_when(sun_ul > quantile(sun_ul,0.9) ~ \"very high\", sun_ul > quantile(sun_ul, 0.75) ~ \"high\", sun_ul > quantile(sun_ul, 0.5) ~ \"above median\", TRUE ~ \"below median\"))  %>% slice(7:9)\n\n# A tibble: 3 × 2\n  dt                  solar_production_level\n  <dttm>              <chr>                 \n1 2020-05-31 17:00:00 above median          \n2 2020-05-31 16:00:00 high                  \n3 2020-05-31 15:00:00 very high             \n\n\nrowwise is actually a type of group_by/summarise function but as the name suggests it allows us to do row-wise operations. Let’s calculate row sums by using c_across function and rowwise. Oh and also now, experimentally, you can use relocate functionality in mutate/transmute. So, conveniently we can place it after date time.\n\nraw_df %>% slice_head(n=5) %>% rowwise() %>% mutate(total_prod = sum(c_across(where(is.numeric))),.after=dt)\n\n# A tibble: 5 × 18\n# Rowwise: \n  dt                  total_prod wind_lic geothermal_lic biogas_lic\n  <dttm>                   <dbl>    <dbl>          <dbl>      <dbl>\n1 2020-05-31 23:00:00      8082.    1434.           913.       75.8\n2 2020-05-31 22:00:00      8248.    1577.           908.       75.6\n3 2020-05-31 21:00:00      8496.    1858.           901.       75.4\n# … with 2 more rows, and 13 more variables: canalType_lic <dbl>,\n#   riverType_lic <dbl>, biomass_lic <dbl>, landfillGas_lic <dbl>,\n#   sun_lic <dbl>, reservoir_lic <dbl>, others_lic <dbl>, wind_ul <dbl>,\n#   biogas_ul <dbl>, canalType_ul <dbl>, biomass_ul <dbl>, sun_ul <dbl>,\n#   others_ul <dbl>"
  },
  {
    "objectID": "dplyr.html#group_bysummarise",
    "href": "dplyr.html#group_bysummarise",
    "title": "2  Introduction to dplyr 1.0.0: Turkish Renewable Energy Production Data",
    "section": "4.5 group_by/summarise",
    "text": "4.5 group_by/summarise\nFinally we will learn how to calculate summary tables. It is similar to Pivot Tables in Excel. group_by is the grouping function, summarise is the summarising function.\nFor instance let’s calculate number of hours where wind production is above 3000 MWh. We will use a special function n() to calculate number of rows. We can define groupings just like mutate.\n\nraw_df %>% group_by(production_group = cut(wind_lic + wind_ul,breaks=c(0,1000,2000,3000,4000,5000,6000),include.lowest = TRUE)) %>% summarise(count = n())\n\n# A tibble: 6 × 2\n  production_group count\n  <fct>            <int>\n1 [0,1e+03]         4294\n2 (1e+03,2e+03]     5733\n3 (2e+03,3e+03]     4725\n# … with 3 more rows\n\n\nNormally, we get one result for each group and summary function. From dplyr 1.0.0 we can have multiple row summarise for each group. Let’s say we want to find the minimum and maximum licensed wind production ranges for each year. But, be warned, it can be a little confusing.\n\nraw_df %>% group_by(year = lubridate::year(dt)) %>% summarise(wind_lic_range = range(wind_lic))\n\n`summarise()` has grouped output by 'year'. You can override using the `.groups` argument.\n\n\n# A tibble: 6 × 2\n# Groups:   year [3]\n   year wind_lic_range\n  <dbl>          <dbl>\n1  2018           46.2\n2  2018         5622. \n3  2019           32.8\n# … with 3 more rows\n\n\n\n4.5.1 group_by/summarise advanced usage\nJust like mutate/transmute you can use across in summarise as well. Let’s see median production of each year and each source. In this example we can also use the named list version of the functions and additional names structure.\n\nraw_df %>% group_by(year = lubridate::year(dt)) %>% summarise(across(where(is.numeric),list(med=median),.names=\"{fn}_{col}\"))\n\n# A tibble: 3 × 17\n   year med_wind_lic med_geothermal_lic med_biogas_lic med_canalType_lic\n  <dbl>        <dbl>              <dbl>          <dbl>             <dbl>\n1  2018        1989.               694.           66.4             1480.\n2  2019        2136.               814.           80.9             1575.\n3  2020        2297.               951.           78.5             2779.\n# … with 12 more variables: med_riverType_lic <dbl>, med_biomass_lic <dbl>,\n#   med_landfillGas_lic <dbl>, med_sun_lic <dbl>, med_reservoir_lic <dbl>,\n#   med_others_lic <dbl>, med_wind_ul <dbl>, med_biogas_ul <dbl>,\n#   med_canalType_ul <dbl>, med_biomass_ul <dbl>, med_sun_ul <dbl>,\n#   med_others_ul <dbl>"
  },
  {
    "objectID": "dplyr.html#mini-lubridate-tutorial",
    "href": "dplyr.html#mini-lubridate-tutorial",
    "title": "2  Introduction to dplyr 1.0.0: Turkish Renewable Energy Production Data",
    "section": "7.1 Mini lubridate tutorial",
    "text": "7.1 Mini lubridate tutorial\nIn this tutorial we use a small portion of a very powerful package, lubridate. You can see the official website here.\nLet’s take just 3 dates at random from our data set.\n\nset.seed(5)\nlub_df <- \nraw_df %>% \n  select(dt) %>%\n  sample_n(3)\n\nprint(lub_df)\n\n# A tibble: 3 × 1\n  dt                 \n  <dttm>             \n1 2018-12-02 06:00:00\n2 2019-01-12 05:00:00\n3 2018-04-16 09:00:00\n\n\nSince we called lubridate at the beginning of this tutorial we do not need to call by package reference (lubridate::) but it is generally good practice.\n\nlub_df %>% \n  mutate(\n    year = lubridate::year(dt),\n    month = lubridate::month(dt),\n    day = lubridate::day(dt),\n    week_day = lubridate::wday(dt),\n    wday_label = lubridate::wday(dt,label=TRUE),\n    hour = lubridate::hour(dt),\n    minute = lubridate::minute(dt),\n    second = lubridate::second(dt)\n  )\n\n# A tibble: 3 × 9\n  dt                   year month   day week_day wday_label  hour minute second\n  <dttm>              <dbl> <dbl> <int>    <dbl> <ord>      <int>  <int>  <dbl>\n1 2018-12-02 06:00:00  2018    12     2        1 Sun            6      0      0\n2 2019-01-12 05:00:00  2019     1    12        7 Sat            5      0      0\n3 2018-04-16 09:00:00  2018     4    16        2 Mon            9      0      0"
  },
  {
    "objectID": "dplyr.html#fundamentals",
    "href": "dplyr.html#fundamentals",
    "title": "2  dplyr",
    "section": "2.2 Fundamentals",
    "text": "2.2 Fundamentals\nIn this chapter fundamental functions of dplyr are introduced. Every function will be used in the following examples after it has been introduced. To limit the number of displayed rows, we use the following global option. You can ignore this part in your exercises.\n\noptions(tibble.print_max = 3, tibble.print_min = 3)\n\n\n2.2.1 select/rename\nSelect, as the name suggests, is used to select columns. For instance, suppose we only want licensed wind production (wind_lic) and date-time (dt) columns.\n\nraw_df %>% select(dt,wind_lic)\n\n# A tibble: 21,168 × 2\n  dt                  wind_lic\n  <dttm>                 <dbl>\n1 2020-05-31 23:00:00    1434.\n2 2020-05-31 22:00:00    1577.\n3 2020-05-31 21:00:00    1858.\n# … with 21,165 more rows\n\n\nIf we wanted to write the above expression without the pipe operator, we could go with the sad expression below. You can extrapolate how complicated things can be without the pipe.\n\nselect(raw_df,dt,wind_lic)\n\nWe can use rename to rename columns (again as the name suggests). Let’s change dt to date_time.\n\nraw_df %>% rename(date_time = dt)\n\n# A tibble: 21,168 × 17\n  date_time           wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2020-05-31 23:00:00    1434.           913.       75.8         2585.\n2 2020-05-31 22:00:00    1577.           908.       75.6         2631.\n3 2020-05-31 21:00:00    1858.           901.       75.4         2585.\n# … with 21,165 more rows, and 12 more variables: riverType_lic <dbl>,\n#   biomass_lic <dbl>, landfillGas_lic <dbl>, sun_lic <dbl>,\n#   reservoir_lic <dbl>, others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>,\n#   canalType_ul <dbl>, biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>\n\n\np.s. We can rename columns inside select function.\nSelect has many convenient sub operators and special expressions. If we know the order of columns, we can use the scope (:) expression to get all the columns determined by the scope. Suppose, we want date-time (dt) and licensed production.\n\nraw_df %>% select(date_time=dt,wind_lic:others_lic)\n\n# A tibble: 21,168 × 11\n  date_time           wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2020-05-31 23:00:00    1434.           913.       75.8         2585.\n2 2020-05-31 22:00:00    1577.           908.       75.6         2631.\n3 2020-05-31 21:00:00    1858.           901.       75.4         2585.\n# … with 21,165 more rows, and 6 more variables: riverType_lic <dbl>,\n#   biomass_lic <dbl>, landfillGas_lic <dbl>, sun_lic <dbl>,\n#   reservoir_lic <dbl>, others_lic <dbl>\n\n\nWe can eliminate unwanted columns by putting - before the names. Suppose I am not interested in wind values, want to remove all other related columns from the data set, and all other related column names start with “wind_”. We can do it using - and starts_with.\n\nraw_df %>% select(-starts_with(\"wind_\")) \n\n# A tibble: 21,168 × 15\n  dt                  geothermal_lic biogas_lic canalType_lic riverType_lic\n  <dttm>                       <dbl>      <dbl>         <dbl>         <dbl>\n1 2020-05-31 23:00:00           913.       75.8         2585.          317.\n2 2020-05-31 22:00:00           908.       75.6         2631.          317.\n3 2020-05-31 21:00:00           901.       75.4         2585.          357.\n# … with 21,165 more rows, and 10 more variables: biomass_lic <dbl>,\n#   landfillGas_lic <dbl>, sun_lic <dbl>, reservoir_lic <dbl>,\n#   others_lic <dbl>, biogas_ul <dbl>, canalType_ul <dbl>, biomass_ul <dbl>,\n#   sun_ul <dbl>, others_ul <dbl>\n\n\nThere are similar expressions for other purposes, such as starts_with, everything and contains. You can see all the expressions in the Cheat Sheet link given at the end of this document.\ndplyr 1.0.0 Feature: Sometimes you just want to change the order of the columns. Then use relocate. Suppose we want to show solar and wind production with date-time. But we want to get licensed wind together with licensed solar.\n\nraw_df %>% select(dt,starts_with(\"sun_\"),starts_with(\"wind\")) %>% relocate(wind_lic,.before=sun_ul)\n\n# A tibble: 21,168 × 5\n  dt                  sun_lic wind_lic sun_ul wind_ul\n  <dttm>                <dbl>    <dbl>  <dbl>   <dbl>\n1 2020-05-31 23:00:00       0    1434. 0.0582    3.78\n2 2020-05-31 22:00:00       0    1577. 0.032     4.84\n3 2020-05-31 21:00:00       0    1858. 0.0335    7.67\n# … with 21,165 more rows\n\n\nIf we specify nothing, it will be in the first place.\n\nraw_df %>% select(dt,starts_with(\"sun_\"),starts_with(\"wind\")) %>% relocate(wind_lic)\n\n# A tibble: 21,168 × 5\n  wind_lic dt                  sun_lic sun_ul wind_ul\n     <dbl> <dttm>                <dbl>  <dbl>   <dbl>\n1    1434. 2020-05-31 23:00:00       0 0.0582    3.78\n2    1577. 2020-05-31 22:00:00       0 0.032     4.84\n3    1858. 2020-05-31 21:00:00       0 0.0335    7.67\n# … with 21,165 more rows\n\n\nWe use last_col() if we want to take a column to the end.\n\nraw_df %>% select(dt,starts_with(\"sun_\"),starts_with(\"wind\")) %>% relocate(dt,.after=last_col())\n\n# A tibble: 21,168 × 5\n  sun_lic sun_ul wind_lic wind_ul dt                 \n    <dbl>  <dbl>    <dbl>   <dbl> <dttm>             \n1       0 0.0582    1434.    3.78 2020-05-31 23:00:00\n2       0 0.032     1577.    4.84 2020-05-31 22:00:00\n3       0 0.0335    1858.    7.67 2020-05-31 21:00:00\n# … with 21,165 more rows\n\n\nHonestly, relocate is a very convenient function.\n\n2.2.1.1 select/rename advanced usage\nAdvanced usage subsection introduces extra functionality which can be a bit confusing at the first phase. But, once you get a grasp on the fundamentals check back here as reference. There are several features not available for versions before dplyr 1.0.0.\nWe can use rename_with function to rename columns with given criteria. In pipe version of the function, first parameter is the function and the second parameter is the criterion. Let’s replace all “Type” with “_type”. For instance it should change “canalType” to “canal_type”.\n\nraw_df %>% rename_with(~gsub(\"Type\",\"_type\",.),contains(\"Type\")) %>% glimpse()\n\nRows: 21,168\nColumns: 17\n$ dt              <dttm> 2020-05-31 23:00:00, 2020-05-31 22:00:00, 2020-05-31 …\n$ wind_lic        <dbl> 1433.8132, 1577.1419, 1857.5492, 1933.0142, 2031.7862,…\n$ geothermal_lic  <dbl> 912.7882, 907.9303, 900.5844, 888.4561, 864.5402, 847.…\n$ biogas_lic      <dbl> 75.8047, 75.6163, 75.3906, 76.7873, 76.9707, 77.5750, …\n$ canal_type_lic  <dbl> 2584.930, 2630.602, 2585.038, 2542.381, 2594.459, 2622…\n$ river_type_lic  <dbl> 316.5538, 316.6800, 356.7637, 350.1544, 377.5312, 379.…\n$ biomass_lic     <dbl> 262.4994, 253.0814, 246.9268, 249.9152, 248.2336, 246.…\n$ landfillGas_lic <dbl> 100.3971, 101.1378, 100.4442, 100.7307, 102.2474, 102.…\n$ sun_lic         <dbl> 0.0000, 0.0000, 0.0000, 0.0000, 2.0594, 14.2800, 48.09…\n$ reservoir_lic   <dbl> 2306.303, 2296.045, 2279.266, 2308.918, 2792.313, 3180…\n$ others_lic      <dbl> 48.3833, 48.4011, 48.4041, 48.4199, 48.4653, 48.5485, …\n$ wind_ul         <dbl> 3.7751, 4.8375, 7.6659, 11.8121, 13.1070, 13.1830, 10.…\n$ biogas_ul       <dbl> 16.9293, 16.9227, 16.9052, 16.7517, 16.2928, 16.5989, …\n$ canal_type_ul   <dbl> 4.1749, 4.4221, 4.4658, 4.6020, 4.6195, 4.5146, 4.6616…\n$ biomass_ul      <dbl> 15.4698, 15.3609, 16.0483, 15.2271, 15.5563, 15.5007, …\n$ sun_ul          <dbl> 0.0582, 0.0320, 0.0335, 1.3121, 103.3267, 555.5787, 14…\n$ others_ul       <dbl> 0.0610, 0.0395, 0.4136, 0.5508, 0.7106, 1.3775, 2.7468…\n\n\nDid you notice ~ and . in the function? Dot (.) is a representation of the entity. Depending on the situation it can be the latest version of the tibble in the pipe chain, a specific column or something else. ~ is a special character notifying that function evaluation will be done using the dot notation. We will see more examples of that.\nLet’s introduce where. If is a function from tidyselect package to select variables with a function where it returns TRUE. It is quite handy.\n\nraw_df %>% select(dt,starts_with(\"sun_\"),starts_with(\"wind\")) %>% relocate(where(is.numeric))\n\n# A tibble: 21,168 × 5\n  sun_lic sun_ul wind_lic wind_ul dt                 \n    <dbl>  <dbl>    <dbl>   <dbl> <dttm>             \n1       0 0.0582    1434.    3.78 2020-05-31 23:00:00\n2       0 0.032     1577.    4.84 2020-05-31 22:00:00\n3       0 0.0335    1858.    7.67 2020-05-31 21:00:00\n# … with 21,165 more rows\n\n\nWe can also use any_of or all_of functions in select. The main difference is while the former returns as much as it can, the latter will throw an error if any one of the criteria is not fulfilled. Let’s try to select “dt”, “others_lic” and “nuclear_lic”. Since this data does not include nuclear power production we should not see it.\n\nraw_df %>% select(any_of(c(\"dt\",\"others_lic\",\"nuclear_lic\")))\n\n# A tibble: 21,168 × 2\n  dt                  others_lic\n  <dttm>                   <dbl>\n1 2020-05-31 23:00:00       48.4\n2 2020-05-31 22:00:00       48.4\n3 2020-05-31 21:00:00       48.4\n# … with 21,165 more rows\n\n\nIn order not to break our notebook, we wrap it around try (error handling is another topic).\n\ntry(raw_df %>% select(all_of(c(\"dt\",\"others_lic\",\"nuclear_lic\"))))\n\nError : Can't subset columns that don't exist.\n✖ Column `nuclear_lic` doesn't exist.\n\n\n\n\n\n2.2.2 filter/distinct\nFilter (no more “as the name suggests”, as you already figured it out) helps filter rows according to given criteria. It is highly similar with Excel’s filter functionality (but much much more flexible and reliable).\nLet’s see the production at 2020-05-08 16:00:00.\n\nraw_df %>% filter(dt == \"2020-05-08 16:00:00\")\n\n# A tibble: 1 × 17\n  dt                  wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2020-05-08 16:00:00    2618.           856.       79.8         3896.\n# … with 12 more variables: riverType_lic <dbl>, biomass_lic <dbl>,\n#   landfillGas_lic <dbl>, sun_lic <dbl>, reservoir_lic <dbl>,\n#   others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>, canalType_ul <dbl>,\n#   biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>\n\n\nBy using == operator, we bring the values in dt column which are equal to the hour we desired. There are other expressions such as not equal to (!=), greater than (or equal to) (>,>=), smaller than (or equal to) (<,<=), in (%in%) and some more.\nAt the same time we can make comparisons between columns and combine multiple criteria to create more complex filters. Here we use AND (&) and OR (|) operators to combine criteria.\nSuppose we want to find our the times when licensed wind production is greater than all of hydro type licensed production.\n\nraw_df %>% filter(wind_lic > canalType_lic & wind_lic > reservoir_lic & wind_lic > riverType_lic)\n\n# A tibble: 11,287 × 17\n  dt                  wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2020-05-27 19:00:00    3303.           930.       74.7         2969.\n2 2020-05-27 18:00:00    3596.           914.       75.0         2953.\n3 2020-05-27 17:00:00    3551.           900.       76.3         2954.\n# … with 11,284 more rows, and 12 more variables: riverType_lic <dbl>,\n#   biomass_lic <dbl>, landfillGas_lic <dbl>, sun_lic <dbl>,\n#   reservoir_lic <dbl>, others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>,\n#   canalType_ul <dbl>, biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>\n\n\nWe can add numeric operations as well. Suppose we want to find the total solar production is greater than total wind production.\n\nraw_df %>% filter(wind_lic + wind_ul < sun_lic + sun_ul)\n\n# A tibble: 4,949 × 17\n  dt                  wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2020-05-31 16:00:00    2036.           843.       76.8         2616.\n2 2020-05-31 15:00:00    1875.           845.       77.4         2685.\n3 2020-05-31 14:00:00    1755.           853.       77.2         2715.\n# … with 4,946 more rows, and 12 more variables: riverType_lic <dbl>,\n#   biomass_lic <dbl>, landfillGas_lic <dbl>, sun_lic <dbl>,\n#   reservoir_lic <dbl>, others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>,\n#   canalType_ul <dbl>, biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>\n\n\nSuppose we want to filter only the unique values. Then we simply use distinct command. Let’s get unique rounded licensed wind production values.\n\nraw_df %>% distinct(round(wind_lic))\n\n# A tibble: 4,893 × 1\n  `round(wind_lic)`\n              <dbl>\n1              1434\n2              1577\n3              1858\n# … with 4,890 more rows\n\n\nIf we want to keep all columns we simply make the parameter .keep=TRUE.\n\nraw_df %>% distinct(round(wind_lic),.keep=TRUE)\n\n# A tibble: 4,893 × 2\n  `round(wind_lic)` .keep\n              <dbl> <lgl>\n1              1434 TRUE \n2              1577 TRUE \n3              1858 TRUE \n# … with 4,890 more rows\n\n\n\n2.2.2.1 filter/distinct advanced usage\nLet’s introduce slice. This function helps return rows by its row number. Suppose we want the top 5 rows.\n\nraw_df %>% slice(1:5) %>% print(n=5)\n\n# A tibble: 5 × 17\n  dt                  wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2020-05-31 23:00:00    1434.           913.       75.8         2585.\n2 2020-05-31 22:00:00    1577.           908.       75.6         2631.\n3 2020-05-31 21:00:00    1858.           901.       75.4         2585.\n4 2020-05-31 20:00:00    1933.           888.       76.8         2542.\n5 2020-05-31 19:00:00    2032.           865.       77.0         2594.\n# … with 12 more variables: riverType_lic <dbl>, biomass_lic <dbl>,\n#   landfillGas_lic <dbl>, sun_lic <dbl>, reservoir_lic <dbl>,\n#   others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>, canalType_ul <dbl>,\n#   biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>\n\n\nIf we want to return random rows we have slice_sample. Let’s bring 5 random rows.\n\nraw_df %>% slice_sample(n=5)\n\n# A tibble: 5 × 17\n  dt                  wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2019-08-15 13:00:00    2163.           669.       77.6          840.\n2 2018-07-24 13:00:00    1399.           550.       60.8          954.\n3 2018-05-01 08:00:00    1119.           702.       65.2         2004.\n# … with 2 more rows, and 12 more variables: riverType_lic <dbl>,\n#   biomass_lic <dbl>, landfillGas_lic <dbl>, sun_lic <dbl>,\n#   reservoir_lic <dbl>, others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>,\n#   canalType_ul <dbl>, biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>\n\n\nIf we want to do it proportionately, we have the prop parameter. Let’s say we want 0.1% of the data frame.\n\nraw_df %>% slice_sample(prop=0.001)\n\n# A tibble: 21 × 17\n  dt                  wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2018-07-26 15:00:00    1346.           555.       61.3          956.\n2 2020-05-24 20:00:00    2550.           876.       75.7         3080.\n3 2019-04-15 20:00:00    2503.           837.       83.1         4406.\n# … with 18 more rows, and 12 more variables: riverType_lic <dbl>,\n#   biomass_lic <dbl>, landfillGas_lic <dbl>, sun_lic <dbl>,\n#   reservoir_lic <dbl>, others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>,\n#   canalType_ul <dbl>, biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>\n\n\nThere are other slice_* type functions. These are slice_head/slice_tail for first/last n or percentage of rows. slice_min/slice_max for the top/bottom n rows according to an ordering criteria.\n\n\n\n2.2.3 arrange\nArrange sorts rows from A to Z or smallest to largest. It has great similarity with Excel’s Sort functionality.\nLet’s sort licensed reservoir production from largest to smallest.\n\nraw_df %>% select(dt,reservoir_lic) %>% arrange(desc(reservoir_lic))\n\n# A tibble: 21,168 × 2\n  dt                  reservoir_lic\n  <dttm>                      <dbl>\n1 2019-05-10 23:00:00         5058.\n2 2019-05-10 21:00:00         5035.\n3 2019-05-15 02:00:00         5019.\n# … with 21,165 more rows\n\n\nDo you see desc() function inside arrange? By default arrange sorts a column by first to last or A-Z. desc reverses this.\nYou can also use multiple sorting criteria and use operations inside arrange. Let’s arrange by licensed wind production rounded down (floor) in 100s range (e.g. 5634 = 5600 and 5693 = 5600 as well). Then we sort by date time to see the first time the production entered a 100-range in the data time period.\n\nraw_df %>% arrange(desc(floor(wind_lic/100)*100),dt)\n\n# A tibble: 21,168 × 17\n  dt                  wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2019-09-15 17:00:00    5767.           691.       83.0          922.\n2 2018-09-26 19:00:00    5622.           672.       67.8          951.\n3 2019-09-15 15:00:00    5628.           692.       81.4          901.\n# … with 21,165 more rows, and 12 more variables: riverType_lic <dbl>,\n#   biomass_lic <dbl>, landfillGas_lic <dbl>, sun_lic <dbl>,\n#   reservoir_lic <dbl>, others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>,\n#   canalType_ul <dbl>, biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>\n\n\n\n\n2.2.4 mutate/transmute\nMutate is the function when we do operations and calculations using other columns.\nFor instance let’s calculate wind power’s share in total renewables production at each hour.\n\nraw_df %>% mutate(wind_lic_perc = wind_lic / (wind_lic + geothermal_lic + biogas_lic + canalType_lic + riverType_lic + biomass_lic + landfillGas_lic + sun_lic + reservoir_lic + others_lic + wind_ul + biogas_ul + canalType_ul + biomass_ul + sun_ul + others_ul)) %>% select(dt, wind_lic_perc)\n\n# A tibble: 21,168 × 2\n  dt                  wind_lic_perc\n  <dttm>                      <dbl>\n1 2020-05-31 23:00:00         0.177\n2 2020-05-31 22:00:00         0.191\n3 2020-05-31 21:00:00         0.219\n# … with 21,165 more rows\n\n\nYou can use many R functions (from both base functions and other packages). For instance to calculate “competition” wind and solar we can use the following expression.\n\nraw_df %>% mutate(wind_or_solar = ifelse(wind_lic + wind_ul > sun_lic + sun_ul, \"wind\", \"solar\")) %>% select(dt,wind_or_solar)\n\n# A tibble: 21,168 × 2\n  dt                  wind_or_solar\n  <dttm>              <chr>        \n1 2020-05-31 23:00:00 wind         \n2 2020-05-31 22:00:00 wind         \n3 2020-05-31 21:00:00 wind         \n# … with 21,165 more rows\n\n\nTransmute has the same functionality as mutate with the additional property similar to select. Transmute returns only the columns included in the function. Suppose we also want to calculate the difference between total wind and total solar.\n\nraw_df %>% transmute(dt, wind_or_solar = ifelse(wind_lic + wind_ul > sun_lic + sun_ul, \"wind\", \"solar\"), absdiff = abs(wind_lic + wind_ul - sun_lic - sun_ul))\n\n# A tibble: 21,168 × 3\n  dt                  wind_or_solar absdiff\n  <dttm>              <chr>           <dbl>\n1 2020-05-31 23:00:00 wind            1438.\n2 2020-05-31 22:00:00 wind            1582.\n3 2020-05-31 21:00:00 wind            1865.\n# … with 21,165 more rows\n\n\n\n2.2.4.1 mutate/transmute advanced usage\nSuppose we want to see the difference between the previous and next hour’s production. We offset rows using lead and lag functions. But remember lead and lag does not actually give you “next/previous hour’s” values, just the rows. You may need to arrange your data.\n\nraw_df %>% transmute(dt, wind_lic, wind_lic_prev_h = lead(wind_lic,1), wind_lic_next_h = lag(wind_lic,1))\n\n# A tibble: 21,168 × 4\n  dt                  wind_lic wind_lic_prev_h wind_lic_next_h\n  <dttm>                 <dbl>           <dbl>           <dbl>\n1 2020-05-31 23:00:00    1434.           1577.             NA \n2 2020-05-31 22:00:00    1577.           1858.           1434.\n3 2020-05-31 21:00:00    1858.           1933.           1577.\n# … with 21,165 more rows\n\n\nIf you want to use the same function over several columns, you can use the new across function. Let’s round every numeric column to one significant digit.\n\nraw_df %>% mutate(across(where(is.numeric),~round(.,1)))\n\n# A tibble: 21,168 × 17\n  dt                  wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2020-05-31 23:00:00    1434.           913.       75.8         2585.\n2 2020-05-31 22:00:00    1577.           908.       75.6         2631.\n3 2020-05-31 21:00:00    1858.           901.       75.4         2585 \n# … with 21,165 more rows, and 12 more variables: riverType_lic <dbl>,\n#   biomass_lic <dbl>, landfillGas_lic <dbl>, sun_lic <dbl>,\n#   reservoir_lic <dbl>, others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>,\n#   canalType_ul <dbl>, biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>\n\n\nWe can also specify columns. Let’s see the comparative production of wind and reservoir hydro against the unlicensed solar production. We just increment solar production by 1 to prevent any infinity values.\n\nraw_df %>% mutate(sun_ul = sun_ul + 1) %>% transmute(dt,across(c(wind_lic,reservoir_lic),~round(./sun_ul,2)))\n\n# A tibble: 21,168 × 3\n  dt                  wind_lic reservoir_lic\n  <dttm>                 <dbl>         <dbl>\n1 2020-05-31 23:00:00    1355.         2179.\n2 2020-05-31 22:00:00    1528.         2225.\n3 2020-05-31 21:00:00    1797.         2205.\n# … with 21,165 more rows\n\n\nIf there are multiple conditions ifelse is not enough. It is possible to use case_when to specify multiple conditions and outcomes.\n\nraw_df %>% transmute(dt, solar_production_level = case_when(sun_ul > quantile(sun_ul,0.9) ~ \"very high\", sun_ul > quantile(sun_ul, 0.75) ~ \"high\", sun_ul > quantile(sun_ul, 0.5) ~ \"above median\", TRUE ~ \"below median\"))  %>% slice(7:9)\n\n# A tibble: 3 × 2\n  dt                  solar_production_level\n  <dttm>              <chr>                 \n1 2020-05-31 17:00:00 above median          \n2 2020-05-31 16:00:00 high                  \n3 2020-05-31 15:00:00 very high             \n\n\nrowwise is actually a type of group_by/summarise function but as the name suggests it allows us to do row-wise operations. Let’s calculate row sums by using c_across function and rowwise. Oh and also now, experimentally, you can use relocate functionality in mutate/transmute. So, conveniently we can place it after date time.\n\nraw_df %>% slice_head(n=5) %>% rowwise() %>% mutate(total_prod = sum(c_across(where(is.numeric))),.after=dt)\n\n# A tibble: 5 × 18\n# Rowwise: \n  dt                  total_prod wind_lic geothermal_lic biogas_lic\n  <dttm>                   <dbl>    <dbl>          <dbl>      <dbl>\n1 2020-05-31 23:00:00      8082.    1434.           913.       75.8\n2 2020-05-31 22:00:00      8248.    1577.           908.       75.6\n3 2020-05-31 21:00:00      8496.    1858.           901.       75.4\n# … with 2 more rows, and 13 more variables: canalType_lic <dbl>,\n#   riverType_lic <dbl>, biomass_lic <dbl>, landfillGas_lic <dbl>,\n#   sun_lic <dbl>, reservoir_lic <dbl>, others_lic <dbl>, wind_ul <dbl>,\n#   biogas_ul <dbl>, canalType_ul <dbl>, biomass_ul <dbl>, sun_ul <dbl>,\n#   others_ul <dbl>\n\n\n\n\n\n2.2.5 group_by/summarise\nFinally we will learn how to calculate summary tables. It is similar to Pivot Tables in Excel. group_by is the grouping function, summarise is the summarising function.\nFor instance let’s calculate number of hours where wind production is above 3000 MWh. We will use a special function n() to calculate number of rows. We can define groupings just like mutate.\n\nraw_df %>% group_by(production_group = cut(wind_lic + wind_ul,breaks=c(0,1000,2000,3000,4000,5000,6000),include.lowest = TRUE)) %>% summarise(count = n())\n\n# A tibble: 6 × 2\n  production_group count\n  <fct>            <int>\n1 [0,1e+03]         4294\n2 (1e+03,2e+03]     5733\n3 (2e+03,3e+03]     4725\n# … with 3 more rows\n\n\nNormally, we get one result for each group and summary function. From dplyr 1.0.0 we can have multiple row summarise for each group. Let’s say we want to find the minimum and maximum licensed wind production ranges for each year. But, be warned, it can be a little confusing.\n\nraw_df %>% group_by(year = lubridate::year(dt)) %>% summarise(wind_lic_range = range(wind_lic))\n\n`summarise()` has grouped output by 'year'. You can override using the `.groups` argument.\n\n\n# A tibble: 6 × 2\n# Groups:   year [3]\n   year wind_lic_range\n  <dbl>          <dbl>\n1  2018           46.2\n2  2018         5622. \n3  2019           32.8\n# … with 3 more rows\n\n\n\n2.2.5.1 group_by/summarise advanced usage\nJust like mutate/transmute you can use across in summarise as well. Let’s see median production of each year and each source. In this example we can also use the named list version of the functions and additional names structure.\n\nraw_df %>% group_by(year = lubridate::year(dt)) %>% summarise(across(where(is.numeric),list(med=median),.names=\"{fn}_{col}\"))\n\n# A tibble: 3 × 17\n   year med_wind_lic med_geothermal_lic med_biogas_lic med_canalType_lic\n  <dbl>        <dbl>              <dbl>          <dbl>             <dbl>\n1  2018        1989.               694.           66.4             1480.\n2  2019        2136.               814.           80.9             1575.\n3  2020        2297.               951.           78.5             2779.\n# … with 12 more variables: med_riverType_lic <dbl>, med_biomass_lic <dbl>,\n#   med_landfillGas_lic <dbl>, med_sun_lic <dbl>, med_reservoir_lic <dbl>,\n#   med_others_lic <dbl>, med_wind_ul <dbl>, med_biogas_ul <dbl>,\n#   med_canalType_ul <dbl>, med_biomass_ul <dbl>, med_sun_ul <dbl>,\n#   med_others_ul <dbl>"
  },
  {
    "objectID": "dplyr.html#exercises",
    "href": "dplyr.html#exercises",
    "title": "2  dplyr",
    "section": "2.3 Exercises",
    "text": "2.3 Exercises\nSolve the following exercises. Outputs are given below, you are expected write code to match the outputs.\n\nFind the mean and standard deviation of licensed geothermal productions in all years. (Tip: Use lubridate::year to get years from date data.)\n\n\n\n# A tibble: 3 × 3\n   year mean_geo sd_geo\n  <dbl>    <dbl>  <dbl>\n1  2018     681.   65.2\n2  2019     799.   74.2\n3  2020     935.   59.0\n\n\n\nFind the hourly average unlicensed solar (sun_ul) production levels for May 2020.\n\n\n\n# A tibble: 24 × 2\n   hour avg_prod\n  <int>    <dbl>\n1     0     0.17\n2     1     0.37\n3     2     0.7 \n# … with 21 more rows\n\n\n\nFind the average daily percentage change of licensed biomass (biomass_lic) in 2019. (e.g. Suppose daily production is 50 in day 1 and 53 in day 2, then the change should be (53-50)/50 -1 = 0.06) (Tip: Use lubridate::as_date to convert date time to date. Use lag and lead functions to offset values.)\n\n\n\n# A tibble: 1 × 1\n  average_change\n           <dbl>\n1        0.00282\n\n\n\nFind the yearly total production levels in TWh (Current values are in MWh. 1 GWh is 1000 MWh and 1 TWh is 1000 GWh). (Tip: In order to avoid a lengthy summation you can use tidyr::pivot_longer to get a long format.)\n\n\n\n# A tibble: 3 × 2\n   year total_production\n  <dbl>            <dbl>\n1  2018             62.6\n2  2019             76.7\n3  2020             37.3"
  },
  {
    "objectID": "dplyr.html#conclusion",
    "href": "dplyr.html#conclusion",
    "title": "2  dplyr",
    "section": "2.4 Conclusion",
    "text": "2.4 Conclusion\nFundamental dplyr functions provide very convenient tools for data analysis. It can also be used to generate the features required for modelling. You can process few million rows of data without breaking a sweat (for larger data sets you can use data.table), you can prepare functions instead of manual Excel operations. With R Markdown system, which this tutorial is prepared in, you can create reproducible documents and automatize the reports. You can use ggplot2 for visualizations, which is also part of the tidyverse package ecosystem."
  },
  {
    "objectID": "dplyr.html#appendix",
    "href": "dplyr.html#appendix",
    "title": "2  dplyr",
    "section": "2.5 Appendix",
    "text": "2.5 Appendix\n\n2.5.1 Mini lubridate tutorial\nIn this tutorial we use a small portion of a very powerful package, lubridate. You can see the official website here.\nLet’s take just 3 dates at random from our data set.\n\nset.seed(5)\nlub_df <- \nraw_df %>% \n  select(dt) %>%\n  sample_n(3)\n\nprint(lub_df)\n\n# A tibble: 3 × 1\n  dt                 \n  <dttm>             \n1 2018-12-02 06:00:00\n2 2019-01-12 05:00:00\n3 2018-04-16 09:00:00\n\n\nSince we called lubridate at the beginning of this tutorial we do not need to call by package reference (lubridate::) but it is generally good practice.\n\nlub_df %>% \n  mutate(\n    year = lubridate::year(dt),\n    month = lubridate::month(dt),\n    day = lubridate::day(dt),\n    week_day = lubridate::wday(dt),\n    wday_label = lubridate::wday(dt,label=TRUE),\n    hour = lubridate::hour(dt),\n    minute = lubridate::minute(dt),\n    second = lubridate::second(dt)\n  )\n\n# A tibble: 3 × 9\n  dt                   year month   day week_day wday_label  hour minute second\n  <dttm>              <dbl> <dbl> <int>    <dbl> <ord>      <int>  <int>  <dbl>\n1 2018-12-02 06:00:00  2018    12     2        1 Sun            6      0      0\n2 2019-01-12 05:00:00  2019     1    12        7 Sat            5      0      0\n3 2018-04-16 09:00:00  2018     4    16        2 Mon            9      0      0"
  },
  {
    "objectID": "dplyr.html#references",
    "href": "dplyr.html#references",
    "title": "2  dplyr",
    "section": "2.6 References",
    "text": "2.6 References\n\nData Set: EPIAS/EXIST Transparency Platform\nTidyverse: https://www.tidyverse.org/\nR for Data Science: https://r4ds.had.co.nz/\nCheatsheet (Data Transformation) (Turkish Version)"
  },
  {
    "objectID": "reticulate.html",
    "href": "reticulate.html",
    "title": "Using Python and R Together",
    "section": "",
    "text": "In the ever-increasing requirements era of data science, Python is one of the fundamental tools that a data scientist should know about. Even though R is quite elegant and enough in many data related applications, a mix of Python might also be required to get the job done. One of the reasons is to benefit from API connections because Python enjoys first class support (e.g. native SDK) in many services. For instance, using boto3 package for AWS was quite useful (before the paws R package).\nRStudio especially positions itself as “A Single Home for R and Python Data Science” in their blog post. It is also the main reason why they created and support the reticulate R package. Before reticulate, Python integration was still possible but much more difficult in many aspects. It still might have quirks but reticulate provides much better integration.\nIn this tutorial, we are going to do simple examples using reticulate package. This tutorial is not exhaustive. For better coverage, check the official package page."
  },
  {
    "objectID": "reticulate.html#initialization",
    "href": "reticulate.html#initialization",
    "title": "Using Python and R Together",
    "section": "Initialization",
    "text": "Initialization\nIt always starts with the loading of the package.\n\nlibrary(reticulate)\n\nPython has multiple versions (thankfully they phased out Python 2 but still a pain in many operating systems) You can learn the current python version PATH using Sys.which function. Output will differ in different systems and installations.\n\nSys.which(\"python\")\n\n                                            python \n\"/opt/homebrew/Caskroom/miniforge/base/bin/python\" \n\n\nFor better detail, py_config is a good function. Output will differ in different systems and installations.\n\npy_config()\n\npython:         /opt/homebrew/Caskroom/miniforge/base/bin/python3\nlibpython:      /opt/homebrew/Caskroom/miniforge/base/lib/libpython3.9.dylib\npythonhome:     /opt/homebrew/Caskroom/miniforge/base:/opt/homebrew/Caskroom/miniforge/base\nversion:        3.9.10 | packaged by conda-forge | (main, Feb  1 2022, 21:27:43)  [Clang 11.1.0 ]\nnumpy:          /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/numpy\nnumpy_version:  1.22.4\n\npython versions found: \n /opt/homebrew/Caskroom/miniforge/base/bin/python3\n /opt/homebrew/Caskroom/miniforge/base/bin/python\n\n\nFor available configurations py_discover_config can be used.\n\npy_discover_config()\n\nreticulate can use other python installations, virtual environments and conda versions. Although it is a great convenience, intricacies and delicateness of Python versions might still hurt your workflows.\n\nuse_python() ## python path\nuse_virtualenv() ## virtual environment name\nuse_condaenv() ## conda environment"
  },
  {
    "objectID": "reticulate.html#methods-and-examples",
    "href": "reticulate.html#methods-and-examples",
    "title": "Using Python and R Together",
    "section": "Methods and Examples",
    "text": "Methods and Examples\nIn this section we will see some methodologies to use with reticulate.\n\nCall Python functions R style\nThis is the fundamental and (in my opinion) worst way to benefit from Python in R. Because translation of style is imperfect and might not work in every case.\nHere is an example with pandas.\n\n## similar to import pandas as pd\npd <- import(\"pandas\") \n## create a simple dataframe \ndf_pandas <- pd$DataFrame(data=list(col1=c(2,1,3),col2=c(\"a\",\"b\",\"c\"))) \n\ndf_pandas\n\n  col1 col2\n1    2    a\n2    1    b\n3    3    c\n\n\nLet’s try a simple example.\n\nos <- import(\"os\")\nos$path$join(\"a\",\"b\",\"c\")\n\n[1] \"a/b/c\"\n\n\nCaveats: Some functions working on console might not work on RMarkdown\n\ntry(df_pandas$sort_values(\"col1\"))\n\nError in try(df_pandas$sort_values(\"col1\")) : \n  attempt to apply non-function\n\n\n\n## filter using query fails both on console and rmarkdown\ntry(df_pandas$query('col1 > 1.0'))\n\nError in try(df_pandas$query(\"col1 > 1.0\")) : \n  attempt to apply non-function\n\n\n\n\nCall Python in RMarkdown chunk\nThe format is similar to an R chunk but instead of r write python.\n\n\n```{python}\n#your python code here\n```\n\n\nHere is an example\n\nimport os\nos.path.join(\"a\",\"b\",\"c\")\n\n'a/b/c'\n\n\nOur pandas examples also works in this case.\n\nimport pandas as pd\n\npandas_df_py = pd.DataFrame(data={'col1':[2,1,3],'col2':['a','b','c']}) \n\npandas_df_py\n\n   col1 col2\n0     2    a\n1     1    b\n2     3    c\n\n\n\npandas_df_py.sort_values('col1')\n\n   col1 col2\n1     1    b\n0     2    a\n2     3    c\n\n\n\n## filter using query fails both on console and rmarkdown\npandas_df_py.query('col1 > 1.0')\n\n   col1 col2\n0     2    a\n2     3    c\n\n\n\n\nSource Python Script\nPersonally, the most convenient way to use Python code is to source a .py file. Even though interoperability is a great idea, keeping Python and R codes as separate as possible will save you from a lot of headache in the future (at least with the current implementation).\nWe can source any python file using source_python() function easily. Let’s name our python file triangle.py and write the following.\n\ndef area_of_triangle(h,x):\n  return h*x/2\n\n\narea_of_triangle(3,5)\n\n7.5\n\n\nFollow\n\nreticulate::source_python(\"triangle.py\") ### Remember to provide proper relative or absolute path.\n\nNote: For RMarkdown demonstration purposes below we;\n\ncreated a temporary file\nwrote our python function to that file using cat\nthen executed source_python\nthen called the function as R function\n\n\npyfile <- tempfile(fileext=\".py\")\ncat('def area_of_triangle(h,x):\n  return h*x/2',file=pyfile)\nsource_python(pyfile)\n\narea_of_triangle(3,5)\n\n[1] 7.5\n\n\nBut deep down it is a Python function.\n\nprint(area_of_triangle)\n\n<function area_of_triangle at 0x13eb463a0>\n\n\n\n\nConclusion\nTo be honest Python versioning is a mess. Lots of parallel versions (even python2 version issues are still looming) and conflicts in different layers of computing might be troublesome especially in Docker settings. Therefore it is highly recommended to add Python code to your R code if it is totally necessary.\nThough it is always a good thing to have an exquisite tool if you need to use Python and cannot separate processes. reticulate is currently that tool."
  },
  {
    "objectID": "basics.html",
    "href": "basics.html",
    "title": "Fundamentals",
    "section": "",
    "text": "Data Manipulation: Taking raw data and creating analyses.\nData Visualization: Visualizing findings from the data.\nReporting: Combining all the findings into a single cohesive report.\nInteractive Reporting (Dashboards): Self-exploring analyses and outcomes.\n\nTo achieve these skills following fundamental R packages are used.\n\ndplyr for data manipulation\nggplot2 for data visualization\nquarto for reporting (alternatively use rmarkdown)\nshiny for interactive dashboarding\n\nFollowing sections provide guidance and examples on these packages in the context of Exploratory Data Analysis. There are many extensions and further packages to consider. However, in order for Fundamentals chapter to stay “fundamental” these topics are moved to Advanced chapter."
  },
  {
    "objectID": "advanced.html",
    "href": "advanced.html",
    "title": "Advanced",
    "section": "",
    "text": "See Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "ggplot2.html",
    "href": "ggplot2.html",
    "title": "3  ggplot2",
    "section": "",
    "text": "raw_df <- readRDS(\"rp_201801_202005_df.rds\")"
  },
  {
    "objectID": "ggplot2.html#scatterplot",
    "href": "ggplot2.html#scatterplot",
    "title": "3  ggplot2",
    "section": "3.2 Scatterplot",
    "text": "3.2 Scatterplot\nFirst let’s preprocess our data to get production in May 2020 and hours between 10:00 AM and 5:00 PM.\n\nplot_df1 <- \n  raw_df %>% \n    filter(dt >= \"2020-05-01\" & dt < \"2020-06-01\" & lubridate::hour(dt) >= 10 & lubridate::hour(dt) <= 17) %>%   transmute(hour_of_day = lubridate::hour(dt),wind_lic,sun_ul)\n\nprint(plot_df1,n=3)\n\n# A tibble: 248 × 3\n  hour_of_day wind_lic sun_ul\n        <int>    <dbl>  <dbl>\n1          17    2055.  1442.\n2          16    2036.  2523.\n3          15    1875.  3402.\n# … with 245 more rows\n\n\nLet’s plot licensed wind production against unlicensed solar production for May 2020 for hours between 10-17. We can say that\n\nUsually during morning time solar production is high and wind production is kind of low.\nExpectedly solar production is decreasing in the afternoon\n\n\nggplot(plot_df1, aes(x = wind_lic, y = sun_ul, color = as.character(hour_of_day))) + geom_point()\n\n\n\n\nggplot2 is quite flexible. We can move aes from ggplot object to geom_point object.\n\nggplot(plot_df1) + geom_point(aes(x = wind_lic, y = sun_ul, color = as.character(hour_of_day)))"
  },
  {
    "objectID": "ggplot2.html#line-chart",
    "href": "ggplot2.html#line-chart",
    "title": "3  ggplot2",
    "section": "3.3 Line Chart",
    "text": "3.3 Line Chart\nHere I want to compare wind and solar production in a time series plot.\n\nplot_df2 <- raw_df %>% filter(dt >= \"2020-05-01\" & dt < \"2020-06-01\") %>% select(dt,wind_lic,sun_ul) \n\nprint(plot_df2,n=3)\n\n# A tibble: 744 × 3\n  dt                  wind_lic sun_ul\n  <dttm>                 <dbl>  <dbl>\n1 2020-05-31 23:00:00    1434. 0.0582\n2 2020-05-31 22:00:00    1577. 0.032 \n3 2020-05-31 21:00:00    1858. 0.0335\n# … with 741 more rows\n\n\n\nggplot(plot_df2) + \n  geom_line(aes(x=dt,y=wind_lic,color=\"wind\")) + \n  geom_line(aes(x=dt,y=sun_ul,color=\"solar\"))\n\n\n\n\nWhat if I don’t want to repeat geom_line functions? I can use pivot_longer function to get all in a single geom_line.\n\nggplot(plot_df2 %>% pivot_longer(.,cols=-dt),aes(x=dt,y=value,color=name)) + geom_line()"
  },
  {
    "objectID": "ggplot2.html#bar-chart",
    "href": "ggplot2.html#bar-chart",
    "title": "3  ggplot2",
    "section": "3.4 Bar Chart",
    "text": "3.4 Bar Chart\nNow I’d like to get the May 2020 production and I’d like to differentiate Licensed and Unlicensed.\n\nplot_df3 <- raw_df %>% filter(dt >= \"2020-05-01\" & dt < \"2020-06-01\") %>% summarise(across(-dt,sum)) %>% pivot_longer(.,everything()) %>% mutate(type = ifelse( grepl(\"_lic+$\",name),\"Licensed\",\"Unlicensed\"))\n\nprint(plot_df3,n=3)\n\n# A tibble: 16 × 3\n  name              value type    \n  <chr>             <dbl> <chr>   \n1 wind_lic       1346260. Licensed\n2 geothermal_lic  654089. Licensed\n3 biogas_lic       56839. Licensed\n# … with 13 more rows\n\n\nLet’s plot total productions using a bar chart. To improve readability, we reorder by production and differentiate Licensed/Unlicensed using color.\n\nggplot(plot_df3,aes(x=reorder(name,-value),y=value,fill=type)) + geom_bar(stat = \"identity\") + theme(axis.text.x = element_text(angle=60,vjust=1,hjust=1))"
  },
  {
    "objectID": "ggplot2.html#pie-chart",
    "href": "ggplot2.html#pie-chart",
    "title": "3  ggplot2",
    "section": "3.5 Pie Chart",
    "text": "3.5 Pie Chart\n\nggplot(plot_df3 %>% filter(type==\"Licensed\"),aes(x=\"\",y=value,fill=name)) + geom_bar(stat=\"identity\") + coord_polar(\"y\")"
  },
  {
    "objectID": "ggplot2.html#theming-and-customization",
    "href": "ggplot2.html#theming-and-customization",
    "title": "3  ggplot2",
    "section": "3.6 Theming and Customization",
    "text": "3.6 Theming and Customization\nLet’s get our charts better looks!\n\nsc_plot <- ggplot(plot_df1) + geom_point(aes(x = wind_lic, y = sun_ul, color=as.character(hour_of_day)))\n\nsc_plot\n\n\n\n\n\nsc_plot2 <- sc_plot + theme_minimal()\nsc_plot2\n\n\n\n\n\nsc_plot3 <-\nsc_plot2 + labs(x=\"Licensed Wind Production (MWh)\", y=\"Unlicensed Solar Production (MWh)\", color=\"Hour of Day\", title = \"Licensed Wind vs Unlicensed Solar\", subtitle = \"Renewable production in May 2020, between 10:00-17:00 each day\") \n\nsc_plot3\n\n\n\n\n\nsc_plot3 + theme(legend.position = \"top\",axis.text.x = element_text(angle=45,hjust=1,vjust=1)) + scale_y_continuous(labels=function(x) format(x, big.mark = \".\", decimal.mark = \",\", scientific = FALSE)) + scale_x_continuous(labels=function(x) format(x, big.mark = \".\", decimal.mark = \",\", scientific = FALSE))"
  },
  {
    "objectID": "base-r.html",
    "href": "base-r.html",
    "title": "1  Base R",
    "section": "",
    "text": "Created by Ross Ithaka and Robert Gentlemen of University of Auckland in 1993. It was derived from commercial S programming language (no kidding) which was created in 1976.\nVersion 1.0.0 is released in 2000. Current version is 4.1.1.\nIn 2017, CRAN (official package manager) had more than 10,000 packages. Today it has 18,214 packages on CRAN.\nRanked as the 9th most popular language in TIOBE index as of September 2021.\n\n\n\n\nhttps://blog.revolutionanalytics.com/2020/07/the-history-of-r-updated-for-2020.html\nhttps://en.wikipedia.org/wiki/R_(programming_language)\nhttps://bookdown.org/rdpeng/rprogdatascience/history-and-overview-of-r.html\nhttps://cran.r-project.org/web/packages/\nhttps://www.tiobe.com/tiobe-index/"
  },
  {
    "objectID": "base-r.html#what-is-there-to-like-r",
    "href": "base-r.html#what-is-there-to-like-r",
    "title": "1  Base R",
    "section": "1.2 What is there to like R?",
    "text": "1.2 What is there to like R?\n(Personal opinions)\n\nOne of the two most powerful scripting languages in data analysis with Python. (Julia, first released in 2012, is an emerging third.)\nSyntax and style focused on more non-computer scientists. (Especially tidyverse)\nExcellently curated and managed package manager (CRAN).\nA powerhouse focused on data analytics. Many packages include implementations of novel research papers which cannot be found elsewhere.\nSupported by a powerful IDE (RStudio).\nLow learning curve for data analysis, visualization, publishing and interactive analysis.\n\nNote: Python and R are not competitors. In many cases they complement each other. It is highly recommended to learn both."
  },
  {
    "objectID": "base-r.html#what-are-the-disadvantages-of-r",
    "href": "base-r.html#what-are-the-disadvantages-of-r",
    "title": "1  Base R",
    "section": "1.3 What are the disadvantages of R?",
    "text": "1.3 What are the disadvantages of R?\n\nNot quite popular as Python in CS community. Support is lagging behind in some areas (especially in cloud computing) compared to Python.\nDespite a very convenient web framework (shiny), not greatly suited for scalable web applications without heavy modifications. (Still a great start)\nParallel computing is not native in R. So, speed can be an issue.\nR keeps data in-memory.\n\nEach disadvantage can be alleviated using a package or a solution. Its benefits far outweigh its disadvantages.\nclass: inverse, center, middle"
  },
  {
    "objectID": "base-r.html#foundations",
    "href": "base-r.html#foundations",
    "title": "2  Base R",
    "section": "2.4 Foundations",
    "text": "2.4 Foundations"
  },
  {
    "objectID": "base-r.html#basic-features",
    "href": "base-r.html#basic-features",
    "title": "1  Base R",
    "section": "1.4 Basic Features",
    "text": "1.4 Basic Features\n\nR is a vector based language. When you call a function or do an operation, it is usually done for every member of the vector. (It is a powerful feature which requires some time to learn.)\nMain data types are numeric, character and logical. But factor, integer, date, dttm (date-time) and some other types are also very common.\nMain object types are vector, matrix, data.frame and list.\nAssignment operators are “<-” and “=”. Aside from rare exceptions, they are the same (x <- 5 is the same as x = 5). Please be consistent in its use.\n\n\nx <- 5\nx\n\n[1] 5\n\n\n\nR console is completely interactive. You can run anything line by line."
  },
  {
    "objectID": "base-r.html#data-types",
    "href": "base-r.html#data-types",
    "title": "1  Base R",
    "section": "1.5 Data Types",
    "text": "1.5 Data Types\n\nNumeric (double): 1.33, 5422.22…\n\nThere is also integer: 3, 5, 6…\n\nCharacter (character): “a”, “course”, “pizza”…\nBoolean (logical): Either TRUE or FALSE.\nDate (date) and date-time (dttm): “2020-07-28”, “2020-07-29 14:00:05.12 UTC+3”\n\nThis part is a bit complicated with POSIXct and POSIXt types.\n\nFactor (factor): Numeric levels with labels of any kind.\n\nEncountered rarely in this course."
  },
  {
    "objectID": "base-r.html#object-types---vector",
    "href": "base-r.html#object-types---vector",
    "title": "2  Base R",
    "section": "2.6 Object Types - Vector",
    "text": "2.6 Object Types - Vector\nVector is the foundation stone of R object types. A variable with a single value is called “atomic” vector.\nVectors with multiple values can be defined using c() (“combine”) function.\n\nx <- c(\"a\",\"b\",\"c\")\nx\n\n[1] \"a\" \"b\" \"c\"\n\n\nA vector can have only a single data type. R conveniently converts vectors to the most appropriate data type.\n\nx <- c(1,\"hi\",FALSE) ## Vector of numeric, character and logical values\nx ## converted to all character\n\n[1] \"1\"     \"hi\"    \"FALSE\""
  },
  {
    "objectID": "base-r.html#object-types---matrix",
    "href": "base-r.html#object-types---matrix",
    "title": "2  Base R",
    "section": "2.7 Object Types - Matrix",
    "text": "2.7 Object Types - Matrix\nMatrix is simply a two dimensional special vector.\n\nmat1<-matrix(1:9, ncol=3, nrow=3)\nmat1\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9\n\n\nWe can get a value from a matrix by providing its location as row/column coordinates or by simply by treating it as a vector.\n\nmat1[2,2]\n\n[1] 5\n\nmat1[5]\n\n[1] 5"
  },
  {
    "objectID": "base-r.html#object-types---data-frame",
    "href": "base-r.html#object-types---data-frame",
    "title": "2  Base R",
    "section": "2.8 Object Types - Data Frame",
    "text": "2.8 Object Types - Data Frame\nData frame object type is still two dimensional but each column can be of a different data type.\n\ndf1 <- data.frame(some_numbers=1:3,\n                  some_names=c(\"Blood\",\"Sweat\",\"Tears\"),\n                  some_logical=c(TRUE,FALSE,TRUE))\ndf1\n\n  some_numbers some_names some_logical\n1            1      Blood         TRUE\n2            2      Sweat        FALSE\n3            3      Tears         TRUE\n\n\nData frames are extremely powerful structures. Most of our work will be on data frames.\nNote: In dplyr package we will see a special version of data frames: tibble."
  },
  {
    "objectID": "base-r.html#object-types---list",
    "href": "base-r.html#object-types---list",
    "title": "2  Base R",
    "section": "2.9 Object Types - List",
    "text": "2.9 Object Types - List\nLists are like vectors but they can hold any object (including lists). You can also add names to lists.\n\nlist1 <- list(data_frame = df1,matrix = mat1,vector= x)\nlist1\n\n$data_frame\n  some_numbers some_names some_logical\n1            1      Blood         TRUE\n2            2      Sweat        FALSE\n3            3      Tears         TRUE\n\n$matrix\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9\n\n$vector\n[1] \"1\"     \"hi\"    \"FALSE\""
  },
  {
    "objectID": "base-r.html#object-types---functions",
    "href": "base-r.html#object-types---functions",
    "title": "2  Base R",
    "section": "2.10 Object Types - Functions",
    "text": "2.10 Object Types - Functions\nFunctions are very useful types as they allow to run reusable code with dynamic inputs. For example, let’s write a function to calculate the area of a triangle.\n\narea_of_triangle <- function(height,base_length){\n  area <- height*base_length/2\n  return(area) ## Return value using return command\n}\n## You can assign the result of a function to a variable\nx <- area_of_triangle(height = 3, base_length = 4) \nx\n\n[1] 6\n\n\n\nRule of thumb is “If you need to copy paste the same code three times, write a function instead.”\nR has thousands of predefined functions to make life easier.\nIf you want to return multiple values return a list.\n\nclass: center, middle, inverse"
  },
  {
    "objectID": "base-r.html#exercises",
    "href": "base-r.html#exercises",
    "title": "1  Base R",
    "section": "1.7 Exercises",
    "text": "1.7 Exercises\nComplete base R document before attempting to solve these.\n\n1.7.1 Temperature Conversion\nWrite a function to convert Fahrenheit to Celsius and Celsius to Fahrenheit.\n(X°C × 9/5) + 32 = Y°F\n\nconvert_temperature <- function(x, F_to_C = TRUE){\n  if(F_to_C){\n    return((x-32)*5/9)\n  }else{\n    return(x*9/5 + 32)\n  }\n}\n\n\nconvert_temperature(30,F_to_C = FALSE)\n\n[1] 86\n\nconvert_temperature(86,F_to_C = TRUE)\n\n[1] 30\n\n\n\n1.7.1.1 Future Value\nWrite a function to calculate the future value of an investment given annually compounding interest over an amount of years.\n\\[FV = X * (1 + i) ^T\\]\n\ncalculate_future_value <- \nfunction(investment, interest, duration_in_years){\n  return(investment * ((1 + interest) ^ duration_in_years)) \n}\n\n\n## 100 units of investments 7% interest rate over 5 years\ncalculate_future_value(\n  investment = 100, interest = 0.07, duration_in_years = 5)\n\n[1] 140.2552\n\n\n\n\n\n1.7.2 Color Hex Code\nWrite a function to randomly generate n color hex codes. You can use letters predefined vector.\n\ngenerate_hex_code <- function(n=1){\n  hex_vec <- c(0:9,letters[1:6])\n  colors <- c()\n  for(i in 1:n){\n    colors <- c(colors,\n      paste0(\"#\",\n      paste0(sample(hex_vec,6,replace=TRUE),collapse=\"\")))\n  }\n  return(colors)\n}\n\n\ngenerate_hex_code(n=3)\n\n[1] \"#8c4e65\" \"#d0ed34\" \"#b756a6\"\n\n\n\n\n1.7.3 Calculate Probability of Dice\nWrite a function which calculates the probability of getting k sixes in n throws of a die. Hint: Use binomial distribution.\n\nget_prob_dice <- function(k,n){\n  combination <- factorial(n)/(factorial(k) * factorial(n-k))\n  probability <- (1/6)^k * (5/6)^(n-k)\n  return(combination*probability)\n}\n\n\nget_prob_dice(3,5)\n\n[1] 0.03215021\n\n\n\ndbinom(3,5,prob=1/6) ## or simply use dbinom\n\n[1] 0.03215021\n\n\n\n\n1.7.4 Rock, Scissors, Paper\nWrite a rock scissors paper game which computer randomly chooses\n\nrsp_game <- function(user,choices=c(\"rock\",\"scissors\",\"paper\")){\n  if(!(user %in% choices))\n    return(\"Choose only rock, scissors or paper as input.\") \n  response <- sample(choices,1)\n  if(user == response)\n    return(\"I chose the same. Tie!\")\n  if((user == \"rock\" & response == \"scissors\") | \n     (user == \"scissors\" & response == \"paper\") |\n     (user == \"paper\" & response == \"rock\")){\n    return(paste0(\"I chose \", response, \". You win!\"))\n  }else{\n    return(paste0(\"I chose \", response, \". You lose!\"))\n  }\n}\n\n\nrsp_game(\"rock\")\n\n[1] \"I chose scissors. You win!\"\n\n\nCheck course webpage for more exercises!"
  },
  {
    "objectID": "base-r.html#exercise---temperature-conversion",
    "href": "base-r.html#exercise---temperature-conversion",
    "title": "2  Base R",
    "section": "2.12 Exercise - Temperature Conversion",
    "text": "2.12 Exercise - Temperature Conversion\nWrite a function to convert Fahrenheit to Celsius and Celsius to Fahrenheit.\n(X°C × 9/5) + 32 = Y°F\n\nconvert_temperature <- function(x, F_to_C = TRUE){\n  if(F_to_C){\n    return((x-32)*5/9)\n  }else{\n    return(x*9/5 + 32)\n  }\n}\n\n\nconvert_temperature(30,F_to_C = FALSE)\n\n[1] 86\n\nconvert_temperature(86,F_to_C = TRUE)\n\n[1] 30"
  },
  {
    "objectID": "base-r.html#exercise---future-value",
    "href": "base-r.html#exercise---future-value",
    "title": "2  Base R",
    "section": "2.13 Exercise - Future Value",
    "text": "2.13 Exercise - Future Value\nWrite a function to calculate the future value of an investment given annually compounding interest over an amount of years.\n\\[FV = X * (1 + i) ^T\\]\n\ncalculate_future_value <- \nfunction(investment, interest, duration_in_years){\n  return(investment * ((1 + interest) ^ duration_in_years)) \n}\n\n\n## 100 units of investments 7% interest rate over 5 years\ncalculate_future_value(\n  investment = 100, interest = 0.07, duration_in_years = 5)\n\n[1] 140.2552"
  },
  {
    "objectID": "base-r.html#exercise---color-hex-code",
    "href": "base-r.html#exercise---color-hex-code",
    "title": "2  Base R",
    "section": "2.14 Exercise - Color Hex Code",
    "text": "2.14 Exercise - Color Hex Code\nWrite a function to randomly generate n color hex codes. You can use letters predefined vector.\n\ngenerate_hex_code <- function(n=1){\n  hex_vec <- c(0:9,letters[1:6])\n  colors <- c()\n  for(i in 1:n){\n    colors <- c(colors,\n      paste0(\"#\",\n      paste0(sample(hex_vec,6,replace=TRUE),collapse=\"\")))\n  }\n  return(colors)\n}\n\n\ngenerate_hex_code(n=3)\n\n[1] \"#029298\" \"#68da5d\" \"#6c2069\""
  },
  {
    "objectID": "base-r.html#exercise---calculate-probability-of-dice",
    "href": "base-r.html#exercise---calculate-probability-of-dice",
    "title": "2  Base R",
    "section": "2.15 Exercise - Calculate Probability of Dice",
    "text": "2.15 Exercise - Calculate Probability of Dice\nWrite a function which calculates the probability of getting k sixes in n throws of a die. Hint: Use binomial distribution.\n\nget_prob_dice <- function(k,n){\n  combination <- factorial(n)/(factorial(k) * factorial(n-k))\n  probability <- (1/6)^k * (5/6)^(n-k)\n  return(combination*probability)\n}\n\n\nget_prob_dice(3,5)\n\n[1] 0.03215021\n\n\n\ndbinom(3,5,prob=1/6) ## or simply use dbinom\n\n[1] 0.03215021"
  },
  {
    "objectID": "base-r.html#exercise---rock-scissors-paper",
    "href": "base-r.html#exercise---rock-scissors-paper",
    "title": "2  Base R",
    "section": "2.16 Exercise - Rock, Scissors, Paper",
    "text": "2.16 Exercise - Rock, Scissors, Paper\nWrite a rock scissors paper game which computer randomly chooses\n\nrsp_game <- function(user,choices=c(\"rock\",\"scissors\",\"paper\")){\n  if(!(user %in% choices))\n    return(\"Choose only rock, scissors or paper as input.\") \n  response <- sample(choices,1)\n  if(user == response)\n    return(\"I chose the same. Tie!\")\n  if((user == \"rock\" & response == \"scissors\") | \n     (user == \"scissors\" & response == \"paper\") |\n     (user == \"paper\" & response == \"rock\")){\n    return(paste0(\"I chose \", response, \". You win!\"))\n  }else{\n    return(paste0(\"I chose \", response, \". You lose!\"))\n  }\n}\n\n\nrsp_game(\"rock\")\n\n[1] \"I chose the same. Tie!\"\n\n\nCheck course webpage for more exercises!"
  },
  {
    "objectID": "base-r.html#object-types",
    "href": "base-r.html#object-types",
    "title": "1  Base R",
    "section": "1.6 Object Types",
    "text": "1.6 Object Types\n\n1.6.1 Vector\nVector is the foundation stone of R object types. A variable with a single value is called “atomic” vector.\nVectors with multiple values can be defined using c() (“combine”) function.\n\nx <- c(\"a\",\"b\",\"c\")\nx\n\n[1] \"a\" \"b\" \"c\"\n\n\nA vector can have only a single data type. R conveniently converts vectors to the most appropriate data type.\n\nx <- c(1,\"hi\",FALSE) ## Vector of numeric, character and logical values\nx ## converted to all character\n\n[1] \"1\"     \"hi\"    \"FALSE\"\n\n\n\n\n1.6.2 Matrix\nMatrix is simply a two dimensional special vector.\n\nmat1<-matrix(1:9, ncol=3, nrow=3)\nmat1\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9\n\n\nWe can get a value from a matrix by providing its location as row/column coordinates or by simply by treating it as a vector.\n\nmat1[2,2]\n\n[1] 5\n\nmat1[5]\n\n[1] 5\n\n\n\n\n1.6.3 Data Frame\nData frame object type is still two dimensional but each column can be of a different data type.\n\ndf1 <- data.frame(some_numbers=1:3,\n                  some_names=c(\"Blood\",\"Sweat\",\"Tears\"),\n                  some_logical=c(TRUE,FALSE,TRUE))\ndf1\n\n  some_numbers some_names some_logical\n1            1      Blood         TRUE\n2            2      Sweat        FALSE\n3            3      Tears         TRUE\n\n\nData frames are extremely powerful structures. Most of our work will be on data frames.\nNote: In dplyr package we will see a special version of data frames: tibble.\n\n\n1.6.4 List\nLists are like vectors but they can hold any object (including lists). You can also add names to lists.\n\nlist1 <- list(data_frame = df1,matrix = mat1,vector= x)\nlist1\n\n$data_frame\n  some_numbers some_names some_logical\n1            1      Blood         TRUE\n2            2      Sweat        FALSE\n3            3      Tears         TRUE\n\n$matrix\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9\n\n$vector\n[1] \"1\"     \"hi\"    \"FALSE\"\n\n\n\n\n1.6.5 Functions\nFunctions are very useful types as they allow to run reusable code with dynamic inputs. For example, let’s write a function to calculate the area of a triangle.\n\narea_of_triangle <- function(height,base_length){\n  area <- height*base_length/2\n  return(area) ## Return value using return command\n}\n## You can assign the result of a function to a variable\nx <- area_of_triangle(height = 3, base_length = 4) \nx\n\n[1] 6\n\n\n\nRule of thumb is “If you need to copy paste the same code three times, write a function instead.”\nR has thousands of predefined functions to make life easier.\nIf you want to return multiple values return a list.\n\nclass: center, middle, inverse"
  },
  {
    "objectID": "fundamentals.html",
    "href": "fundamentals.html",
    "title": "Fundamentals",
    "section": "",
    "text": "Data Manipulation: Taking raw data and creating analyses.\nData Visualization: Visualizing findings from the data.\nReporting: Combining all the findings into a single cohesive report.\nInteractive Reporting (Dashboards): Self-exploring analyses and outcomes.\n\nTo achieve these skills following fundamental R packages are used.\n\ndplyr for data manipulation\nggplot2 for data visualization\nquarto for reporting (alternatively use rmarkdown)\nshiny for interactive dashboarding\n\nFollowing sections provide guidance and examples on these packages in the context of Exploratory Data Analysis. There are many extensions and further packages to consider. However, in order for Fundamentals chapter to stay “fundamental” these topics are moved to Advanced chapter."
  },
  {
    "objectID": "fundamentals-end.html",
    "href": "fundamentals-end.html",
    "title": "4  Chapter End",
    "section": "",
    "text": "Fundamentals chapter ends here. You now built the foundations for data analysis skills to take it to the next level. Congratulations!"
  },
  {
    "objectID": "quarto.html",
    "href": "quarto.html",
    "title": "5  Quarto",
    "section": "",
    "text": "Quarto is the most recent solution released by RStudio/Posit. It is very similar to RMarkdown but it has two major advantages. First advantage is Quarto is multilingual (currently R, Python, Julia and Observable). Second advantage is while RMarkdown inspired other packages such as pagedown for webpages, bookdown for books, pkgdown for packages, blogdown for blogs and xaringan for presentations Quarto provides those capabilities (mostly) and more under a single umbrella.\nAccording to official announcement Quarto will not replace RMarkdown but it will not go in the same direction either. For more details you can read Yihui Xie’s (author of RMarkdown) blog post.\nYou can start with the official page’s Get Started and then Quarto Guide. You can also use Quarto Pub to publish your Quarto documents.\nAlso see Thomas Mock’s Quarto Webinar (beware! 2hrs) and its materials."
  },
  {
    "objectID": "shiny.html",
    "href": "shiny.html",
    "title": "5  shiny",
    "section": "",
    "text": "Coming soon…"
  },
  {
    "objectID": "quarto.html#resources",
    "href": "quarto.html#resources",
    "title": "5  Quarto",
    "section": "5.1 Resources",
    "text": "5.1 Resources\n\nA Quarto tip a day\nQuarto Gallery\nAwesome Quarto\n#quartopub hashtag on Twitter"
  },
  {
    "objectID": "base-r.html#other-links",
    "href": "base-r.html#other-links",
    "title": "1  Base R",
    "section": "1.8 Other Links",
    "text": "1.8 Other Links\n\nBase R Cheat Sheet"
  },
  {
    "objectID": "base-r-in-detail.html",
    "href": "base-r-in-detail.html",
    "title": "2  Base R in Detail",
    "section": "",
    "text": "This document is more step by step. It was created in 2018, therefore there is no information about Base R pipes (“|>”)."
  },
  {
    "objectID": "base-r-in-detail.html#object-types",
    "href": "base-r-in-detail.html#object-types",
    "title": "2  Base R in Detail",
    "section": "5.1 Object Types",
    "text": "5.1 Object Types\nIn this part, object types such as vector, matrix, data.frame and list are explained. Although this is not a complete list (e.g. array is another object type) and object is a more general concept, these object types are mostly sufficient at beginner and intermediate levels.\n\n5.1.1 Vector\nMost basic data structure is a vector. You can create a simple vector with c() (combine).\n\nx <- c(5,2,2)\nx\n\n[1] 5 2 2\n\n\nYou can change any value in a vector by defining its index. Index starts with 1.\n\nx[2] <- 7\nx\n\n[1] 5 7 2\n\n\nYou can omit a value by putting a negative index.\n\nx[-2] <- 0\nx\n\n[1] 0 7 0\n\n\nR handles out of bounds index values and returns NA.\n\nx[5] <- 10\nx\n\n[1]  0  7  0 NA 10\n\n\nYou can define multiple index values and define rules to choose the index.\n\nx2 <- 10:19 #This is a special representation that generates a vector from a (10) to b (19).\nx2[c(1,3,7)] #Return 1st, 3rd and 7th values.\n\n[1] 10 12 16\n\nx2[(1:3)] #Return 1st to 3rd values.\n\n[1] 10 11 12\n\n\n\nx2[x2>15] #Return the index values where x2 > 15\n\n[1] 16 17 18 19\n\nx2>15\n\n [1] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE\n\n\nYou can give names instead of index values.\n\nx3<-c(1,2,3)\nnames(x3)<-c(\"a1\",\"b2\",\"c3\")\nx3\n\na1 b2 c3 \n 1  2  3 \n\nx3[\"b2\"]\n\nb2 \n 2 \n\n\nIf you try to combine different data types, R will transform them to characters or numeric.\n\nc(5,FALSE)\n\n[1] 5 0\n\nc(5,FALSE,\"BDA503\")\n\n[1] \"5\"      \"FALSE\"  \"BDA503\"\n\n\nMathematical operations can be easily done with vectors.\n\nvec1 <- 1:5 # This is a special representation of consecutive numbers.\nvec1\n\n[1] 1 2 3 4 5\n\nvec2 <- vec1 * 2\nvec2\n\n[1]  2  4  6  8 10\n\nvec1 + vec2\n\n[1]  3  6  9 12 15\n\n\nVectors need not to be of equal size (though recommended).\n\nvec1 <- 1:6\nvec2 <- 3:5\nvec1 + vec2\n\n[1]  4  6  8  7  9 11\n\n\n\n\n5.1.2 Matrix\nMatrix is more like a stylized vector in a rectangular (matrix) format with some special functions.\n\nmat1<-matrix(1:9, ncol=3, nrow=3)\nmat1\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9\n\n\nYou can manipulate a value of a matrix by giving its index value.\n\nmat1[2,2] <- -10\nmat1\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2  -10    8\n[3,]    3    6    9\n\n\nHere are some basic matrix operations.\n\nmat2 <- matrix(c(0,4,1,2,0,0,0,0,1),ncol=3)\nmat2\n\n     [,1] [,2] [,3]\n[1,]    0    2    0\n[2,]    4    0    0\n[3,]    1    0    1\n\nt(mat2) # Transpose of a matrix\n\n     [,1] [,2] [,3]\n[1,]    0    4    1\n[2,]    2    0    0\n[3,]    0    0    1\n\nsolve(mat2) # Inverse of a matrix\n\n     [,1]  [,2] [,3]\n[1,]  0.0  0.25    0\n[2,]  0.5  0.00    0\n[3,]  0.0 -0.25    1\n\ndet(mat2) # Determinant value of a matrix\n\n[1] -8\n\ndim(mat2) # Dimensions of a matrix\n\n[1] 3 3\n\nnrow(mat2) # Number of rows of a matrix\n\n[1] 3\n\nncol(mat2) # Number of columns of a matrix\n\n[1] 3\n\ndiag(mat2) # Diagonal values of a matrix\n\n[1] 0 0 1\n\neigen(mat2) # Eigenvalues and eigenvectors of a matrix\n\neigen() decomposition\n$values\n[1]  2.828427 -2.828427  1.000000\n\n$vectors\n          [,1]       [,2] [,3]\n[1,] 0.5505553  0.5708950    0\n[2,] 0.7786028 -0.8073674    0\n[3,] 0.3011087 -0.1491200    1\n\nmat1 %*% mat2 # Matrix multiplication\n\n     [,1] [,2] [,3]\n[1,]   23    2    7\n[2,]  -32    4    8\n[3,]   33    6    9\n\n\nYou can also do vector operations with matrices.\n\nmat1 + mat2\n\n     [,1] [,2] [,3]\n[1,]    1    6    7\n[2,]    6  -10    8\n[3,]    4    6   10\n\nmat1 - mat2\n\n     [,1] [,2] [,3]\n[1,]    1    2    7\n[2,]   -2  -10    8\n[3,]    2    6    8\n\nmat1 / mat2\n\n     [,1] [,2] [,3]\n[1,]  Inf    2  Inf\n[2,]  0.5 -Inf  Inf\n[3,]  3.0  Inf    9\n\nmat1 * mat2\n\n     [,1] [,2] [,3]\n[1,]    0    8    0\n[2,]    8    0    0\n[3,]    3    0    9\n\n\nYou can do operations with matrices and vectors together. Then matrix is treated like a vector with the index column order (i.e. starts from top to bottom, then goes to next column).\n\nmat3 <- matrix(1:9,ncol=3)\nmat3\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9\n\nvec <- c(0,1,0)\nmat3 + vec\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    3    6    9\n[3,]    3    6    9\n\nmat3 * vec\n\n     [,1] [,2] [,3]\n[1,]    0    0    0\n[2,]    2    5    8\n[3,]    0    0    0\n\n\nYou can name rows and columns of a matrix.\n\nrownames(mat3) <- c(\"a\",\"b\",\"c\")\ncolnames(mat3) <- c(\"y1\",\"y2\",\"y3\")\nmat3\n\n  y1 y2 y3\na  1  4  7\nb  2  5  8\nc  3  6  9\n\n\n\n\n5.1.3 Data Frame\nData frame is the most useful object type. Unlike matrix and vector you can define different data types for different columns.\n\ndf1 <- data.frame(some_numbers=1:3,some_names=c(\"Blood\",\"Sweat\",\"Tears\"),some_logical=c(TRUE,FALSE,TRUE))\ndf1\n\n  some_numbers some_names some_logical\n1            1      Blood         TRUE\n2            2      Sweat        FALSE\n3            3      Tears         TRUE\n\n\nYou can see the details of an object (in this case the data frame) using str() function.\n\nstr(df1)\n\n'data.frame':   3 obs. of  3 variables:\n $ some_numbers: int  1 2 3\n $ some_names  : chr  \"Blood\" \"Sweat\" \"Tears\"\n $ some_logical: logi  TRUE FALSE TRUE\n\n\nYou easily can do operations on a single column using $.\n\ndf1$some_numbers\n\n[1] 1 2 3\n\ndf1$some_names\n\n[1] \"Blood\" \"Sweat\" \"Tears\"\n\ndf1$some_logical\n\n[1]  TRUE FALSE  TRUE\n\ndf1$some_numbers <- df1$some_numbers^2\ndf1\n\n  some_numbers some_names some_logical\n1            1      Blood         TRUE\n2            4      Sweat        FALSE\n3            9      Tears         TRUE\n\n\nThere are many example data sets in base R and packages in data.frame format. For instance, EuStockMarkets contains the closing prices of DAX (Germany), SMI (Switzerland), CAC (French), FTSE (UK) stock market indices.\n\nhead(EuStockMarkets) #head() function shows the first rows of a data frame.\n\n         DAX    SMI    CAC   FTSE\n[1,] 1628.75 1678.1 1772.8 2443.6\n[2,] 1613.63 1688.5 1750.5 2460.2\n[3,] 1606.51 1678.6 1718.0 2448.2\n[4,] 1621.04 1684.1 1708.1 2470.4\n[5,] 1618.16 1686.6 1723.1 2484.7\n[6,] 1610.61 1671.6 1714.3 2466.8\n\n\n\n\n5.1.4 List\nLists can hold many objects (including lists).\n\nlist1 <- list(df1,mat3,vec2)\nlist1\n\n[[1]]\n  some_numbers some_names some_logical\n1            1      Blood         TRUE\n2            4      Sweat        FALSE\n3            9      Tears         TRUE\n\n[[2]]\n  y1 y2 y3\na  1  4  7\nb  2  5  8\nc  3  6  9\n\n[[3]]\n[1] 3 4 5\n\nlist1[[1]]\n\n  some_numbers some_names some_logical\n1            1      Blood         TRUE\n2            4      Sweat        FALSE\n3            9      Tears         TRUE\n\n\nYou can name the objects and call them with the names if you like.\n\nlist1 <- list(some_df=df1,some_mat=mat3,vec2)\nlist1\n\n$some_df\n  some_numbers some_names some_logical\n1            1      Blood         TRUE\n2            4      Sweat        FALSE\n3            9      Tears         TRUE\n\n$some_mat\n  y1 y2 y3\na  1  4  7\nb  2  5  8\nc  3  6  9\n\n[[3]]\n[1] 3 4 5\n\nlist1$some_df\n\n  some_numbers some_names some_logical\n1            1      Blood         TRUE\n2            4      Sweat        FALSE\n3            9      Tears         TRUE\n\n\nLists are frequently used in functions as parameter set holders and for other purposes."
  },
  {
    "objectID": "base-r-in-detail.html#useful-base-r-functions",
    "href": "base-r-in-detail.html#useful-base-r-functions",
    "title": "2  Base R in Detail",
    "section": "5.2 Useful Base R Functions",
    "text": "5.2 Useful Base R Functions\nRemember, you can always look for help for a function using ?function_name or help(function_name). This is not an exhaustive list, there are many other fantastic functions in base R.\n\nrep(x=5,times=10) #Repeat a value or a vector\n\n [1] 5 5 5 5 5 5 5 5 5 5\n\nseq(from=5,to=10,length.out=11) #Create a sequence with the given number of equidistant elements\n\n [1]  5.0  5.5  6.0  6.5  7.0  7.5  8.0  8.5  9.0  9.5 10.0\n\nseq(from=5,to=10,by=0.25) #Create a sequence with the given increment value\n\n [1]  5.00  5.25  5.50  5.75  6.00  6.25  6.50  6.75  7.00  7.25  7.50  7.75\n[13]  8.00  8.25  8.50  8.75  9.00  9.25  9.50  9.75 10.00\n\nvec1 <- sample(x=1:10,size=10,replace=FALSE) #Pick 10 numbers randomly without replacement (Note: Your results might differ from this document due to randomness.)\nvec1\n\n [1]  7 10  9  4  3  6  1  5  8  2\n\nprint(vec1/2) #Print the outputs of an object. Useful for later.\n\n [1] 3.5 5.0 4.5 2.0 1.5 3.0 0.5 2.5 4.0 1.0\n\nrev(vec1) #Reverse of a vector\n\n [1]  2  8  5  1  6  3  4  9 10  7\n\nlength(vec1) #Number of elements of a vector\n\n[1] 10\n\nvec1 %% 2 #Mod 2 of the elements in the vector\n\n [1] 1 0 1 0 1 0 1 1 0 0\n\nmin(vec1) #Minimum value of the vector\n\n[1] 1\n\nmax(vec1) #Maximum value of the vector\n\n[1] 10\n\nfactorial(vec1) #Factorial value of all elements of a vector (You can use a single value as well)\n\n [1]    5040 3628800  362880      24       6     720       1     120   40320\n[10]       2\n\nsum(vec1) #Sum of all the values in the vector\n\n[1] 55\n\ncumsum(vec1) #Cumulative sum of all the values in the vector\n\n [1]  7 17 26 30 33 39 40 45 53 55\n\nprod(vec1) #Product (multiplication) of all the values in the vector\n\n[1] 3628800\n\ncumprod(vec1) #Cumulative product of all the values in the vector\n\n [1]       7      70     630    2520    7560   45360   45360  226800 1814400\n[10] 3628800\n\nlog(vec1) #Natural logarithm of the values in the vector\n\n [1] 1.9459101 2.3025851 2.1972246 1.3862944 1.0986123 1.7917595 0.0000000\n [8] 1.6094379 2.0794415 0.6931472\n\nlog(vec1,base=2) #Logarithm of base 2.\n\n [1] 2.807355 3.321928 3.169925 2.000000 1.584963 2.584963 0.000000 2.321928\n [9] 3.000000 1.000000\n\nexp(vec1) #Exponential values of a vector (e=2.71...)\n\n [1]  1096.633158 22026.465795  8103.083928    54.598150    20.085537\n [6]   403.428793     2.718282   148.413159  2980.957987     7.389056\n\nvec1^2 #Power of 2\n\n [1]  49 100  81  16   9  36   1  25  64   4\n\nsqrt(vec1) #Square root\n\n [1] 2.645751 3.162278 3.000000 2.000000 1.732051 2.449490 1.000000 2.236068\n [9] 2.828427 1.414214\n\nvecx <- c(1,3,5,7) #Define another vector\nvecy <- c(8,6,4,2) #Define another vector\npmax(vecx,vecy) #Maximum of each corresponding element of two (or more) vectors\n\n[1] 8 6 5 7\n\npmin(vecx,vecy) #Minimum of each corresponding element of two (or more) vectors\n\n[1] 1 3 4 2\n\nmax(vecx,vecy) #Difference between max and pmax\n\n[1] 8\n\nvec1 <- c(-1,0.5,-1.2,4/3)\nvec1\n\n[1] -1.000000  0.500000 -1.200000  1.333333\n\nabs(vec1) #Absolute value\n\n[1] 1.000000 0.500000 1.200000 1.333333\n\nround(vec1,digits = 1) #Round a value to a number of digits\n\n[1] -1.0  0.5 -1.2  1.3\n\nfloor(vec1) #Round down value of vector\n\n[1] -1  0 -2  1\n\nceiling(vec1) #Round up value of vector\n\n[1] -1  1 -1  2\n\nround(0.5) #Interesting case about rounding. Compare with below.\n\n[1] 0\n\nround(1.5) #Interesting case about rounding. Compare with above.\n\n[1] 2\n\nvec_table<-sample(letters[1:5],20,replace=TRUE) #Another vector for frequency tables. letters is a predefined object in R.\nvec_table\n\n [1] \"e\" \"c\" \"d\" \"a\" \"b\" \"e\" \"a\" \"e\" \"d\" \"c\" \"e\" \"a\" \"b\" \"d\" \"b\" \"b\" \"a\" \"d\" \"c\"\n[20] \"d\"\n\ntable(vec_table) #Easily do a frequency table.\n\nvec_table\na b c d e \n4 4 3 5 4 \n\n\n\n5.2.1 Sorting, Ranking and Ordering\n\nvec2 <- sample(x=11:20,size=10,replace=FALSE)\nvec2\n\n [1] 15 16 13 12 19 14 18 20 11 17\n\nsort(vec2) #Sort the values in the vector\n\n [1] 11 12 13 14 15 16 17 18 19 20\n\nrank(vec2) #Rank of the values in the vector\n\n [1]  5  6  3  2  9  4  8 10  1  7\n\norder(vec2) #Returns the index values (ascending) of the sorted vector.\n\n [1]  9  4  3  6  1  2 10  7  5  8\n\norder(vec2,decreasing=TRUE) #Returns the index values (descending) of the sorted vector.\n\n [1]  8  5  7 10  2  1  6  3  4  9\n\n\n\n\n5.2.2 Logical operators\nThese operators return TRUE or FALSE values. They are especially useful to\n\nvec1 <- 1:10\nvec1\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nvec1 > 5 #Logical (TRUE/FALSE) result of elements greater than 5.\n\n [1] FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE\n\nvec1[vec1 > 5]\n\n[1]  6  7  8  9 10\n\nvec1 >= 5 #Logical result of elements greater than or equal to 5.\n\n [1] FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n\nvec1[vec1 >= 5]\n\n[1]  5  6  7  8  9 10\n\nvec1 < 5 #Logical result of elements less than 5.\n\n [1]  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE\n\nvec1 <= 5 #Logical result of elements less than or equal to 5.\n\n [1]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE\n\nvec1 > 5 & vec1 < 9 #and (&) operator\n\n [1] FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE FALSE\n\nvec1[vec1 > 5 & vec1 < 9]\n\n[1] 6 7 8\n\nvec1 < 5 | vec1 > 9 #or (|) operator\n\n [1]  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE\n\nvec1[vec1 < 5 | vec1 > 9]\n\n[1]  1  2  3  4 10\n\n\nYou can also do element by element comparisons of two vectors.\n\neu_df<- data.frame(EuStockMarkets[1:20,]) #Take the first 20 rows of the stock market index data\neu_df_returns <- data.frame(DAX=100*(round(eu_df$DAX[-1]/eu_df$DAX[-20],4)-1),\n                            CAC=100*(round(eu_df$CAC[-1]/eu_df$CAC[-20],4)-1)) #Calculate the index percentage returns\neu_df_returns$DAX_or_CAC <- eu_df_returns$DAX >= eu_df_returns$CAC #If the return of DAX is larger than or equal to CAC return TRUE\neu_df_returns\n\n     DAX   CAC DAX_or_CAC\n1  -0.93 -1.26       TRUE\n2  -0.44 -1.86       TRUE\n3   0.90 -0.58       TRUE\n4  -0.18  0.88      FALSE\n5  -0.47 -0.51       TRUE\n6   1.25  1.18       TRUE\n7   0.58  1.32      FALSE\n8  -0.29 -0.19      FALSE\n9   0.64  0.02       TRUE\n10  0.12  0.31      FALSE\n11 -0.58 -0.24      FALSE\n12 -0.51  0.15      FALSE\n13 -0.52 -0.03      FALSE\n14  0.20  0.34      FALSE\n15  0.18 -0.04       TRUE\n16  0.27  0.35      FALSE\n17 -0.66  0.52      FALSE\n18 -0.48  0.11      FALSE\n19 -0.52 -0.70       TRUE\n\n\n\n\n5.2.3 Statistics Functions\nSome functions are predefined to facilitate statistics calculations.\n\nvec1 <- sample(1:20,50,replace=TRUE) #Sample 50 numbers from values between 1 to 20\nvec1\n\n [1]  8  7  5  4  9 15  7 20 11 19 20 10  9  7 20 13 18 17 19  4 16  6  8  7  9\n[26] 10 10 18  8 13 15 12  6 15 11  1 19 18 16  7 15  4  5 19  4 10  3  2 12 16\n\nmean(vec1) #Mean\n\n[1] 11.14\n\nmedian(vec1) #Median\n\n[1] 10\n\nvar(vec1) #Variance\n\n[1] 30.93918\n\nsd(vec1) #Standard deviation\n\n[1] 5.5623\n\nquantile(vec1) #Quantile values\n\n  0%  25%  50%  75% 100% \n   1    7   10   16   20 \n\nquantile(vec1,0.65) #Quantile value of a specific percentage\n\n 65% \n14.7 \n\nsummary(vec1) #An aggregate summary\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   1.00    7.00   10.00   11.14   16.00   20.00 \n\ncor(matrix(sample(1:20,50,replace=TRUE),ncol=5)) #Correlation matrix\n\n            [,1]       [,2]       [,3]       [,4]        [,5]\n[1,]  1.00000000 -0.1624537 -0.1612215 -0.1470552 -0.07665429\n[2,] -0.16245374  1.0000000  0.4149489  0.4664830  0.10344126\n[3,] -0.16122151  0.4149489  1.0000000 -0.1041721 -0.10328904\n[4,] -0.14705518  0.4664830 -0.1041721  1.0000000  0.23853320\n[5,] -0.07665429  0.1034413 -0.1032890  0.2385332  1.00000000\n\ncov(matrix(sample(1:20,50,replace=TRUE),ncol=5)) #Covariance matrix\n\n           [,1]       [,2]      [,3]      [,4]      [,5]\n[1,]  7.5666667 -0.6111111 -3.111111  5.000000 -3.188889\n[2,] -0.6111111 17.8333333 -2.222222  1.777778 -8.611111\n[3,] -3.1111111 -2.2222222 38.222222  3.888889 18.000000\n[4,]  5.0000000  1.7777778  3.888889 23.777778  3.111111\n[5,] -3.1888889 -8.6111111 18.000000  3.111111 24.988889\n\n\nThere are also random number generators and functions related with densities and cdf’s of different distributions. Here are the functions for normal distribution.\n\nrnorm(5,mean=0,sd=1) #Generate 5 normally distributed random numbers with mean 0 and sd 1\n\n[1] -0.8910757  0.6250769  0.4091871 -1.1077102 -1.4903099\n\ndnorm(x=0,mean=0,sd=1) #Density value of a point in a normal distribution with mean 0 and sd 1\n\n[1] 0.3989423\n\npnorm(q=1.96,mean=0,sd=1) #Cumulative distribution value of a point in a normal distribution with mean 0 and sd 1\n\n[1] 0.9750021\n\nqnorm(p=0.975,mean=0,sd=1) #Quantile value of a point in a normal distribution with mean 0 and sd 1\n\n[1] 1.959964\n\n\nOther distributions include dpois (poisson), dbinom (binomial), dgeom (geometric), dunif (uniform), dgamma (gamma), dexp (exponential), dchisq (chi-squared), dt (t distribution), df (F distribution), dcauchy (cauchy),dnbinom (negative binomial), dhyper (hypergeometric), dlnorm (lognormal), dbeta (beta), dlogis (logistic) and dweibull (weibull) with the same format (e.g. rpois generates random poisson numbers).\n\n5.2.3.1 Random Number Generation\nTip: For reproducibility use set.seed. It will set the randomness seed to a value and random number generation will be the same for (almost) everyone.\n\nset.seed(522)\nrnorm(10)\n\n [1]  0.52028245  0.75354770 -0.80932517 -0.42112173  0.08458416  1.80153605\n [7]  1.25071091 -0.31097287  1.16377544 -0.67728655\n\n\nLet’s run it a second time by resetting the seed. The output will be the same.\n\nset.seed(522)\nrnorm(10)\n\n [1]  0.52028245  0.75354770 -0.80932517 -0.42112173  0.08458416  1.80153605\n [7]  1.25071091 -0.31097287  1.16377544 -0.67728655\n\n\nSee, the same output happens when randomness seed is restarted at the same value.\n\n\n\n5.2.4 Conversion between data and object types\nYou can convert numeric to character, logical to numeric using functions starting with as. and check the type of the object with is. or typeof().\n\nvec1<-c(1,2,3,4)\nis.numeric(vec1) #Is the vector numeric?\n\n[1] TRUE\n\nas.character(vec1) #Make the vector character?\n\n[1] \"1\" \"2\" \"3\" \"4\"\n\ntypeof(vec1) #What is the type?\n\n[1] \"double\"\n\nvec2<-c(\"a\",\"b\",\"c\",\"d\")\ntypeof(vec2)\n\n[1] \"character\"\n\nas.numeric(vec2) # oops\n\nWarning: NAs introduced by coercion\n\n\n[1] NA NA NA NA\n\nvec3<-c(TRUE,FALSE,TRUE,FALSE)\nis.logical(vec3)\n\n[1] TRUE\n\nas.numeric(vec3)\n\n[1] 1 0 1 0\n\nas.character(vec3)\n\n[1] \"TRUE\"  \"FALSE\" \"TRUE\"  \"FALSE\"\n\nvec3*1 #Convert to numeric with multiplication\n\n[1] 1 0 1 0\n\ndf1<-data.frame(a=c(1,2,3),b=c(4,5,6),c=c(7,8,9))\nas.matrix(df1) #Convert to matrix\n\n     a b c\n[1,] 1 4 7\n[2,] 2 5 8\n[3,] 3 6 9\n\nmat1 <- matrix(1:9,ncol=3)\nas.data.frame(mat1)\n\n  V1 V2 V3\n1  1  4  7\n2  2  5  8\n3  3  6  9\n\n\n\n\n5.2.5 String Manipulation\n\nstrvec1<-c(\"BDA503\",\"FE511\",\"IE422\")\ngrep(\"ETM\",strvec1) #Index values of character strings including FE\n\ninteger(0)\n\ngrepl(\"ETM\",strvec1) #TRUE FALSE statements of character strings including FE\n\n[1] FALSE FALSE FALSE\n\ngsub(\"ETM\",\"IE\",strvec1) #Replacing strings\n\n[1] \"BDA503\" \"FE511\"  \"IE422\" \n\nnchar(strvec1) #Return number of characters in string\n\n[1] 6 5 5\n\nsubstr(strvec1,start=1,stop=2) #Trim the string from start to stop\n\n[1] \"BD\" \"FE\" \"IE\"\n\npaste(\"ETM\",\"522\",sep=\"-\") #Concatenate two strings with a separator.\n\n[1] \"ETM-522\"\n\npaste0(\"ETM\",\"522\") #Concatenate two strings without a separator, equivalent of paste(.,sep=\"\").\n\n[1] \"ETM522\"\n\npaste(strvec1,collapse=\"+\") #Concatenate elements of a vector with a collapse character.\n\n[1] \"BDA503+FE511+IE422\""
  },
  {
    "objectID": "base-r-in-detail.html#conditionals-if-else",
    "href": "base-r-in-detail.html#conditionals-if-else",
    "title": "2  Base R in Detail",
    "section": "5.3 Conditionals (If-Else)",
    "text": "5.3 Conditionals (If-Else)\nConditionals are straightforward. If a statement returns TRUE, then the code chunk defined by the brackets are executed.\n\ncourse_name <- \"BDA503\" #Define the course name.\n\nif(course_name==\"BDA503\"){ #If the course name is FE522.\n  print(\"Correct course.\")\n}\n\n[1] \"Correct course.\"\n\n\nIt is possible to execute some other code chunk if the statement is FALSE with else and add other conditionals using else if.\n\ncourse_name <- \"FE511\" #Define the course name.\n\nif(course_name==\"BDA503\"){ #If the course name is FE522.\n  print(\"Correct course.\")\n}else if(grepl(\"ETM\",course_name)){ #If the course name include FE but it is not FE522.\n  print(\"Wrong course but close.\")\n}else{ #If none of the above\n  print(\"Wrong course.\")\n}\n\n[1] \"Wrong course.\"\n\n\nif conditional statements accept only one value. If you want to check for all elements in a vector use ifelse().\n\ncourse_name<-c(\"BDA503\",\"FE511\",\"IE422\")\nifelse(course_name==\"BDA503\",\"Correct Course\",\"Wrong Course\")\n\n[1] \"Correct Course\" \"Wrong Course\"   \"Wrong Course\""
  },
  {
    "objectID": "base-r-in-detail.html#loops",
    "href": "base-r-in-detail.html#loops",
    "title": "2  Base R in Detail",
    "section": "5.4 Loops",
    "text": "5.4 Loops\nAlthough you are warned that R works slowly with loops (especially loops within loops), it is usually inevitable to use the loops.\n\n5.4.1 For\nFor loops consist of a loop variable and a scope.\n\nval<-2\nfor(i in 1:3){ #Define the loop variable and scope\n  print(val^i)\n}\n\n[1] 2\n[1] 4\n[1] 8\n\n\nScope does not need to be numbers. For returns whatever in the scope in index order\n\nfor(i in c(\"BDA503\",\"FE511\",\"IE422\")){\n  print(i)\n}\n\n[1] \"BDA503\"\n[1] \"FE511\"\n[1] \"IE422\"\n\n\n\n\n5.4.2 While\nWhile is a less frequently used loop type. It repeats the code while a condition is met. It first checks the condition. When it is not satisfied, it skips the code chunk.\n\nx <- 0\nwhile(x < 3){\n  x <- x+1\n  print(paste0(\"x is \",x,\" x is not at the desired level. Desired level is above 3.\"))\n}\n\n[1] \"x is 1 x is not at the desired level. Desired level is above 3.\"\n[1] \"x is 2 x is not at the desired level. Desired level is above 3.\"\n[1] \"x is 3 x is not at the desired level. Desired level is above 3.\""
  },
  {
    "objectID": "base-r-in-detail.html#functions",
    "href": "base-r-in-detail.html#functions",
    "title": "2  Base R in Detail",
    "section": "5.5 Functions",
    "text": "5.5 Functions\nR lets you to define functions easily, with a flexible format. Here are some examples.\n\nfun1<-function(par1=\"This is a default value\"){\n  print(par1)\n}\n\nIf there is a default value defined on the function you do not need to enter any value if you are comfortable with.\n\nfun1()\n\n[1] \"This is a default value\"\n\n\nYou can change the parameters when you call the function.\n\nfun1(par1=\"Congratulations, you changed the parameter.\")\n\n[1] \"Congratulations, you changed the parameter.\"\n\n\nIf you are careful about the order of your entered parameters, you do not need to write the parameter name.\n\nfun1(\"Wow you do it like a pro without parameter names!\")\n\n[1] \"Wow you do it like a pro without parameter names!\"\n\n\nHere is another simple example. Let’s calculate the future value of an initial investment compounded interest.\n\ncalc_future_value<-function(present_value,interest_rate,years){\n  return(present_value*(1+interest_rate)^years)\n}\ncalc_future_value(100,0.05,5)\n\n[1] 127.6282\n\n\nPut a technical analysis."
  },
  {
    "objectID": "base-r-in-detail.html#input-output-io-operations",
    "href": "base-r-in-detail.html#input-output-io-operations",
    "title": "2  Base R in Detail",
    "section": "5.6 Input Output (I/O) Operations",
    "text": "5.6 Input Output (I/O) Operations\nReading from and writing to data files will be unavoidable at some point. While it is useful to know the fundamental functions, I/O operations usually require experience. In other words, you will face many challenges to read a table from an excel file or writing outputs to txt files. Though, it gets easier\nFrequently use the help of these functions to understand their inner workings. For xlsx files and other data types (e.g. JSON, SQL) there are packages.\n\nsetwd(\"~/some_path\") #Set working directory path.\ngetwd() #Get the working directory path.\nscan(file=\"some_data_file.txt\") #Read data from file.\nread.table(file=\"some_data_file.csv\") #Read xls or csv files but not xlsx files. You will need a package for that.\nsource(\"path_to_some_r_file/some_r_file.r\")\nwrite(\"writing_something\",file=\"some_document_file.txt\")\nwrite.table() #Writing to csv or xls. Similar logic to to read.table with opposite function.\nfile.choose() #Manually choosing a file from computer. You can use it like read.table(file.choose())\ndir(path=\"some_path\") #Files in the path directory.\n\nImportant: Defining paths in R can be different in Windows and Mac. See this link for more detail.\n\ndir(\"C:/Desktop/\") #Windows style 1\ndir(\"C:\\\\Desktop\\\\\") #Windows style 2\ndir(\"~/Documents/\") #Mac and Linux style. Might work for Windows too.\n\nTip: Sometimes, R reads columns containing characters as factor data type. It is not covered in this tutorial and it is tough to handle and convert. Therefore using the following code will prevent R to read character strings as factors.\n\noptions(stringsAsFactors=FALSE)\n\nIf your character vector is read as a factor, use as.character() function. If your numeric vector is read as a factor, use as.numeric(as.character()) function. Examples are given below.\n\nfactvec<-factor(c(\"a\",\"b\",\"c\",\"a\")) #Factor data vector\nfactvec\nas.character(factvec) #Convert to character\nfactvec2<-factor(c(10,20,30,40,10)) #Factor data vector with numbers only\nfactvec2\nas.numeric(factvec2) #If you want to convert directly to numeric, output will not be desirable.\nas.numeric(as.character(factvec2))\n\n\n5.6.1 RData\nRData is a special data file type used by R. It is quite useful and efficient to store (better than csv). One disadvantage is it is not as common as csv, so reading RData outside R is a challenge.\n\nload(path=\"some_RData\")\nsave(some_data_frame,file=\"some_file.RData\")"
  },
  {
    "objectID": "base-r-in-detail.html#packages",
    "href": "base-r-in-detail.html#packages",
    "title": "2  Base R in Detail",
    "section": "5.7 Packages",
    "text": "5.7 Packages\nPackages are the most important asset class of R. These last years have seen a rapid expansion of R packages for almost any topic of interest that need computation. There are two steps to use a package; to install and to load.\n\ninstall.packages(\"package_name\") #Install command\nlibrary(package_name) #Load the package require() also works. No quotes!\n\nRemember: You need to install a package only once. It is downloaded and ready to use whenever you load the package with library(). Packages are updated from time to time. To update your installed packages, use update.packages() command.\nBelow displays an example of a package use from the start. You will see how it is done in base R and how it can be enhanced with the packages.\n\n5.7.1 Plotting\nPlotting in R can be a bit problematic and hard. Let’s plot the returns of stock indexes of the previous EuStockMarkets data.\n\n#Let's redo what we did previously.\neu_df<- data.frame(EuStockMarkets[1:20,]) #Take the first 20 rows of the stock market index data\neu_df_returns <- data.frame(DAX=100*(round(eu_df$DAX[-1]/eu_df$DAX[-20],4)-1),\n                            CAC=100*(round(eu_df$CAC[-1]/eu_df$CAC[-20],4)-1)) #Calculate the index percentage returns\neu_df_returns\n\n     DAX   CAC\n1  -0.93 -1.26\n2  -0.44 -1.86\n3   0.90 -0.58\n4  -0.18  0.88\n5  -0.47 -0.51\n6   1.25  1.18\n7   0.58  1.32\n8  -0.29 -0.19\n9   0.64  0.02\n10  0.12  0.31\n11 -0.58 -0.24\n12 -0.51  0.15\n13 -0.52 -0.03\n14  0.20  0.34\n15  0.18 -0.04\n16  0.27  0.35\n17 -0.66  0.52\n18 -0.48  0.11\n19 -0.52 -0.70\n\n\nBase R plotting is as following.\n\nplot(x=1:nrow(eu_df_returns),\n     y=eu_df_returns$DAX,\n     type=\"l\",col=\"red\",\n     ylim=c(min(unlist(eu_df_returns)),max(unlist(eu_df_returns))),\n     ylab=\"Returns (%)\",\n     xlab=\"Time Index\")\nlines(eu_df_returns$CAC)\n\n\n\n\nYou can probably do better with ggplot2 package. It has more beautiful aesthetics, more readable code and better options. Even with the default values your plots will look better. Here is a simple implementation of the previous example.\n\nif(!(\"ggplot2\" %in% rownames(installed.packages()))){\n  install.packages(\"ggplot2\") #Install the package (you can skip it if it is already installed)\n}\nlibrary(ggplot2)\nggplot(data=eu_df_returns,aes(x=1:nrow(eu_df_returns))) +\ngeom_line(aes(y=DAX,color=\"DAX\")) +\ngeom_line(aes(y=CAC,color=\"CAC\")) +\nlabs(x=\"Time Index\",y=\"Returns (%)\")"
  },
  {
    "objectID": "base-r-in-detail.html#recommendations",
    "href": "base-r-in-detail.html#recommendations",
    "title": "2  Base R in Detail",
    "section": "5.8 Recommendations",
    "text": "5.8 Recommendations\nR is quite extensive and the best ways to quickly learn are to write as much code as possible (this is the boring advice) and expose yourself to information by subscribing to newsletters, following related Twitter accounts and Facebook pages. Some prominently beneficial sources are given below.\nR CRAN Task View: Curated lists of packages categorized on the purpose of use. They have categories such as Finance, Time Series and Econometrics. It is a good way to start searching for packages.\nStackexchange: Programmer’s best friend. It is the umbrella site for highly technical Q&A sites such as Stack Overflow (for general programming), Cross Validated (statistics and data science) and Quantitative Finance. You can ask your programming problems here by providing an MWE (minimal working example)\nKaggle: There are many data science tasks, data sets and codes in here. Known for data competitions.\nQuandl: Vast collection of data sets mainly on economics and finance. Great R support (even has a package).\nGitHub: Most popular online code repository for git5 based projects. Plus, putting R packages on GitHub prior to release on CRAN is a popular practice (advanced topic).\nCoursera: Online learning at its best. There are many good quality quantitative finance, R and data science courses in here.\nR-bloggers: Very useful site about R. I personally recommend subscribing to their newsletter and following their Twitter and Facebook accounts.\nR-SIG-FIN: A mail group about R and Finance. A bit outdated but you can still search the archives.\nROpenSci: An organization promoting reproducible research with R. They have many good packages also.\n\n5.8.1 R Cheat Sheets\nThere are many code cheat sheets on the internet. Here are some. I will update the list with new additions.\nRStudio Cheat Sheets: Cheat sheets on base R, plotting and some very useful packages (i.e. dplyr, ggplot2, shiny, rmarkdown).\nData Management\nQuandl Cheat Sheet: A cheat sheet by Quandl. There are also tips to use the quandl package.\nR Reference Card: This one is from official R site.\nGoogle’s R Style Guide: This is more about styling your code. Best practices for readability."
  }
]