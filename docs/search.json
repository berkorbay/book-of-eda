[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Book of Exploratory Data Analysis (EDA)",
    "section": "",
    "text": "This “book”, Book of Exploratory Data Analysis (EDA), is actually the organized lecture notes of the course MEF BDA 503.\nMaterials will progressively emerge…"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "See Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "4  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "dplyr.html",
    "href": "dplyr.html",
    "title": "2  dplyr",
    "section": "",
    "text": "Main purpose of this document is to introduce a major data manipulation package, dplyr, with a contemporary subject. There are seven fundamental dplyr functions: select/rename, filter, distinct, arrange, mutate/transmute, group_by and summarise with a number of assisting functions used either in these functions or separately. In this document, we will cover every one of them and there will be supplementary functions to carry out data operations. Also, pipe operator (%>%) will be briefly introduced. This document is updated for dplyr 1.0.0 and R 4.0+ to show you new stuff as well. We will also use lubridate package for date time operations but we will not cover it except for quick explanations (check appendix at the end of this document for a mini tutorial). You can use advanced features in the “Advance Usage” subsections.\n\n\nThere are two prerequisites to start: Install tidyverse package and putting the relevant data set into the working directory (write getwd() in the console to locate your working directory). In this document, topic of the data set is the hourly licensed and unlicensed renewable energy production data between January 1, 2018 and May 31, 2020.\nTo install the package run install.packages(\"tidyverse\") in the console and select a mirror (first one is quite ok). Once you install the library you can always call it with library(tidyverse) command (no need to reinstall). You can download the data set from its GitHub Repository.\n\nlibrary(tidyverse) #tidyverse is a package group which includes dplyr as well\nlibrary(lubridate)\nraw_df <- readRDS(\"rp_201801_202005_df.rds\")\n\n\n\n\nFirst of those above commands calls the package (different from installing) The second command assigns the data to raw_df variable. There are two types of assignment operators in R: <- and =. No operation in R is permanent unless you assign it to somewhere (There are exceptions, though. See data.table package for instance.). We will benefit from this property in this document as well. No matter how many operations we do on each example we will always start from the original data frame.\nLet’s do a simple sanity check. The output of the following command reads “21,168 x 17” in the first line, which means there are 21,168 rows and 17 columns in the tibble. Tibble is the name of the data.frame type of dplyr. It usually is data frame plus some advanced features. There are abbreviations of data types under each column name. These are usually character/string (), numeric (, if integer ), logical (TRUE/FALSE, logical) (), factor (), date () and datetime (). In the introduction phase we will only use character, numeric and logical data types.\n\nprint(raw_df,n=3)\n\n# A tibble: 21,168 × 17\n  dt                  wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2020-05-31 23:00:00    1434.           913.       75.8         2585.\n2 2020-05-31 22:00:00    1577.           908.       75.6         2631.\n3 2020-05-31 21:00:00    1858.           901.       75.4         2585.\n# … with 21,165 more rows, and 12 more variables: riverType_lic <dbl>,\n#   biomass_lic <dbl>, landfillGas_lic <dbl>, sun_lic <dbl>,\n#   reservoir_lic <dbl>, others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>,\n#   canalType_ul <dbl>, biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>\n\n\nAlso we can use glimpse function to inspect. Using glimpse each column is represented in a row with its data type and first few entries. Our data consists of hourly renewable electricity production of YEKDEM plants from different origins and license types. YEKDEM is a type of feed-in-tariff incentive framework. Suffixes with “_lic” represents licensed (larger scale) plants and “_ul” represents unlicensed (smaller scale) production. canalType, riverType and reservoir columns represent hydro power.\n\nraw_df %>% glimpse()\n\nRows: 21,168\nColumns: 17\n$ dt              <dttm> 2020-05-31 23:00:00, 2020-05-31 22:00:00, 2020-05-31 …\n$ wind_lic        <dbl> 1433.8132, 1577.1419, 1857.5492, 1933.0142, 2031.7862,…\n$ geothermal_lic  <dbl> 912.7882, 907.9303, 900.5844, 888.4561, 864.5402, 847.…\n$ biogas_lic      <dbl> 75.8047, 75.6163, 75.3906, 76.7873, 76.9707, 77.5750, …\n$ canalType_lic   <dbl> 2584.930, 2630.602, 2585.038, 2542.381, 2594.459, 2622…\n$ riverType_lic   <dbl> 316.5538, 316.6800, 356.7637, 350.1544, 377.5312, 379.…\n$ biomass_lic     <dbl> 262.4994, 253.0814, 246.9268, 249.9152, 248.2336, 246.…\n$ landfillGas_lic <dbl> 100.3971, 101.1378, 100.4442, 100.7307, 102.2474, 102.…\n$ sun_lic         <dbl> 0.0000, 0.0000, 0.0000, 0.0000, 2.0594, 14.2800, 48.09…\n$ reservoir_lic   <dbl> 2306.303, 2296.045, 2279.266, 2308.918, 2792.313, 3180…\n$ others_lic      <dbl> 48.3833, 48.4011, 48.4041, 48.4199, 48.4653, 48.5485, …\n$ wind_ul         <dbl> 3.7751, 4.8375, 7.6659, 11.8121, 13.1070, 13.1830, 10.…\n$ biogas_ul       <dbl> 16.9293, 16.9227, 16.9052, 16.7517, 16.2928, 16.5989, …\n$ canalType_ul    <dbl> 4.1749, 4.4221, 4.4658, 4.6020, 4.6195, 4.5146, 4.6616…\n$ biomass_ul      <dbl> 15.4698, 15.3609, 16.0483, 15.2271, 15.5563, 15.5007, …\n$ sun_ul          <dbl> 0.0582, 0.0320, 0.0335, 1.3121, 103.3267, 555.5787, 14…\n$ others_ul       <dbl> 0.0610, 0.0395, 0.4136, 0.5508, 0.7106, 1.3775, 2.7468…\n\n\nDid you notice the expression we used this time? Pipe operator makes data analysis and transformation very easy and civilized. We will use pipes frequently in this document and in the future.\nWe can connect many functions without calling the variable multiple times with the help of the pipe operator."
  },
  {
    "objectID": "dplyr.html#selectrename",
    "href": "dplyr.html#selectrename",
    "title": "2  Introduction to dplyr 1.0.0: Turkish Renewable Energy Production Data",
    "section": "4.1 select/rename",
    "text": "4.1 select/rename\nSelect, as the name suggests, is used to select columns. For instance, suppose we only want licensed wind production (wind_lic) and date-time (dt) columns.\n\nraw_df %>% select(dt,wind_lic)\n\n# A tibble: 21,168 × 2\n  dt                  wind_lic\n  <dttm>                 <dbl>\n1 2020-05-31 23:00:00    1434.\n2 2020-05-31 22:00:00    1577.\n3 2020-05-31 21:00:00    1858.\n# … with 21,165 more rows\n\n\nIf we wanted to write the above expression without the pipe operator, we could go with the sad expression below. You can extrapolate how complicated things can be without the pipe.\n\nselect(raw_df,dt,wind_lic)\n\nWe can use rename to rename columns (again as the name suggests). Let’s change dt to date_time.\n\nraw_df %>% rename(date_time = dt)\n\n# A tibble: 21,168 × 17\n  date_time           wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2020-05-31 23:00:00    1434.           913.       75.8         2585.\n2 2020-05-31 22:00:00    1577.           908.       75.6         2631.\n3 2020-05-31 21:00:00    1858.           901.       75.4         2585.\n# … with 21,165 more rows, and 12 more variables: riverType_lic <dbl>,\n#   biomass_lic <dbl>, landfillGas_lic <dbl>, sun_lic <dbl>,\n#   reservoir_lic <dbl>, others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>,\n#   canalType_ul <dbl>, biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>\n\n\np.s. We can rename columns inside select function.\nSelect has many convenient sub operators and special expressions. If we know the order of columns, we can use the scope (:) expression to get all the columns determined by the scope. Suppose, we want date-time (dt) and licensed production.\n\nraw_df %>% select(date_time=dt,wind_lic:others_lic)\n\n# A tibble: 21,168 × 11\n  date_time           wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2020-05-31 23:00:00    1434.           913.       75.8         2585.\n2 2020-05-31 22:00:00    1577.           908.       75.6         2631.\n3 2020-05-31 21:00:00    1858.           901.       75.4         2585.\n# … with 21,165 more rows, and 6 more variables: riverType_lic <dbl>,\n#   biomass_lic <dbl>, landfillGas_lic <dbl>, sun_lic <dbl>,\n#   reservoir_lic <dbl>, others_lic <dbl>\n\n\nWe can eliminate unwanted columns by putting - before the names. Suppose I am not interested in wind values, want to remove all other related columns from the data set, and all other related column names start with “wind_”. We can do it using - and starts_with.\n\nraw_df %>% select(-starts_with(\"wind_\")) \n\n# A tibble: 21,168 × 15\n  dt                  geothermal_lic biogas_lic canalType_lic riverType_lic\n  <dttm>                       <dbl>      <dbl>         <dbl>         <dbl>\n1 2020-05-31 23:00:00           913.       75.8         2585.          317.\n2 2020-05-31 22:00:00           908.       75.6         2631.          317.\n3 2020-05-31 21:00:00           901.       75.4         2585.          357.\n# … with 21,165 more rows, and 10 more variables: biomass_lic <dbl>,\n#   landfillGas_lic <dbl>, sun_lic <dbl>, reservoir_lic <dbl>,\n#   others_lic <dbl>, biogas_ul <dbl>, canalType_ul <dbl>, biomass_ul <dbl>,\n#   sun_ul <dbl>, others_ul <dbl>\n\n\nThere are similar expressions for other purposes, such as starts_with, everything and contains. You can see all the expressions in the Cheat Sheet link given at the end of this document.\ndplyr 1.0.0 Feature: Sometimes you just want to change the order of the columns. Then use relocate. Suppose we want to show solar and wind production with date-time. But we want to get licensed wind together with licensed solar.\n\nraw_df %>% select(dt,starts_with(\"sun_\"),starts_with(\"wind\")) %>% relocate(wind_lic,.before=sun_ul)\n\n# A tibble: 21,168 × 5\n  dt                  sun_lic wind_lic sun_ul wind_ul\n  <dttm>                <dbl>    <dbl>  <dbl>   <dbl>\n1 2020-05-31 23:00:00       0    1434. 0.0582    3.78\n2 2020-05-31 22:00:00       0    1577. 0.032     4.84\n3 2020-05-31 21:00:00       0    1858. 0.0335    7.67\n# … with 21,165 more rows\n\n\nIf we specify nothing, it will be in the first place.\n\nraw_df %>% select(dt,starts_with(\"sun_\"),starts_with(\"wind\")) %>% relocate(wind_lic)\n\n# A tibble: 21,168 × 5\n  wind_lic dt                  sun_lic sun_ul wind_ul\n     <dbl> <dttm>                <dbl>  <dbl>   <dbl>\n1    1434. 2020-05-31 23:00:00       0 0.0582    3.78\n2    1577. 2020-05-31 22:00:00       0 0.032     4.84\n3    1858. 2020-05-31 21:00:00       0 0.0335    7.67\n# … with 21,165 more rows\n\n\nWe use last_col() if we want to take a column to the end.\n\nraw_df %>% select(dt,starts_with(\"sun_\"),starts_with(\"wind\")) %>% relocate(dt,.after=last_col())\n\n# A tibble: 21,168 × 5\n  sun_lic sun_ul wind_lic wind_ul dt                 \n    <dbl>  <dbl>    <dbl>   <dbl> <dttm>             \n1       0 0.0582    1434.    3.78 2020-05-31 23:00:00\n2       0 0.032     1577.    4.84 2020-05-31 22:00:00\n3       0 0.0335    1858.    7.67 2020-05-31 21:00:00\n# … with 21,165 more rows\n\n\nHonestly, relocate is a very convenient function.\n\n4.1.1 select/rename advanced usage\nAdvanced usage subsection introduces extra functionality which can be a bit confusing at the first phase. But, once you get a grasp on the fundamentals check back here as reference. There are several features not available for versions before dplyr 1.0.0.\nWe can use rename_with function to rename columns with given criteria. In pipe version of the function, first parameter is the function and the second parameter is the criterion. Let’s replace all “Type” with “_type”. For instance it should change “canalType” to “canal_type”.\n\nraw_df %>% rename_with(~gsub(\"Type\",\"_type\",.),contains(\"Type\")) %>% glimpse()\n\nRows: 21,168\nColumns: 17\n$ dt              <dttm> 2020-05-31 23:00:00, 2020-05-31 22:00:00, 2020-05-31 …\n$ wind_lic        <dbl> 1433.8132, 1577.1419, 1857.5492, 1933.0142, 2031.7862,…\n$ geothermal_lic  <dbl> 912.7882, 907.9303, 900.5844, 888.4561, 864.5402, 847.…\n$ biogas_lic      <dbl> 75.8047, 75.6163, 75.3906, 76.7873, 76.9707, 77.5750, …\n$ canal_type_lic  <dbl> 2584.930, 2630.602, 2585.038, 2542.381, 2594.459, 2622…\n$ river_type_lic  <dbl> 316.5538, 316.6800, 356.7637, 350.1544, 377.5312, 379.…\n$ biomass_lic     <dbl> 262.4994, 253.0814, 246.9268, 249.9152, 248.2336, 246.…\n$ landfillGas_lic <dbl> 100.3971, 101.1378, 100.4442, 100.7307, 102.2474, 102.…\n$ sun_lic         <dbl> 0.0000, 0.0000, 0.0000, 0.0000, 2.0594, 14.2800, 48.09…\n$ reservoir_lic   <dbl> 2306.303, 2296.045, 2279.266, 2308.918, 2792.313, 3180…\n$ others_lic      <dbl> 48.3833, 48.4011, 48.4041, 48.4199, 48.4653, 48.5485, …\n$ wind_ul         <dbl> 3.7751, 4.8375, 7.6659, 11.8121, 13.1070, 13.1830, 10.…\n$ biogas_ul       <dbl> 16.9293, 16.9227, 16.9052, 16.7517, 16.2928, 16.5989, …\n$ canal_type_ul   <dbl> 4.1749, 4.4221, 4.4658, 4.6020, 4.6195, 4.5146, 4.6616…\n$ biomass_ul      <dbl> 15.4698, 15.3609, 16.0483, 15.2271, 15.5563, 15.5007, …\n$ sun_ul          <dbl> 0.0582, 0.0320, 0.0335, 1.3121, 103.3267, 555.5787, 14…\n$ others_ul       <dbl> 0.0610, 0.0395, 0.4136, 0.5508, 0.7106, 1.3775, 2.7468…\n\n\nDid you notice ~ and . in the function? Dot (.) is a representation of the entity. Depending on the situation it can be the latest version of the tibble in the pipe chain, a specific column or something else. ~ is a special character notifying that function evaluation will be done using the dot notation. We will see more examples of that.\nLet’s introduce where. If is a function from tidyselect package to select variables with a function where it returns TRUE. It is quite handy.\n\nraw_df %>% select(dt,starts_with(\"sun_\"),starts_with(\"wind\")) %>% relocate(where(is.numeric))\n\n# A tibble: 21,168 × 5\n  sun_lic sun_ul wind_lic wind_ul dt                 \n    <dbl>  <dbl>    <dbl>   <dbl> <dttm>             \n1       0 0.0582    1434.    3.78 2020-05-31 23:00:00\n2       0 0.032     1577.    4.84 2020-05-31 22:00:00\n3       0 0.0335    1858.    7.67 2020-05-31 21:00:00\n# … with 21,165 more rows\n\n\nWe can also use any_of or all_of functions in select. The main difference is while the former returns as much as it can, the latter will throw an error if any one of the criteria is not fulfilled. Let’s try to select “dt”, “others_lic” and “nuclear_lic”. Since this data does not include nuclear power production we should not see it.\n\nraw_df %>% select(any_of(c(\"dt\",\"others_lic\",\"nuclear_lic\")))\n\n# A tibble: 21,168 × 2\n  dt                  others_lic\n  <dttm>                   <dbl>\n1 2020-05-31 23:00:00       48.4\n2 2020-05-31 22:00:00       48.4\n3 2020-05-31 21:00:00       48.4\n# … with 21,165 more rows\n\n\nIn order not to break our notebook, we wrap it around try (error handling is another topic).\n\ntry(raw_df %>% select(all_of(c(\"dt\",\"others_lic\",\"nuclear_lic\"))))\n\nError : Can't subset columns that don't exist.\n✖ Column `nuclear_lic` doesn't exist."
  },
  {
    "objectID": "dplyr.html#filterdistinct",
    "href": "dplyr.html#filterdistinct",
    "title": "2  Introduction to dplyr 1.0.0: Turkish Renewable Energy Production Data",
    "section": "4.2 filter/distinct",
    "text": "4.2 filter/distinct\nFilter (no more “as the name suggests”, as you already figured it out) helps filter rows according to given criteria. It is highly similar with Excel’s filter functionality (but much much more flexible and reliable).\nLet’s see the production at 2020-05-08 16:00:00.\n\nraw_df %>% filter(dt == \"2020-05-08 16:00:00\")\n\n# A tibble: 1 × 17\n  dt                  wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2020-05-08 16:00:00    2618.           856.       79.8         3896.\n# … with 12 more variables: riverType_lic <dbl>, biomass_lic <dbl>,\n#   landfillGas_lic <dbl>, sun_lic <dbl>, reservoir_lic <dbl>,\n#   others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>, canalType_ul <dbl>,\n#   biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>\n\n\nBy using == operator, we bring the values in dt column which are equal to the hour we desired. There are other expressions such as not equal to (!=), greater than (or equal to) (>,>=), smaller than (or equal to) (<,<=), in (%in%) and some more.\nAt the same time we can make comparisons between columns and combine multiple criteria to create more complex filters. Here we use AND (&) and OR (|) operators to combine criteria.\nSuppose we want to find our the times when licensed wind production is greater than all of hydro type licensed production.\n\nraw_df %>% filter(wind_lic > canalType_lic & wind_lic > reservoir_lic & wind_lic > riverType_lic)\n\n# A tibble: 11,287 × 17\n  dt                  wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2020-05-27 19:00:00    3303.           930.       74.7         2969.\n2 2020-05-27 18:00:00    3596.           914.       75.0         2953.\n3 2020-05-27 17:00:00    3551.           900.       76.3         2954.\n# … with 11,284 more rows, and 12 more variables: riverType_lic <dbl>,\n#   biomass_lic <dbl>, landfillGas_lic <dbl>, sun_lic <dbl>,\n#   reservoir_lic <dbl>, others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>,\n#   canalType_ul <dbl>, biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>\n\n\nWe can add numeric operations as well. Suppose we want to find the total solar production is greater than total wind production.\n\nraw_df %>% filter(wind_lic + wind_ul < sun_lic + sun_ul)\n\n# A tibble: 4,949 × 17\n  dt                  wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2020-05-31 16:00:00    2036.           843.       76.8         2616.\n2 2020-05-31 15:00:00    1875.           845.       77.4         2685.\n3 2020-05-31 14:00:00    1755.           853.       77.2         2715.\n# … with 4,946 more rows, and 12 more variables: riverType_lic <dbl>,\n#   biomass_lic <dbl>, landfillGas_lic <dbl>, sun_lic <dbl>,\n#   reservoir_lic <dbl>, others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>,\n#   canalType_ul <dbl>, biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>\n\n\nSuppose we want to filter only the unique values. Then we simply use distinct command. Let’s get unique rounded licensed wind production values.\n\nraw_df %>% distinct(round(wind_lic))\n\n# A tibble: 4,893 × 1\n  `round(wind_lic)`\n              <dbl>\n1              1434\n2              1577\n3              1858\n# … with 4,890 more rows\n\n\nIf we want to keep all columns we simply make the parameter .keep=TRUE.\n\nraw_df %>% distinct(round(wind_lic),.keep=TRUE)\n\n# A tibble: 4,893 × 2\n  `round(wind_lic)` .keep\n              <dbl> <lgl>\n1              1434 TRUE \n2              1577 TRUE \n3              1858 TRUE \n# … with 4,890 more rows\n\n\n\n4.2.1 filter/distinct advanced usage\nLet’s introduce slice. This function helps return rows by its row number. Suppose we want the top 5 rows.\n\nraw_df %>% slice(1:5) %>% print(n=5)\n\n# A tibble: 5 × 17\n  dt                  wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2020-05-31 23:00:00    1434.           913.       75.8         2585.\n2 2020-05-31 22:00:00    1577.           908.       75.6         2631.\n3 2020-05-31 21:00:00    1858.           901.       75.4         2585.\n4 2020-05-31 20:00:00    1933.           888.       76.8         2542.\n5 2020-05-31 19:00:00    2032.           865.       77.0         2594.\n# … with 12 more variables: riverType_lic <dbl>, biomass_lic <dbl>,\n#   landfillGas_lic <dbl>, sun_lic <dbl>, reservoir_lic <dbl>,\n#   others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>, canalType_ul <dbl>,\n#   biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>\n\n\nIf we want to return random rows we have slice_sample. Let’s bring 5 random rows.\n\nraw_df %>% slice_sample(n=5)\n\n# A tibble: 5 × 17\n  dt                  wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2020-05-18 13:00:00    1661.           669.       75.9         3266.\n2 2019-08-28 10:00:00    3410.           691.       83.0          843.\n3 2019-02-28 12:00:00    2106.           898.       82.5         2128.\n# … with 2 more rows, and 12 more variables: riverType_lic <dbl>,\n#   biomass_lic <dbl>, landfillGas_lic <dbl>, sun_lic <dbl>,\n#   reservoir_lic <dbl>, others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>,\n#   canalType_ul <dbl>, biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>\n\n\nIf we want to do it proportionately, we have the prop parameter. Let’s say we want 0.1% of the data frame.\n\nraw_df %>% slice_sample(prop=0.001)\n\n# A tibble: 21 × 17\n  dt                  wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2020-02-09 17:00:00    1422.           971.       77.3         1995.\n2 2020-02-28 18:00:00    2401.           923.       77.4         2389.\n3 2018-04-22 22:00:00    1525.           720.       64.3         1986.\n# … with 18 more rows, and 12 more variables: riverType_lic <dbl>,\n#   biomass_lic <dbl>, landfillGas_lic <dbl>, sun_lic <dbl>,\n#   reservoir_lic <dbl>, others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>,\n#   canalType_ul <dbl>, biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>\n\n\nThere are other slice_* type functions. These are slice_head/slice_tail for first/last n or percentage of rows. slice_min/slice_max for the top/bottom n rows according to an ordering criteria."
  },
  {
    "objectID": "dplyr.html#arrange",
    "href": "dplyr.html#arrange",
    "title": "2  Introduction to dplyr 1.0.0: Turkish Renewable Energy Production Data",
    "section": "4.3 arrange",
    "text": "4.3 arrange\nArrange sorts rows from A to Z or smallest to largest. It has great similarity with Excel’s Sort functionality.\nLet’s sort licensed reservoir production from largest to smallest.\n\nraw_df %>% select(dt,reservoir_lic) %>% arrange(desc(reservoir_lic))\n\n# A tibble: 21,168 × 2\n  dt                  reservoir_lic\n  <dttm>                      <dbl>\n1 2019-05-10 23:00:00         5058.\n2 2019-05-10 21:00:00         5035.\n3 2019-05-15 02:00:00         5019.\n# … with 21,165 more rows\n\n\nDo you see desc() function inside arrange? By default arrange sorts a column by first to last or A-Z. desc reverses this.\nYou can also use multiple sorting criteria and use operations inside arrange. Let’s arrange by licensed wind production rounded down (floor) in 100s range (e.g. 5634 = 5600 and 5693 = 5600 as well). Then we sort by date time to see the first time the production entered a 100-range in the data time period.\n\nraw_df %>% arrange(desc(floor(wind_lic/100)*100),dt)\n\n# A tibble: 21,168 × 17\n  dt                  wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2019-09-15 17:00:00    5767.           691.       83.0          922.\n2 2018-09-26 19:00:00    5622.           672.       67.8          951.\n3 2019-09-15 15:00:00    5628.           692.       81.4          901.\n# … with 21,165 more rows, and 12 more variables: riverType_lic <dbl>,\n#   biomass_lic <dbl>, landfillGas_lic <dbl>, sun_lic <dbl>,\n#   reservoir_lic <dbl>, others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>,\n#   canalType_ul <dbl>, biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>"
  },
  {
    "objectID": "dplyr.html#mutatetransmute",
    "href": "dplyr.html#mutatetransmute",
    "title": "2  Introduction to dplyr 1.0.0: Turkish Renewable Energy Production Data",
    "section": "4.4 mutate/transmute",
    "text": "4.4 mutate/transmute\nMutate is the function when we do operations and calculations using other columns.\nFor instance let’s calculate wind power’s share in total renewables production at each hour.\n\nraw_df %>% mutate(wind_lic_perc = wind_lic / (wind_lic + geothermal_lic + biogas_lic + canalType_lic + riverType_lic + biomass_lic + landfillGas_lic + sun_lic + reservoir_lic + others_lic + wind_ul + biogas_ul + canalType_ul + biomass_ul + sun_ul + others_ul)) %>% select(dt, wind_lic_perc)\n\n# A tibble: 21,168 × 2\n  dt                  wind_lic_perc\n  <dttm>                      <dbl>\n1 2020-05-31 23:00:00         0.177\n2 2020-05-31 22:00:00         0.191\n3 2020-05-31 21:00:00         0.219\n# … with 21,165 more rows\n\n\nYou can use many R functions (from both base functions and other packages). For instance to calculate “competition” wind and solar we can use the following expression.\n\nraw_df %>% mutate(wind_or_solar = ifelse(wind_lic + wind_ul > sun_lic + sun_ul, \"wind\", \"solar\")) %>% select(dt,wind_or_solar)\n\n# A tibble: 21,168 × 2\n  dt                  wind_or_solar\n  <dttm>              <chr>        \n1 2020-05-31 23:00:00 wind         \n2 2020-05-31 22:00:00 wind         \n3 2020-05-31 21:00:00 wind         \n# … with 21,165 more rows\n\n\nTransmute has the same functionality as mutate with the additional property similar to select. Transmute returns only the columns included in the function. Suppose we also want to calculate the difference between total wind and total solar.\n\nraw_df %>% transmute(dt, wind_or_solar = ifelse(wind_lic + wind_ul > sun_lic + sun_ul, \"wind\", \"solar\"), absdiff = abs(wind_lic + wind_ul - sun_lic - sun_ul))\n\n# A tibble: 21,168 × 3\n  dt                  wind_or_solar absdiff\n  <dttm>              <chr>           <dbl>\n1 2020-05-31 23:00:00 wind            1438.\n2 2020-05-31 22:00:00 wind            1582.\n3 2020-05-31 21:00:00 wind            1865.\n# … with 21,165 more rows\n\n\n\n4.4.1 mutate/transmute advanced usage\nSuppose we want to see the difference between the previous and next hour’s production. We offset rows using lead and lag functions. But remember lead and lag does not actually give you “next/previous hour’s” values, just the rows. You may need to arrange your data.\n\nraw_df %>% transmute(dt, wind_lic, wind_lic_prev_h = lead(wind_lic,1), wind_lic_next_h = lag(wind_lic,1))\n\n# A tibble: 21,168 × 4\n  dt                  wind_lic wind_lic_prev_h wind_lic_next_h\n  <dttm>                 <dbl>           <dbl>           <dbl>\n1 2020-05-31 23:00:00    1434.           1577.             NA \n2 2020-05-31 22:00:00    1577.           1858.           1434.\n3 2020-05-31 21:00:00    1858.           1933.           1577.\n# … with 21,165 more rows\n\n\nIf you want to use the same function over several columns, you can use the new across function. Let’s round every numeric column to one significant digit.\n\nraw_df %>% mutate(across(where(is.numeric),~round(.,1)))\n\n# A tibble: 21,168 × 17\n  dt                  wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2020-05-31 23:00:00    1434.           913.       75.8         2585.\n2 2020-05-31 22:00:00    1577.           908.       75.6         2631.\n3 2020-05-31 21:00:00    1858.           901.       75.4         2585 \n# … with 21,165 more rows, and 12 more variables: riverType_lic <dbl>,\n#   biomass_lic <dbl>, landfillGas_lic <dbl>, sun_lic <dbl>,\n#   reservoir_lic <dbl>, others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>,\n#   canalType_ul <dbl>, biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>\n\n\nWe can also specify columns. Let’s see the comparative production of wind and reservoir hydro against the unlicensed solar production. We just increment solar production by 1 to prevent any infinity values.\n\nraw_df %>% mutate(sun_ul = sun_ul + 1) %>% transmute(dt,across(c(wind_lic,reservoir_lic),~round(./sun_ul,2)))\n\n# A tibble: 21,168 × 3\n  dt                  wind_lic reservoir_lic\n  <dttm>                 <dbl>         <dbl>\n1 2020-05-31 23:00:00    1355.         2179.\n2 2020-05-31 22:00:00    1528.         2225.\n3 2020-05-31 21:00:00    1797.         2205.\n# … with 21,165 more rows\n\n\nIf there are multiple conditions ifelse is not enough. It is possible to use case_when to specify multiple conditions and outcomes.\n\nraw_df %>% transmute(dt, solar_production_level = case_when(sun_ul > quantile(sun_ul,0.9) ~ \"very high\", sun_ul > quantile(sun_ul, 0.75) ~ \"high\", sun_ul > quantile(sun_ul, 0.5) ~ \"above median\", TRUE ~ \"below median\"))  %>% slice(7:9)\n\n# A tibble: 3 × 2\n  dt                  solar_production_level\n  <dttm>              <chr>                 \n1 2020-05-31 17:00:00 above median          \n2 2020-05-31 16:00:00 high                  \n3 2020-05-31 15:00:00 very high             \n\n\nrowwise is actually a type of group_by/summarise function but as the name suggests it allows us to do row-wise operations. Let’s calculate row sums by using c_across function and rowwise. Oh and also now, experimentally, you can use relocate functionality in mutate/transmute. So, conveniently we can place it after date time.\n\nraw_df %>% slice_head(n=5) %>% rowwise() %>% mutate(total_prod = sum(c_across(where(is.numeric))),.after=dt)\n\n# A tibble: 5 × 18\n# Rowwise: \n  dt                  total_prod wind_lic geothermal_lic biogas_lic\n  <dttm>                   <dbl>    <dbl>          <dbl>      <dbl>\n1 2020-05-31 23:00:00      8082.    1434.           913.       75.8\n2 2020-05-31 22:00:00      8248.    1577.           908.       75.6\n3 2020-05-31 21:00:00      8496.    1858.           901.       75.4\n# … with 2 more rows, and 13 more variables: canalType_lic <dbl>,\n#   riverType_lic <dbl>, biomass_lic <dbl>, landfillGas_lic <dbl>,\n#   sun_lic <dbl>, reservoir_lic <dbl>, others_lic <dbl>, wind_ul <dbl>,\n#   biogas_ul <dbl>, canalType_ul <dbl>, biomass_ul <dbl>, sun_ul <dbl>,\n#   others_ul <dbl>"
  },
  {
    "objectID": "dplyr.html#group_bysummarise",
    "href": "dplyr.html#group_bysummarise",
    "title": "2  Introduction to dplyr 1.0.0: Turkish Renewable Energy Production Data",
    "section": "4.5 group_by/summarise",
    "text": "4.5 group_by/summarise\nFinally we will learn how to calculate summary tables. It is similar to Pivot Tables in Excel. group_by is the grouping function, summarise is the summarising function.\nFor instance let’s calculate number of hours where wind production is above 3000 MWh. We will use a special function n() to calculate number of rows. We can define groupings just like mutate.\n\nraw_df %>% group_by(production_group = cut(wind_lic + wind_ul,breaks=c(0,1000,2000,3000,4000,5000,6000),include.lowest = TRUE)) %>% summarise(count = n())\n\n# A tibble: 6 × 2\n  production_group count\n  <fct>            <int>\n1 [0,1e+03]         4294\n2 (1e+03,2e+03]     5733\n3 (2e+03,3e+03]     4725\n# … with 3 more rows\n\n\nNormally, we get one result for each group and summary function. From dplyr 1.0.0 we can have multiple row summarise for each group. Let’s say we want to find the minimum and maximum licensed wind production ranges for each year. But, be warned, it can be a little confusing.\n\nraw_df %>% group_by(year = lubridate::year(dt)) %>% summarise(wind_lic_range = range(wind_lic))\n\n`summarise()` has grouped output by 'year'. You can override using the `.groups` argument.\n\n\n# A tibble: 6 × 2\n# Groups:   year [3]\n   year wind_lic_range\n  <dbl>          <dbl>\n1  2018           46.2\n2  2018         5622. \n3  2019           32.8\n# … with 3 more rows\n\n\n\n4.5.1 group_by/summarise advanced usage\nJust like mutate/transmute you can use across in summarise as well. Let’s see median production of each year and each source. In this example we can also use the named list version of the functions and additional names structure.\n\nraw_df %>% group_by(year = lubridate::year(dt)) %>% summarise(across(where(is.numeric),list(med=median),.names=\"{fn}_{col}\"))\n\n# A tibble: 3 × 17\n   year med_wind_lic med_geothermal_lic med_biogas_lic med_canalType_lic\n  <dbl>        <dbl>              <dbl>          <dbl>             <dbl>\n1  2018        1989.               694.           66.4             1480.\n2  2019        2136.               814.           80.9             1575.\n3  2020        2297.               951.           78.5             2779.\n# … with 12 more variables: med_riverType_lic <dbl>, med_biomass_lic <dbl>,\n#   med_landfillGas_lic <dbl>, med_sun_lic <dbl>, med_reservoir_lic <dbl>,\n#   med_others_lic <dbl>, med_wind_ul <dbl>, med_biogas_ul <dbl>,\n#   med_canalType_ul <dbl>, med_biomass_ul <dbl>, med_sun_ul <dbl>,\n#   med_others_ul <dbl>"
  },
  {
    "objectID": "dplyr.html#mini-lubridate-tutorial",
    "href": "dplyr.html#mini-lubridate-tutorial",
    "title": "2  Introduction to dplyr 1.0.0: Turkish Renewable Energy Production Data",
    "section": "7.1 Mini lubridate tutorial",
    "text": "7.1 Mini lubridate tutorial\nIn this tutorial we use a small portion of a very powerful package, lubridate. You can see the official website here.\nLet’s take just 3 dates at random from our data set.\n\nset.seed(5)\nlub_df <- \nraw_df %>% \n  select(dt) %>%\n  sample_n(3)\n\nprint(lub_df)\n\n# A tibble: 3 × 1\n  dt                 \n  <dttm>             \n1 2018-12-02 06:00:00\n2 2019-01-12 05:00:00\n3 2018-04-16 09:00:00\n\n\nSince we called lubridate at the beginning of this tutorial we do not need to call by package reference (lubridate::) but it is generally good practice.\n\nlub_df %>% \n  mutate(\n    year = lubridate::year(dt),\n    month = lubridate::month(dt),\n    day = lubridate::day(dt),\n    week_day = lubridate::wday(dt),\n    wday_label = lubridate::wday(dt,label=TRUE),\n    hour = lubridate::hour(dt),\n    minute = lubridate::minute(dt),\n    second = lubridate::second(dt)\n  )\n\n# A tibble: 3 × 9\n  dt                   year month   day week_day wday_label  hour minute second\n  <dttm>              <dbl> <dbl> <int>    <dbl> <ord>      <int>  <int>  <dbl>\n1 2018-12-02 06:00:00  2018    12     2        1 Sun            6      0      0\n2 2019-01-12 05:00:00  2019     1    12        7 Sat            5      0      0\n3 2018-04-16 09:00:00  2018     4    16        2 Mon            9      0      0"
  },
  {
    "objectID": "dplyr.html#fundamentals",
    "href": "dplyr.html#fundamentals",
    "title": "2  dplyr",
    "section": "2.2 Fundamentals",
    "text": "2.2 Fundamentals\nIn this chapter fundamental functions of dplyr are introduced. Every function will be used in the following examples after it has been introduced. To limit the number of displayed rows, we use the following global option. You can ignore this part in your exercises.\n\noptions(tibble.print_max = 3, tibble.print_min = 3)\n\n\n2.2.1 select/rename\nSelect, as the name suggests, is used to select columns. For instance, suppose we only want licensed wind production (wind_lic) and date-time (dt) columns.\n\nraw_df %>% select(dt,wind_lic)\n\n# A tibble: 21,168 × 2\n  dt                  wind_lic\n  <dttm>                 <dbl>\n1 2020-05-31 23:00:00    1434.\n2 2020-05-31 22:00:00    1577.\n3 2020-05-31 21:00:00    1858.\n# … with 21,165 more rows\n\n\nIf we wanted to write the above expression without the pipe operator, we could go with the sad expression below. You can extrapolate how complicated things can be without the pipe.\n\nselect(raw_df,dt,wind_lic)\n\nWe can use rename to rename columns (again as the name suggests). Let’s change dt to date_time.\n\nraw_df %>% rename(date_time = dt)\n\n# A tibble: 21,168 × 17\n  date_time           wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2020-05-31 23:00:00    1434.           913.       75.8         2585.\n2 2020-05-31 22:00:00    1577.           908.       75.6         2631.\n3 2020-05-31 21:00:00    1858.           901.       75.4         2585.\n# … with 21,165 more rows, and 12 more variables: riverType_lic <dbl>,\n#   biomass_lic <dbl>, landfillGas_lic <dbl>, sun_lic <dbl>,\n#   reservoir_lic <dbl>, others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>,\n#   canalType_ul <dbl>, biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>\n\n\np.s. We can rename columns inside select function.\nSelect has many convenient sub operators and special expressions. If we know the order of columns, we can use the scope (:) expression to get all the columns determined by the scope. Suppose, we want date-time (dt) and licensed production.\n\nraw_df %>% select(date_time=dt,wind_lic:others_lic)\n\n# A tibble: 21,168 × 11\n  date_time           wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2020-05-31 23:00:00    1434.           913.       75.8         2585.\n2 2020-05-31 22:00:00    1577.           908.       75.6         2631.\n3 2020-05-31 21:00:00    1858.           901.       75.4         2585.\n# … with 21,165 more rows, and 6 more variables: riverType_lic <dbl>,\n#   biomass_lic <dbl>, landfillGas_lic <dbl>, sun_lic <dbl>,\n#   reservoir_lic <dbl>, others_lic <dbl>\n\n\nWe can eliminate unwanted columns by putting - before the names. Suppose I am not interested in wind values, want to remove all other related columns from the data set, and all other related column names start with “wind_”. We can do it using - and starts_with.\n\nraw_df %>% select(-starts_with(\"wind_\")) \n\n# A tibble: 21,168 × 15\n  dt                  geothermal_lic biogas_lic canalType_lic riverType_lic\n  <dttm>                       <dbl>      <dbl>         <dbl>         <dbl>\n1 2020-05-31 23:00:00           913.       75.8         2585.          317.\n2 2020-05-31 22:00:00           908.       75.6         2631.          317.\n3 2020-05-31 21:00:00           901.       75.4         2585.          357.\n# … with 21,165 more rows, and 10 more variables: biomass_lic <dbl>,\n#   landfillGas_lic <dbl>, sun_lic <dbl>, reservoir_lic <dbl>,\n#   others_lic <dbl>, biogas_ul <dbl>, canalType_ul <dbl>, biomass_ul <dbl>,\n#   sun_ul <dbl>, others_ul <dbl>\n\n\nThere are similar expressions for other purposes, such as starts_with, everything and contains. You can see all the expressions in the Cheat Sheet link given at the end of this document.\ndplyr 1.0.0 Feature: Sometimes you just want to change the order of the columns. Then use relocate. Suppose we want to show solar and wind production with date-time. But we want to get licensed wind together with licensed solar.\n\nraw_df %>% select(dt,starts_with(\"sun_\"),starts_with(\"wind\")) %>% relocate(wind_lic,.before=sun_ul)\n\n# A tibble: 21,168 × 5\n  dt                  sun_lic wind_lic sun_ul wind_ul\n  <dttm>                <dbl>    <dbl>  <dbl>   <dbl>\n1 2020-05-31 23:00:00       0    1434. 0.0582    3.78\n2 2020-05-31 22:00:00       0    1577. 0.032     4.84\n3 2020-05-31 21:00:00       0    1858. 0.0335    7.67\n# … with 21,165 more rows\n\n\nIf we specify nothing, it will be in the first place.\n\nraw_df %>% select(dt,starts_with(\"sun_\"),starts_with(\"wind\")) %>% relocate(wind_lic)\n\n# A tibble: 21,168 × 5\n  wind_lic dt                  sun_lic sun_ul wind_ul\n     <dbl> <dttm>                <dbl>  <dbl>   <dbl>\n1    1434. 2020-05-31 23:00:00       0 0.0582    3.78\n2    1577. 2020-05-31 22:00:00       0 0.032     4.84\n3    1858. 2020-05-31 21:00:00       0 0.0335    7.67\n# … with 21,165 more rows\n\n\nWe use last_col() if we want to take a column to the end.\n\nraw_df %>% select(dt,starts_with(\"sun_\"),starts_with(\"wind\")) %>% relocate(dt,.after=last_col())\n\n# A tibble: 21,168 × 5\n  sun_lic sun_ul wind_lic wind_ul dt                 \n    <dbl>  <dbl>    <dbl>   <dbl> <dttm>             \n1       0 0.0582    1434.    3.78 2020-05-31 23:00:00\n2       0 0.032     1577.    4.84 2020-05-31 22:00:00\n3       0 0.0335    1858.    7.67 2020-05-31 21:00:00\n# … with 21,165 more rows\n\n\nHonestly, relocate is a very convenient function.\n\n2.2.1.1 select/rename advanced usage\nAdvanced usage subsection introduces extra functionality which can be a bit confusing at the first phase. But, once you get a grasp on the fundamentals check back here as reference. There are several features not available for versions before dplyr 1.0.0.\nWe can use rename_with function to rename columns with given criteria. In pipe version of the function, first parameter is the function and the second parameter is the criterion. Let’s replace all “Type” with “_type”. For instance it should change “canalType” to “canal_type”.\n\nraw_df %>% rename_with(~gsub(\"Type\",\"_type\",.),contains(\"Type\")) %>% glimpse()\n\nRows: 21,168\nColumns: 17\n$ dt              <dttm> 2020-05-31 23:00:00, 2020-05-31 22:00:00, 2020-05-31 …\n$ wind_lic        <dbl> 1433.8132, 1577.1419, 1857.5492, 1933.0142, 2031.7862,…\n$ geothermal_lic  <dbl> 912.7882, 907.9303, 900.5844, 888.4561, 864.5402, 847.…\n$ biogas_lic      <dbl> 75.8047, 75.6163, 75.3906, 76.7873, 76.9707, 77.5750, …\n$ canal_type_lic  <dbl> 2584.930, 2630.602, 2585.038, 2542.381, 2594.459, 2622…\n$ river_type_lic  <dbl> 316.5538, 316.6800, 356.7637, 350.1544, 377.5312, 379.…\n$ biomass_lic     <dbl> 262.4994, 253.0814, 246.9268, 249.9152, 248.2336, 246.…\n$ landfillGas_lic <dbl> 100.3971, 101.1378, 100.4442, 100.7307, 102.2474, 102.…\n$ sun_lic         <dbl> 0.0000, 0.0000, 0.0000, 0.0000, 2.0594, 14.2800, 48.09…\n$ reservoir_lic   <dbl> 2306.303, 2296.045, 2279.266, 2308.918, 2792.313, 3180…\n$ others_lic      <dbl> 48.3833, 48.4011, 48.4041, 48.4199, 48.4653, 48.5485, …\n$ wind_ul         <dbl> 3.7751, 4.8375, 7.6659, 11.8121, 13.1070, 13.1830, 10.…\n$ biogas_ul       <dbl> 16.9293, 16.9227, 16.9052, 16.7517, 16.2928, 16.5989, …\n$ canal_type_ul   <dbl> 4.1749, 4.4221, 4.4658, 4.6020, 4.6195, 4.5146, 4.6616…\n$ biomass_ul      <dbl> 15.4698, 15.3609, 16.0483, 15.2271, 15.5563, 15.5007, …\n$ sun_ul          <dbl> 0.0582, 0.0320, 0.0335, 1.3121, 103.3267, 555.5787, 14…\n$ others_ul       <dbl> 0.0610, 0.0395, 0.4136, 0.5508, 0.7106, 1.3775, 2.7468…\n\n\nDid you notice ~ and . in the function? Dot (.) is a representation of the entity. Depending on the situation it can be the latest version of the tibble in the pipe chain, a specific column or something else. ~ is a special character notifying that function evaluation will be done using the dot notation. We will see more examples of that.\nLet’s introduce where. If is a function from tidyselect package to select variables with a function where it returns TRUE. It is quite handy.\n\nraw_df %>% select(dt,starts_with(\"sun_\"),starts_with(\"wind\")) %>% relocate(where(is.numeric))\n\n# A tibble: 21,168 × 5\n  sun_lic sun_ul wind_lic wind_ul dt                 \n    <dbl>  <dbl>    <dbl>   <dbl> <dttm>             \n1       0 0.0582    1434.    3.78 2020-05-31 23:00:00\n2       0 0.032     1577.    4.84 2020-05-31 22:00:00\n3       0 0.0335    1858.    7.67 2020-05-31 21:00:00\n# … with 21,165 more rows\n\n\nWe can also use any_of or all_of functions in select. The main difference is while the former returns as much as it can, the latter will throw an error if any one of the criteria is not fulfilled. Let’s try to select “dt”, “others_lic” and “nuclear_lic”. Since this data does not include nuclear power production we should not see it.\n\nraw_df %>% select(any_of(c(\"dt\",\"others_lic\",\"nuclear_lic\")))\n\n# A tibble: 21,168 × 2\n  dt                  others_lic\n  <dttm>                   <dbl>\n1 2020-05-31 23:00:00       48.4\n2 2020-05-31 22:00:00       48.4\n3 2020-05-31 21:00:00       48.4\n# … with 21,165 more rows\n\n\nIn order not to break our notebook, we wrap it around try (error handling is another topic).\n\ntry(raw_df %>% select(all_of(c(\"dt\",\"others_lic\",\"nuclear_lic\"))))\n\nError : Can't subset columns that don't exist.\n✖ Column `nuclear_lic` doesn't exist.\n\n\n\n\n\n2.2.2 filter/distinct\nFilter (no more “as the name suggests”, as you already figured it out) helps filter rows according to given criteria. It is highly similar with Excel’s filter functionality (but much much more flexible and reliable).\nLet’s see the production at 2020-05-08 16:00:00.\n\nraw_df %>% filter(dt == \"2020-05-08 16:00:00\")\n\n# A tibble: 1 × 17\n  dt                  wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2020-05-08 16:00:00    2618.           856.       79.8         3896.\n# … with 12 more variables: riverType_lic <dbl>, biomass_lic <dbl>,\n#   landfillGas_lic <dbl>, sun_lic <dbl>, reservoir_lic <dbl>,\n#   others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>, canalType_ul <dbl>,\n#   biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>\n\n\nBy using == operator, we bring the values in dt column which are equal to the hour we desired. There are other expressions such as not equal to (!=), greater than (or equal to) (>,>=), smaller than (or equal to) (<,<=), in (%in%) and some more.\nAt the same time we can make comparisons between columns and combine multiple criteria to create more complex filters. Here we use AND (&) and OR (|) operators to combine criteria.\nSuppose we want to find our the times when licensed wind production is greater than all of hydro type licensed production.\n\nraw_df %>% filter(wind_lic > canalType_lic & wind_lic > reservoir_lic & wind_lic > riverType_lic)\n\n# A tibble: 11,287 × 17\n  dt                  wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2020-05-27 19:00:00    3303.           930.       74.7         2969.\n2 2020-05-27 18:00:00    3596.           914.       75.0         2953.\n3 2020-05-27 17:00:00    3551.           900.       76.3         2954.\n# … with 11,284 more rows, and 12 more variables: riverType_lic <dbl>,\n#   biomass_lic <dbl>, landfillGas_lic <dbl>, sun_lic <dbl>,\n#   reservoir_lic <dbl>, others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>,\n#   canalType_ul <dbl>, biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>\n\n\nWe can add numeric operations as well. Suppose we want to find the total solar production is greater than total wind production.\n\nraw_df %>% filter(wind_lic + wind_ul < sun_lic + sun_ul)\n\n# A tibble: 4,949 × 17\n  dt                  wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2020-05-31 16:00:00    2036.           843.       76.8         2616.\n2 2020-05-31 15:00:00    1875.           845.       77.4         2685.\n3 2020-05-31 14:00:00    1755.           853.       77.2         2715.\n# … with 4,946 more rows, and 12 more variables: riverType_lic <dbl>,\n#   biomass_lic <dbl>, landfillGas_lic <dbl>, sun_lic <dbl>,\n#   reservoir_lic <dbl>, others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>,\n#   canalType_ul <dbl>, biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>\n\n\nSuppose we want to filter only the unique values. Then we simply use distinct command. Let’s get unique rounded licensed wind production values.\n\nraw_df %>% distinct(round(wind_lic))\n\n# A tibble: 4,893 × 1\n  `round(wind_lic)`\n              <dbl>\n1              1434\n2              1577\n3              1858\n# … with 4,890 more rows\n\n\nIf we want to keep all columns we simply make the parameter .keep=TRUE.\n\nraw_df %>% distinct(round(wind_lic),.keep=TRUE)\n\n# A tibble: 4,893 × 2\n  `round(wind_lic)` .keep\n              <dbl> <lgl>\n1              1434 TRUE \n2              1577 TRUE \n3              1858 TRUE \n# … with 4,890 more rows\n\n\n\n2.2.2.1 filter/distinct advanced usage\nLet’s introduce slice. This function helps return rows by its row number. Suppose we want the top 5 rows.\n\nraw_df %>% slice(1:5) %>% print(n=5)\n\n# A tibble: 5 × 17\n  dt                  wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2020-05-31 23:00:00    1434.           913.       75.8         2585.\n2 2020-05-31 22:00:00    1577.           908.       75.6         2631.\n3 2020-05-31 21:00:00    1858.           901.       75.4         2585.\n4 2020-05-31 20:00:00    1933.           888.       76.8         2542.\n5 2020-05-31 19:00:00    2032.           865.       77.0         2594.\n# … with 12 more variables: riverType_lic <dbl>, biomass_lic <dbl>,\n#   landfillGas_lic <dbl>, sun_lic <dbl>, reservoir_lic <dbl>,\n#   others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>, canalType_ul <dbl>,\n#   biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>\n\n\nIf we want to return random rows we have slice_sample. Let’s bring 5 random rows.\n\nraw_df %>% slice_sample(n=5)\n\n# A tibble: 5 × 17\n  dt                  wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2019-08-15 13:00:00    2163.           669.       77.6          840.\n2 2018-07-24 13:00:00    1399.           550.       60.8          954.\n3 2018-05-01 08:00:00    1119.           702.       65.2         2004.\n# … with 2 more rows, and 12 more variables: riverType_lic <dbl>,\n#   biomass_lic <dbl>, landfillGas_lic <dbl>, sun_lic <dbl>,\n#   reservoir_lic <dbl>, others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>,\n#   canalType_ul <dbl>, biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>\n\n\nIf we want to do it proportionately, we have the prop parameter. Let’s say we want 0.1% of the data frame.\n\nraw_df %>% slice_sample(prop=0.001)\n\n# A tibble: 21 × 17\n  dt                  wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2018-07-26 15:00:00    1346.           555.       61.3          956.\n2 2020-05-24 20:00:00    2550.           876.       75.7         3080.\n3 2019-04-15 20:00:00    2503.           837.       83.1         4406.\n# … with 18 more rows, and 12 more variables: riverType_lic <dbl>,\n#   biomass_lic <dbl>, landfillGas_lic <dbl>, sun_lic <dbl>,\n#   reservoir_lic <dbl>, others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>,\n#   canalType_ul <dbl>, biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>\n\n\nThere are other slice_* type functions. These are slice_head/slice_tail for first/last n or percentage of rows. slice_min/slice_max for the top/bottom n rows according to an ordering criteria.\n\n\n\n2.2.3 arrange\nArrange sorts rows from A to Z or smallest to largest. It has great similarity with Excel’s Sort functionality.\nLet’s sort licensed reservoir production from largest to smallest.\n\nraw_df %>% select(dt,reservoir_lic) %>% arrange(desc(reservoir_lic))\n\n# A tibble: 21,168 × 2\n  dt                  reservoir_lic\n  <dttm>                      <dbl>\n1 2019-05-10 23:00:00         5058.\n2 2019-05-10 21:00:00         5035.\n3 2019-05-15 02:00:00         5019.\n# … with 21,165 more rows\n\n\nDo you see desc() function inside arrange? By default arrange sorts a column by first to last or A-Z. desc reverses this.\nYou can also use multiple sorting criteria and use operations inside arrange. Let’s arrange by licensed wind production rounded down (floor) in 100s range (e.g. 5634 = 5600 and 5693 = 5600 as well). Then we sort by date time to see the first time the production entered a 100-range in the data time period.\n\nraw_df %>% arrange(desc(floor(wind_lic/100)*100),dt)\n\n# A tibble: 21,168 × 17\n  dt                  wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2019-09-15 17:00:00    5767.           691.       83.0          922.\n2 2018-09-26 19:00:00    5622.           672.       67.8          951.\n3 2019-09-15 15:00:00    5628.           692.       81.4          901.\n# … with 21,165 more rows, and 12 more variables: riverType_lic <dbl>,\n#   biomass_lic <dbl>, landfillGas_lic <dbl>, sun_lic <dbl>,\n#   reservoir_lic <dbl>, others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>,\n#   canalType_ul <dbl>, biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>\n\n\n\n\n2.2.4 mutate/transmute\nMutate is the function when we do operations and calculations using other columns.\nFor instance let’s calculate wind power’s share in total renewables production at each hour.\n\nraw_df %>% mutate(wind_lic_perc = wind_lic / (wind_lic + geothermal_lic + biogas_lic + canalType_lic + riverType_lic + biomass_lic + landfillGas_lic + sun_lic + reservoir_lic + others_lic + wind_ul + biogas_ul + canalType_ul + biomass_ul + sun_ul + others_ul)) %>% select(dt, wind_lic_perc)\n\n# A tibble: 21,168 × 2\n  dt                  wind_lic_perc\n  <dttm>                      <dbl>\n1 2020-05-31 23:00:00         0.177\n2 2020-05-31 22:00:00         0.191\n3 2020-05-31 21:00:00         0.219\n# … with 21,165 more rows\n\n\nYou can use many R functions (from both base functions and other packages). For instance to calculate “competition” wind and solar we can use the following expression.\n\nraw_df %>% mutate(wind_or_solar = ifelse(wind_lic + wind_ul > sun_lic + sun_ul, \"wind\", \"solar\")) %>% select(dt,wind_or_solar)\n\n# A tibble: 21,168 × 2\n  dt                  wind_or_solar\n  <dttm>              <chr>        \n1 2020-05-31 23:00:00 wind         \n2 2020-05-31 22:00:00 wind         \n3 2020-05-31 21:00:00 wind         \n# … with 21,165 more rows\n\n\nTransmute has the same functionality as mutate with the additional property similar to select. Transmute returns only the columns included in the function. Suppose we also want to calculate the difference between total wind and total solar.\n\nraw_df %>% transmute(dt, wind_or_solar = ifelse(wind_lic + wind_ul > sun_lic + sun_ul, \"wind\", \"solar\"), absdiff = abs(wind_lic + wind_ul - sun_lic - sun_ul))\n\n# A tibble: 21,168 × 3\n  dt                  wind_or_solar absdiff\n  <dttm>              <chr>           <dbl>\n1 2020-05-31 23:00:00 wind            1438.\n2 2020-05-31 22:00:00 wind            1582.\n3 2020-05-31 21:00:00 wind            1865.\n# … with 21,165 more rows\n\n\n\n2.2.4.1 mutate/transmute advanced usage\nSuppose we want to see the difference between the previous and next hour’s production. We offset rows using lead and lag functions. But remember lead and lag does not actually give you “next/previous hour’s” values, just the rows. You may need to arrange your data.\n\nraw_df %>% transmute(dt, wind_lic, wind_lic_prev_h = lead(wind_lic,1), wind_lic_next_h = lag(wind_lic,1))\n\n# A tibble: 21,168 × 4\n  dt                  wind_lic wind_lic_prev_h wind_lic_next_h\n  <dttm>                 <dbl>           <dbl>           <dbl>\n1 2020-05-31 23:00:00    1434.           1577.             NA \n2 2020-05-31 22:00:00    1577.           1858.           1434.\n3 2020-05-31 21:00:00    1858.           1933.           1577.\n# … with 21,165 more rows\n\n\nIf you want to use the same function over several columns, you can use the new across function. Let’s round every numeric column to one significant digit.\n\nraw_df %>% mutate(across(where(is.numeric),~round(.,1)))\n\n# A tibble: 21,168 × 17\n  dt                  wind_lic geothermal_lic biogas_lic canalType_lic\n  <dttm>                 <dbl>          <dbl>      <dbl>         <dbl>\n1 2020-05-31 23:00:00    1434.           913.       75.8         2585.\n2 2020-05-31 22:00:00    1577.           908.       75.6         2631.\n3 2020-05-31 21:00:00    1858.           901.       75.4         2585 \n# … with 21,165 more rows, and 12 more variables: riverType_lic <dbl>,\n#   biomass_lic <dbl>, landfillGas_lic <dbl>, sun_lic <dbl>,\n#   reservoir_lic <dbl>, others_lic <dbl>, wind_ul <dbl>, biogas_ul <dbl>,\n#   canalType_ul <dbl>, biomass_ul <dbl>, sun_ul <dbl>, others_ul <dbl>\n\n\nWe can also specify columns. Let’s see the comparative production of wind and reservoir hydro against the unlicensed solar production. We just increment solar production by 1 to prevent any infinity values.\n\nraw_df %>% mutate(sun_ul = sun_ul + 1) %>% transmute(dt,across(c(wind_lic,reservoir_lic),~round(./sun_ul,2)))\n\n# A tibble: 21,168 × 3\n  dt                  wind_lic reservoir_lic\n  <dttm>                 <dbl>         <dbl>\n1 2020-05-31 23:00:00    1355.         2179.\n2 2020-05-31 22:00:00    1528.         2225.\n3 2020-05-31 21:00:00    1797.         2205.\n# … with 21,165 more rows\n\n\nIf there are multiple conditions ifelse is not enough. It is possible to use case_when to specify multiple conditions and outcomes.\n\nraw_df %>% transmute(dt, solar_production_level = case_when(sun_ul > quantile(sun_ul,0.9) ~ \"very high\", sun_ul > quantile(sun_ul, 0.75) ~ \"high\", sun_ul > quantile(sun_ul, 0.5) ~ \"above median\", TRUE ~ \"below median\"))  %>% slice(7:9)\n\n# A tibble: 3 × 2\n  dt                  solar_production_level\n  <dttm>              <chr>                 \n1 2020-05-31 17:00:00 above median          \n2 2020-05-31 16:00:00 high                  \n3 2020-05-31 15:00:00 very high             \n\n\nrowwise is actually a type of group_by/summarise function but as the name suggests it allows us to do row-wise operations. Let’s calculate row sums by using c_across function and rowwise. Oh and also now, experimentally, you can use relocate functionality in mutate/transmute. So, conveniently we can place it after date time.\n\nraw_df %>% slice_head(n=5) %>% rowwise() %>% mutate(total_prod = sum(c_across(where(is.numeric))),.after=dt)\n\n# A tibble: 5 × 18\n# Rowwise: \n  dt                  total_prod wind_lic geothermal_lic biogas_lic\n  <dttm>                   <dbl>    <dbl>          <dbl>      <dbl>\n1 2020-05-31 23:00:00      8082.    1434.           913.       75.8\n2 2020-05-31 22:00:00      8248.    1577.           908.       75.6\n3 2020-05-31 21:00:00      8496.    1858.           901.       75.4\n# … with 2 more rows, and 13 more variables: canalType_lic <dbl>,\n#   riverType_lic <dbl>, biomass_lic <dbl>, landfillGas_lic <dbl>,\n#   sun_lic <dbl>, reservoir_lic <dbl>, others_lic <dbl>, wind_ul <dbl>,\n#   biogas_ul <dbl>, canalType_ul <dbl>, biomass_ul <dbl>, sun_ul <dbl>,\n#   others_ul <dbl>\n\n\n\n\n\n2.2.5 group_by/summarise\nFinally we will learn how to calculate summary tables. It is similar to Pivot Tables in Excel. group_by is the grouping function, summarise is the summarising function.\nFor instance let’s calculate number of hours where wind production is above 3000 MWh. We will use a special function n() to calculate number of rows. We can define groupings just like mutate.\n\nraw_df %>% group_by(production_group = cut(wind_lic + wind_ul,breaks=c(0,1000,2000,3000,4000,5000,6000),include.lowest = TRUE)) %>% summarise(count = n())\n\n# A tibble: 6 × 2\n  production_group count\n  <fct>            <int>\n1 [0,1e+03]         4294\n2 (1e+03,2e+03]     5733\n3 (2e+03,3e+03]     4725\n# … with 3 more rows\n\n\nNormally, we get one result for each group and summary function. From dplyr 1.0.0 we can have multiple row summarise for each group. Let’s say we want to find the minimum and maximum licensed wind production ranges for each year. But, be warned, it can be a little confusing.\n\nraw_df %>% group_by(year = lubridate::year(dt)) %>% summarise(wind_lic_range = range(wind_lic))\n\n`summarise()` has grouped output by 'year'. You can override using the `.groups` argument.\n\n\n# A tibble: 6 × 2\n# Groups:   year [3]\n   year wind_lic_range\n  <dbl>          <dbl>\n1  2018           46.2\n2  2018         5622. \n3  2019           32.8\n# … with 3 more rows\n\n\n\n2.2.5.1 group_by/summarise advanced usage\nJust like mutate/transmute you can use across in summarise as well. Let’s see median production of each year and each source. In this example we can also use the named list version of the functions and additional names structure.\n\nraw_df %>% group_by(year = lubridate::year(dt)) %>% summarise(across(where(is.numeric),list(med=median),.names=\"{fn}_{col}\"))\n\n# A tibble: 3 × 17\n   year med_wind_lic med_geothermal_lic med_biogas_lic med_canalType_lic\n  <dbl>        <dbl>              <dbl>          <dbl>             <dbl>\n1  2018        1989.               694.           66.4             1480.\n2  2019        2136.               814.           80.9             1575.\n3  2020        2297.               951.           78.5             2779.\n# … with 12 more variables: med_riverType_lic <dbl>, med_biomass_lic <dbl>,\n#   med_landfillGas_lic <dbl>, med_sun_lic <dbl>, med_reservoir_lic <dbl>,\n#   med_others_lic <dbl>, med_wind_ul <dbl>, med_biogas_ul <dbl>,\n#   med_canalType_ul <dbl>, med_biomass_ul <dbl>, med_sun_ul <dbl>,\n#   med_others_ul <dbl>"
  },
  {
    "objectID": "dplyr.html#exercises",
    "href": "dplyr.html#exercises",
    "title": "2  dplyr",
    "section": "2.3 Exercises",
    "text": "2.3 Exercises\nSolve the following exercises. Outputs are given below, you are expected write code to match the outputs.\n\nFind the mean and standard deviation of licensed geothermal productions in all years. (Tip: Use lubridate::year to get years from date data.)\n\n\n\n# A tibble: 3 × 3\n   year mean_geo sd_geo\n  <dbl>    <dbl>  <dbl>\n1  2018     681.   65.2\n2  2019     799.   74.2\n3  2020     935.   59.0\n\n\n\nFind the hourly average unlicensed solar (sun_ul) production levels for May 2020.\n\n\n\n# A tibble: 24 × 2\n   hour avg_prod\n  <int>    <dbl>\n1     0     0.17\n2     1     0.37\n3     2     0.7 \n# … with 21 more rows\n\n\n\nFind the average daily percentage change of licensed biomass (biomass_lic) in 2019. (e.g. Suppose daily production is 50 in day 1 and 53 in day 2, then the change should be (53-50)/50 -1 = 0.06) (Tip: Use lubridate::as_date to convert date time to date. Use lag and lead functions to offset values.)\n\n\n\n# A tibble: 1 × 1\n  average_change\n           <dbl>\n1        0.00282\n\n\n\nFind the yearly total production levels in TWh (Current values are in MWh. 1 GWh is 1000 MWh and 1 TWh is 1000 GWh). (Tip: In order to avoid a lengthy summation you can use tidyr::pivot_longer to get a long format.)\n\n\n\n# A tibble: 3 × 2\n   year total_production\n  <dbl>            <dbl>\n1  2018             62.6\n2  2019             76.7\n3  2020             37.3"
  },
  {
    "objectID": "dplyr.html#conclusion",
    "href": "dplyr.html#conclusion",
    "title": "2  dplyr",
    "section": "2.4 Conclusion",
    "text": "2.4 Conclusion\nFundamental dplyr functions provide very convenient tools for data analysis. It can also be used to generate the features required for modelling. You can process few million rows of data without breaking a sweat (for larger data sets you can use data.table), you can prepare functions instead of manual Excel operations. With R Markdown system, which this tutorial is prepared in, you can create reproducible documents and automatize the reports. You can use ggplot2 for visualizations, which is also part of the tidyverse package ecosystem."
  },
  {
    "objectID": "dplyr.html#appendix",
    "href": "dplyr.html#appendix",
    "title": "2  dplyr",
    "section": "2.5 Appendix",
    "text": "2.5 Appendix\n\n2.5.1 Mini lubridate tutorial\nIn this tutorial we use a small portion of a very powerful package, lubridate. You can see the official website here.\nLet’s take just 3 dates at random from our data set.\n\nset.seed(5)\nlub_df <- \nraw_df %>% \n  select(dt) %>%\n  sample_n(3)\n\nprint(lub_df)\n\n# A tibble: 3 × 1\n  dt                 \n  <dttm>             \n1 2018-12-02 06:00:00\n2 2019-01-12 05:00:00\n3 2018-04-16 09:00:00\n\n\nSince we called lubridate at the beginning of this tutorial we do not need to call by package reference (lubridate::) but it is generally good practice.\n\nlub_df %>% \n  mutate(\n    year = lubridate::year(dt),\n    month = lubridate::month(dt),\n    day = lubridate::day(dt),\n    week_day = lubridate::wday(dt),\n    wday_label = lubridate::wday(dt,label=TRUE),\n    hour = lubridate::hour(dt),\n    minute = lubridate::minute(dt),\n    second = lubridate::second(dt)\n  )\n\n# A tibble: 3 × 9\n  dt                   year month   day week_day wday_label  hour minute second\n  <dttm>              <dbl> <dbl> <int>    <dbl> <ord>      <int>  <int>  <dbl>\n1 2018-12-02 06:00:00  2018    12     2        1 Sun            6      0      0\n2 2019-01-12 05:00:00  2019     1    12        7 Sat            5      0      0\n3 2018-04-16 09:00:00  2018     4    16        2 Mon            9      0      0"
  },
  {
    "objectID": "dplyr.html#references",
    "href": "dplyr.html#references",
    "title": "2  dplyr",
    "section": "2.6 References",
    "text": "2.6 References\n\nData Set: EPIAS/EXIST Transparency Platform\nTidyverse: https://www.tidyverse.org/\nR for Data Science: https://r4ds.had.co.nz/\nCheatsheet (Data Transformation) (Turkish Version)"
  },
  {
    "objectID": "reticulate.html",
    "href": "reticulate.html",
    "title": "Using Python and R Together",
    "section": "",
    "text": "In the ever-increasing requirements era of data science, Python is one of the fundamental tools that a data scientist should know about. Even though R is quite elegant and enough in many data related applications, a mix of Python might also be required to get the job done. One of the reasons is to benefit from API connections because Python enjoys first class support (e.g. native SDK) in many services. For instance, using boto3 package for AWS was quite useful (before the paws R package).\nRStudio especially positions itself as “A Single Home for R and Python Data Science” in their blog post. It is also the main reason why they created and support the reticulate R package. Before reticulate, Python integration was still possible but much more difficult in many aspects. It still might have quirks but reticulate provides much better integration.\nIn this tutorial, we are going to do simple examples using reticulate package. This tutorial is not exhaustive. For better coverage, check the official package page."
  },
  {
    "objectID": "reticulate.html#initialization",
    "href": "reticulate.html#initialization",
    "title": "Using Python and R Together",
    "section": "Initialization",
    "text": "Initialization\nIt always starts with the loading of the package.\n\nlibrary(reticulate)\n\nPython has multiple versions (thankfully they phased out Python 2 but still a pain in many operating systems) You can learn the current python version PATH using Sys.which function. Output will differ in different systems and installations.\n\nSys.which(\"python\")\n\n                                            python \n\"/opt/homebrew/Caskroom/miniforge/base/bin/python\" \n\n\nFor better detail, py_config is a good function. Output will differ in different systems and installations.\n\npy_config()\n\npython:         /opt/homebrew/Caskroom/miniforge/base/bin/python3\nlibpython:      /opt/homebrew/Caskroom/miniforge/base/lib/libpython3.9.dylib\npythonhome:     /opt/homebrew/Caskroom/miniforge/base:/opt/homebrew/Caskroom/miniforge/base\nversion:        3.9.10 | packaged by conda-forge | (main, Feb  1 2022, 21:27:43)  [Clang 11.1.0 ]\nnumpy:          /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/numpy\nnumpy_version:  1.22.4\n\npython versions found: \n /opt/homebrew/Caskroom/miniforge/base/bin/python3\n /opt/homebrew/Caskroom/miniforge/base/bin/python\n\n\nFor available configurations py_discover_config can be used.\n\npy_discover_config()\n\nreticulate can use other python installations, virtual environments and conda versions. Although it is a great convenience, intricacies and delicateness of Python versions might still hurt your workflows.\n\nuse_python() ## python path\nuse_virtualenv() ## virtual environment name\nuse_condaenv() ## conda environment"
  },
  {
    "objectID": "reticulate.html#methods-and-examples",
    "href": "reticulate.html#methods-and-examples",
    "title": "Using Python and R Together",
    "section": "Methods and Examples",
    "text": "Methods and Examples\nIn this section we will see some methodologies to use with reticulate.\n\nCall Python functions R style\nThis is the fundamental and (in my opinion) worst way to benefit from Python in R. Because translation of style is imperfect and might not work in every case.\nHere is an example with pandas.\n\n## similar to import pandas as pd\npd <- import(\"pandas\") \n## create a simple dataframe \ndf_pandas <- pd$DataFrame(data=list(col1=c(2,1,3),col2=c(\"a\",\"b\",\"c\"))) \n\ndf_pandas\n\n  col1 col2\n1    2    a\n2    1    b\n3    3    c\n\n\nLet’s try a simple example.\n\nos <- import(\"os\")\nos$path$join(\"a\",\"b\",\"c\")\n\n[1] \"a/b/c\"\n\n\nCaveats: Some functions working on console might not work on RMarkdown\n\ntry(df_pandas$sort_values(\"col1\"))\n\nError in try(df_pandas$sort_values(\"col1\")) : \n  attempt to apply non-function\n\n\n\n## filter using query fails both on console and rmarkdown\ntry(df_pandas$query('col1 > 1.0'))\n\nError in try(df_pandas$query(\"col1 > 1.0\")) : \n  attempt to apply non-function\n\n\n\n\nCall Python in RMarkdown chunk\nThe format is similar to an R chunk but instead of r write python.\n\n\n```{python}\n#your python code here\n```\n\n\nHere is an example\n\nimport os\nos.path.join(\"a\",\"b\",\"c\")\n\n'a/b/c'\n\n\nOur pandas examples also works in this case.\n\nimport pandas as pd\n\npandas_df_py = pd.DataFrame(data={'col1':[2,1,3],'col2':['a','b','c']}) \n\npandas_df_py\n\n   col1 col2\n0     2    a\n1     1    b\n2     3    c\n\n\n\npandas_df_py.sort_values('col1')\n\n   col1 col2\n1     1    b\n0     2    a\n2     3    c\n\n\n\n## filter using query fails both on console and rmarkdown\npandas_df_py.query('col1 > 1.0')\n\n   col1 col2\n0     2    a\n2     3    c\n\n\n\n\nSource Python Script\nPersonally, the most convenient way to use Python code is to source a .py file. Even though interoperability is a great idea, keeping Python and R codes as separate as possible will save you from a lot of headache in the future (at least with the current implementation).\nWe can source any python file using source_python() function easily. Let’s name our python file triangle.py and write the following.\n\ndef area_of_triangle(h,x):\n  return h*x/2\n\n\narea_of_triangle(3,5)\n\n7.5\n\n\nFollow\n\nreticulate::source_python(\"triangle.py\") ### Remember to provide proper relative or absolute path.\n\nNote: For RMarkdown demonstration purposes below we;\n\ncreated a temporary file\nwrote our python function to that file using cat\nthen executed source_python\nthen called the function as R function\n\n\npyfile <- tempfile(fileext=\".py\")\ncat('def area_of_triangle(h,x):\n  return h*x/2',file=pyfile)\nsource_python(pyfile)\n\narea_of_triangle(3,5)\n\n[1] 7.5\n\n\nBut deep down it is a Python function.\n\nprint(area_of_triangle)\n\n<function area_of_triangle at 0x13eb463a0>\n\n\n\n\nConclusion\nTo be honest Python versioning is a mess. Lots of parallel versions (even python2 version issues are still looming) and conflicts in different layers of computing might be troublesome especially in Docker settings. Therefore it is highly recommended to add Python code to your R code if it is totally necessary.\nThough it is always a good thing to have an exquisite tool if you need to use Python and cannot separate processes. reticulate is currently that tool."
  },
  {
    "objectID": "basics.html",
    "href": "basics.html",
    "title": "Basics",
    "section": "",
    "text": "See Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "advanced.html",
    "href": "advanced.html",
    "title": "Advanced",
    "section": "",
    "text": "See Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "ggplot2.html",
    "href": "ggplot2.html",
    "title": "3  ggplot2",
    "section": "",
    "text": "raw_df <- readRDS(\"rp_201801_202005_df.rds\")"
  },
  {
    "objectID": "ggplot2.html#scatterplot",
    "href": "ggplot2.html#scatterplot",
    "title": "3  ggplot2",
    "section": "3.2 Scatterplot",
    "text": "3.2 Scatterplot\nFirst let’s preprocess our data to get production in May 2020 and hours between 10:00 AM and 5:00 PM.\n\nplot_df1 <- \n  raw_df %>% \n    filter(dt >= \"2020-05-01\" & dt < \"2020-06-01\" & lubridate::hour(dt) >= 10 & lubridate::hour(dt) <= 17) %>%   transmute(hour_of_day = lubridate::hour(dt),wind_lic,sun_ul)\n\nprint(plot_df1,n=3)\n\n# A tibble: 248 × 3\n  hour_of_day wind_lic sun_ul\n        <int>    <dbl>  <dbl>\n1          17    2055.  1442.\n2          16    2036.  2523.\n3          15    1875.  3402.\n# … with 245 more rows\n\n\nLet’s plot licensed wind production against unlicensed solar production for May 2020 for hours between 10-17. We can say that\n\nUsually during morning time solar production is high and wind production is kind of low.\nExpectedly solar production is decreasing in the afternoon\n\n\nggplot(plot_df1, aes(x = wind_lic, y = sun_ul, color = as.character(hour_of_day))) + geom_point()\n\n\n\n\nggplot2 is quite flexible. We can move aes from ggplot object to geom_point object.\n\nggplot(plot_df1) + geom_point(aes(x = wind_lic, y = sun_ul, color = as.character(hour_of_day)))"
  },
  {
    "objectID": "ggplot2.html#line-chart",
    "href": "ggplot2.html#line-chart",
    "title": "3  ggplot2",
    "section": "3.3 Line Chart",
    "text": "3.3 Line Chart\nHere I want to compare wind and solar production in a time series plot.\n\nplot_df2 <- raw_df %>% filter(dt >= \"2020-05-01\" & dt < \"2020-06-01\") %>% select(dt,wind_lic,sun_ul) \n\nprint(plot_df2,n=3)\n\n# A tibble: 744 × 3\n  dt                  wind_lic sun_ul\n  <dttm>                 <dbl>  <dbl>\n1 2020-05-31 23:00:00    1434. 0.0582\n2 2020-05-31 22:00:00    1577. 0.032 \n3 2020-05-31 21:00:00    1858. 0.0335\n# … with 741 more rows\n\n\n\nggplot(plot_df2) + \n  geom_line(aes(x=dt,y=wind_lic,color=\"wind\")) + \n  geom_line(aes(x=dt,y=sun_ul,color=\"solar\"))\n\n\n\n\nWhat if I don’t want to repeat geom_line functions? I can use pivot_longer function to get all in a single geom_line.\n\nggplot(plot_df2 %>% pivot_longer(.,cols=-dt),aes(x=dt,y=value,color=name)) + geom_line()"
  },
  {
    "objectID": "ggplot2.html#bar-chart",
    "href": "ggplot2.html#bar-chart",
    "title": "3  ggplot2",
    "section": "3.4 Bar Chart",
    "text": "3.4 Bar Chart\nNow I’d like to get the May 2020 production and I’d like to differentiate Licensed and Unlicensed.\n\nplot_df3 <- raw_df %>% filter(dt >= \"2020-05-01\" & dt < \"2020-06-01\") %>% summarise(across(-dt,sum)) %>% pivot_longer(.,everything()) %>% mutate(type = ifelse( grepl(\"_lic+$\",name),\"Licensed\",\"Unlicensed\"))\n\nprint(plot_df3,n=3)\n\n# A tibble: 16 × 3\n  name              value type    \n  <chr>             <dbl> <chr>   \n1 wind_lic       1346260. Licensed\n2 geothermal_lic  654089. Licensed\n3 biogas_lic       56839. Licensed\n# … with 13 more rows\n\n\nLet’s plot total productions using a bar chart. To improve readability, we reorder by production and differentiate Licensed/Unlicensed using color.\n\nggplot(plot_df3,aes(x=reorder(name,-value),y=value,fill=type)) + geom_bar(stat = \"identity\") + theme(axis.text.x = element_text(angle=60,vjust=1,hjust=1))"
  },
  {
    "objectID": "ggplot2.html#pie-chart",
    "href": "ggplot2.html#pie-chart",
    "title": "3  ggplot2",
    "section": "3.5 Pie Chart",
    "text": "3.5 Pie Chart\n\nggplot(plot_df3 %>% filter(type==\"Licensed\"),aes(x=\"\",y=value,fill=name)) + geom_bar(stat=\"identity\") + coord_polar(\"y\")"
  },
  {
    "objectID": "ggplot2.html#theming-and-customization",
    "href": "ggplot2.html#theming-and-customization",
    "title": "3  ggplot2",
    "section": "3.6 Theming and Customization",
    "text": "3.6 Theming and Customization\nLet’s get our charts better looks!\n\nsc_plot <- ggplot(plot_df1) + geom_point(aes(x = wind_lic, y = sun_ul, color=as.character(hour_of_day)))\n\nsc_plot\n\n\n\n\n\nsc_plot2 <- sc_plot + theme_minimal()\nsc_plot2\n\n\n\n\n\nsc_plot3 <-\nsc_plot2 + labs(x=\"Licensed Wind Production (MWh)\", y=\"Unlicensed Solar Production (MWh)\", color=\"Hour of Day\", title = \"Licensed Wind vs Unlicensed Solar\", subtitle = \"Renewable production in May 2020, between 10:00-17:00 each day\") \n\nsc_plot3\n\n\n\n\n\nsc_plot3 + theme(legend.position = \"top\",axis.text.x = element_text(angle=45,hjust=1,vjust=1)) + scale_y_continuous(labels=function(x) format(x, big.mark = \".\", decimal.mark = \",\", scientific = FALSE)) + scale_x_continuous(labels=function(x) format(x, big.mark = \".\", decimal.mark = \",\", scientific = FALSE))"
  }
]